Title,Authors,Skip,Abstract
A Practitioner’s Guide to Software Test Design,"Copeland, L.",x (Book),
A Test Generation Strategy for Pairwise Testing,"Tai, K.-C. and Lei, Y.",,"Pairwise testing is a specification-based testing criterion which requires that for each pair of input parameters of a system, every combination of valid values of these two parameters be covered by at least one test case. The authors propose a novel test generation strategy for pairwise testing."
A Tester-Assisted Methodology for Test Redundancy Detection,"Negar, Vahid",,"Test redundancy detection reduces test maintenance costs and also ensures the integrity of test suites. One of the most widely used approaches for this purpose is based on coverage information. In a recent work, we have shown that although this information can be useful in detecting redundant tests, it may suffer from large number of false-positive errors, that is, a test case being identified as redundant while it is really not. In this paper, we propose a semiautomated methodology to derive a reduced test suite from a given test suite, while keeping the fault detection effectiveness unchanged. To evaluate the methodology, we apply the mutation analysis technique to measure the fault detection effectiveness of the reduced test suite of a real Java project. The results confirm that the proposed manual interactive inspection process leads to a reduced test suite with the same fault detection ability as the original test suite."
A comprehensive framework for testing database-centric applications,"Kapfhammer, G.M.",,"The database is a critical component of many modern software applications. Recent reports indicate that the vast majority of database use occurs from within an application program. Indeed, database-centric applications have been implemented to create digital libraries, scientific data repositories, and electronic commerce applications. However, a database-centric application is very different from a traditional software system because it interacts with a database that has a complex state and structure. This dissertation formulates a comprehensive framework to address the challenges that are associated with the efficient and effective testing of database-centric applications. The database-aware approach to testing includes: (i) a fault model, (ii) several unified representations of a program's database interactions, (iii) a family of test adequacycriteria, (iv) a test coverage monitoring component, and (v) tools for reducing and re-ordering a test suite during regression testing.This dissertation analyzes the worst-case time complexity of every important testing algorithm. This analysis is complemented by experiments that measure the efficiency and effectiveness of thedatabase-aware testing techniques. Each tool is evaluated by using it to test six database-centric applications. The experiments show thatthe database-aware representations can be constructed with moderate time and space overhead. The adequacy criteria call for test suitesto cover 20% more requirements than traditional criteria and this ensures the accurate assessment of test suite quality. It is possibleto enumerate data flow-based test requirements in less than one minute and coverage tree path requirements are normally identified in no morethan ten seconds. The experimental results also indicate that the coverage monitor can insert instrumentation probes into all six of theapplications in fewer than ten seconds. Although instrumentation may moderately increase the static space overhead of an application, the coverage monitoring techniques only increase testing time by 55% on average. A coverage tree often can be stored in less than five seconds even though the coverage report may consume up to twenty-fivemegabytes of storage. The regression tester usually reduces or prioritizes a test suite in under five seconds. The experiments also demonstrate that the modified test suite is frequently more streamlined than the initial tests."
A hybrid coverage criterion for dynamic web testing,"Zou, Y. and Fang, C. and Chen, Z. and Zhang, X. and Zhao, Z.",,"Testing criterion is a fundamental topic of software testing. A criterion is important to evaluate and drive a testing method. Code coverage is widely used in software testing, due to its simple implementation and effectiveness. Dynamic web techniques have been used to improve the usability and user experience of applications. However, it brings some new challenges for testing. Dynamic web applications have richer iterations between client-side and server-side, such that code coverage is difficult to capture these complex iterations for sufficient testing. In this paper, we present a novel coverage criterion - hybrid coverage. A hybrid coverage criterion which combines statement coverage and HTML element coverage, covers both client-side and server-side features. The experimental result shows that the hybrid coverage can detect 22.2%-48.1% more bugs than statement coverage, 7.9%-57.1% more bugs than element coverage."
A manager’s guide to evaluating test suites,"Marick, B. and Bach, J. and Kaner, C.Cem",x (not found),
A novel approach to collaborative testing in a crowdsourcing environment,"Tung, Y.-H. and Tseng, S.-S.",,"Software testing processes are generally labor-intensive and often involve substantial collaboration among testers, developers, and even users. However, considerable human resource capacity exists on the Internet in social networks, expert communities, or internet forums—referred to as crowds. Effectively using crowd resources to support collaborative testing is an interesting and challenging topic. This paper defines the collaborative testing problem in a crowd environment as an NP-Complete job assignment problem and formulates it as an integer linear programming (ILP) problem. Although package tools can be used to obtain the optimal solution to an ILP problem, computational complexity makes these tools unsuitable for solving large-scale problems. This study uses a greedy approach with four heuristic strategies to solve the problem. This is called the crowdsourcing-based collaborative testing approach. This approach includes two phases, training phase and testing phase. The training phase transforms the original problem into an ILP problem. The testing phase solves the ILP using heuristic strategies. A prototype system, called the Collaborative Testing System (COTS), is also implemented. The experiment results show that the proposed heuristic algorithms produce good quality approximate solutions in an acceptable timeframe."
A novel method of mutation clustering based on domain analysis,"Ji, C. and Chen, Z. and Xu, B. and Zhao, Z.",,"Mutation testing is an effective but expensive technique. There exists much improvement to help mutation testing become a wide-used technique. The main objective is to reduce the number of mutants and the reduced test sets can still approximate the adequacy. Recently a new method, called mutation clustering, is proposed to integrate data clustering and mutation analysis, such that both mutant sets and test sets can be reduced dramatically. This paper provides domain analysis to cluster mutants statically before test case generation. And then the simplified mutant set is used to generate a test set. We hypothesize that such a test set can kill the original mutant set approximately. The cost of mutation testing will further decrease, because only a small test set needs to be generated and executed. A case study shows an encouraging result to support our hypothesis."
A practical tutorial on modified condition/decision coverage,"Hayhurst, K. and Veerhusen, D. and Rierson, L.",x (Book),
"A safe, efficient regression test selection technique","Rothermel, G. and Harrold, M.J.",,"Regression testing is an expensive but necessary maintenance activity performed on modified software to provide confidence that changes are correct and do not adversely affect other portions of the softwore. A regression test selection technique choses, from an existing test set, thests that are deemed necessary to validate modified software. We present a new technique for regression test selection. Our algorithms construct control flow graphs for a precedure or program and its modified version and use these graphs to select tests that execute changed code from the original test suite. We prove that, under certain conditions, the set of tests our technique selects includes every test from the original test suite that con expose faults in the modified procedfdure or program. Under these conditions our algorithms are safe. Moreover, although our algorithms may select some tests that cannot expose faults, they are at lease as precise as other safe regression test selection algorithms. Unlike many other regression test selection algorithms, our algorithms handle all language constructs and all types of program modifications. We have implemented our algorithms; initial empirical studies indicate that our technique can significantly reduce the cost of regression testing modified software."
A specification-based coverage metric to evaluate test sets,"Amman, Paul E. and Black, Paul E.",,"Software developers use a variety of formal and informal methods, including testing, to argue that their systems are suitable for building high assurance applications. In this paper, we develop another connection between formal methods and testing by defining a specification-based coverage metric to evaluate test sets. Formal methods in the form of a model checker supply the necessary automation to make the metric practical. The metric gives the software developer assurance that a given test set is sufficiently sensitive to the structure of an application's specification. We also develop the necessary foundation for the metric and then illustrate the metric on an example."
A state-based approach to testing aspect-oriented programs,"Xu, D. and Xu, W. and Nygard, K.",,"This paper presents a state-based approach to testing aspect-oriented programs. Aspectual state models, as an extension to the testable FREE state model of classes, are exploited to capture the impact of aspects on the state models of classes. To generate test suites for adequately testing object behavior and interaction between classes and aspects in terms of message sequences, we transform an aspectual state model to a transition tree, where each path from the root to some leaf node indicates a template of test cases, i.e. message sequences. Since the state-based approach is directly built upon the test design patterns for object-oriented programs, it is not only applicable to the simultaneous development of classes and aspects, but also to the incremental development of aspects based on the existing classes."
A survey of combinatorial testing,"Nie, C. and Leung, H.",,"Combinatorial Testing (CT) can detect failures triggered by interactions of parameters in the Software Under Test (SUT) with a covering array test suite generated by some sampling mechanisms. It has been an active field of research in the last twenty years. This article aims to review previous work on CT, highlights the evolution of CT, and identifies important issues, methods, and applications of CT, with the goal of supporting and directing future practice and research in this area. First, we present the basic concepts and notations of CT. Second, we classify the research on CT into the following categories: modeling for CT, test suite generation, constraints, failure diagnosis, prioritization, metric, evaluation, testing procedure and the application of CT. For each of the categories, we survey the motivation, key issues, solutions, and the current state of research. Then, we review the contribution from different research groups, and present the growing trend of CT research. Finally, we recommend directions for future CT research, including: (1) modeling for CT, (2) improving the existing test suite generation algorithm, (3) improving analysis of testing result, (4) exploring the application of CT to different levels of testing and additional types of systems, (5) conducting more empirical studies to fully understand limitations and strengths of CT, and (6) combining CT with other testing techniques."
A survey on code coverage as a stopping criterion for unit testing,"Smith, B. and Williams, L.A.",,"The evidence regarding code coverage as a predictor of software quality is conflicting and inconclusive. However, an estimate of the software testing practices of the majority of professionals can help researchers know how code coverage is being used—or whether it is being used at all. The purpose of this report is to present the results of an online survey we conducted to estimate the percentage of software developers who use code coverage as a stopping criterion for unit testing. We find that a majority of participants 1) perform automated unit testing; and 2) use code coverage, though not always as a stopping criterion. Those people who do not use code coverage, do not find it useful or provide some other reason. Finally, in place of code coverage, we find that most participants stop testing when they have “tested the most important parts of the code”."
A systematic approach for designing mutation operators for MDE languages,"Alhwikem, F. and Paige, R.F. and Rose, L. and Alexander, R.",,"Testing is an essential activity in software development, used to increase confidence in the quality of software. One testing approach that is used to evaluate the quality of testing inputs for a particular program is mutation analysis. The most important step in mutation analysis is the process of defining mutation operators that mimic typical errors of the users of a language. There is a wide variety of mutation operators that have been designed for a number of languages including C, Java, and SQL. However, the design of mutation operators is rarely systematic, which may result in passing over crucial operators for specific features of languages. This paper describes a way to apply mutation analysis in the context of Model Driven Engineering (MDE). In particular, the paper proposes a systematic approach for designing mutation operators for MDE languages. The systematic approach is demonstrated for the Atlas Transformation Language (ATL) and the result is a list of mutation operators that includes previously designed ones for ATL from the literature."
A tool for domain-independent model mutation,"Gómez-Abajo, P. and Guerra, E. and Lara, J. and Merayo, M.G.",,"Mutation is a systematic technique to create variants of a seed artefact by means of mutation operators. It has many applications in computer science, like software testing, automatic exercise generation and design space exploration. Typically, mutation frameworks are developed ad-hoc by implementing mutation operators and their application strategies from scratch, using general-purpose programming languages. However, this is costly and error-prone. To improve this situation, we propose Wodel: a domain-specific language and tool for model-based mutation that is independent of the domain meta-model. Wodelenables the rapid development and application of model mutations. It provides built-in advanced functionalities like automatic generation of seed models, and static and dynamic metrics of operator coverage and applicability. It offers extension points, e.g., to post-process mutants and describe domain-specific equivalence criteria. As an example, we illustrate the usage of Wodel for the mutation of security policies, and present an empirical evaluation of its expressiveness."
Advances on Improving Automation in Developer Testing,"Xiao, X. and Thummalapenta, S. and Xie, T.",,"Developer testing, a common step in software development, involves generating desirable test inputs and checking the behavior of the program unit under test during the execution of the test inputs. Existing developer testing tools include various techniques to address challenges of generating desirable test inputs and checking the behavior of the program unit under test (referred to as test oracles). In this chapter, we present an overview of techniques implemented in these testing tools to address challenges in improving automation in developer testing. In particular, we focus on a recent state-of-the-art technique, called symbolic execution for test inputs. We briefly describe symbolic execution and discuss various challenges (along with the techniques developed to address those challenges) in generating test inputs automatically. For test inputs, the techniques presented in our chapter are summarized from two main aspects: test efficiency (e.g., with a focus on cost) and test effectiveness (e.g., with a focus on benefit). We conclude this chapter by presenting a new frontier, called cooperative developer testing, that is orthogonal to previous techniques and involves synergistic cooperation between humans and tools for effectively generating desirable test inputs."
Agile High Assurance: Testing re-imagined,"Binder, R.V.",x (Presentation),
All-du-path coverage for parallel programs,"Yang, C.-S.D. and Souter, A.L. and Pollock, L.L.",,"One significant challenge in bringing the power of parallel machines to application programmers is providing them with a suite of software tools similar to the tools that sequential programmers currently utilize. In particular, automatic or semi-automatic testing tools for parallel programs are lacking. This paper describes our work in automatic generation of all-du-paths for testing parallel programs. Our goal is to demonstrate that, with some extension, sequential test data adequacy criteria are still applicable to parallel program testing. The concepts and algorithms in this paper have been incorporated as the foundation of our DELaware PArallel Software Testing Aid, della pasta."
An Experimental Evaluation of Data Flow and Mutation Testing,"A. Jefferson, Jie, Kanupriya, Tong",,"Two experimental comparisons of data flow and mutation testing are presented. These techniques are widely considered to be effective for unit-level software testing, but can only be analytically compared to a limited extent. We compare the techniques by evaluating the effectiveness of test data developed for each. We develop ten independent sets of test data for a number of programs: five to satisfy the mutation criterion and five to satisfy the all-uses data-flow criterion. These test sets are developed using automated tools, in a manner consistent with the way a test engineer might be expected to generate test data in practice. We use these test sets in two separate experiments. First we measure the effectiveness of the test data that was developed for one technique in terms of the other. Second, we investigate the ability of the test sets to find faults. We place a number of faults into each of our subject programs, and measure the number of faults that are detected by the test sets. Our results indicate that while both techniques are effective, mutation-adequate test sets are closer to satisfying the data flow criterion, and detect more faults."
An Experimental Mutation System for Java,"Offutt, A.J. and Ma, Y.-S. and Kwon, Y.-R.",,"Mutation is a powerful but complicated and computationally expensive testing method. Mutation is also a valuable experimental research technique that has been used in many studies. Mutation has been experimentally compared with other test criteria, and also used to support experimental comparisons of other test criteria, by using mutants as a method to create faults. In effect, mutation is often used as a "gold standard" for experimental evaluations of test methods. This paper presents a publicly available mutation system for Java that supports both traditional statement-level mutants and newer inter-class mutants. MUJAVA can be freely downloaded and installed with relative ease under both Unix and Windows. MUJAVA is offered as a free service to the community and we hope that it will promote the use of mutation analysis for experimental research in software testing."
An empirical analysis of flaky tests,"Luo, Q. and Hariri, F. and Eloussi, L. and Marinov, D.",,"Regression testing is a crucial part of software development. It checks that software changes do not break existing functionality. An important assumption of regression testing is that test outcomes are deterministic: an unmodified test is expected to either always pass or always fail for the same code under test. Unfortunately, in practice, some tests often called flaky tests—have non-deterministic outcomes. Such tests undermine the regression testing as they make it difficult to rely on test results. We present the first extensive study of flaky tests. We study in detail a total of 201 commits that likely fix flaky tests in 51 open-source projects. We classify the most common root causes of flaky tests, identify approaches that could manifest flaky behavior, and describe common strategies that developers use to fix flaky tests. We believe that our insights and implications can help guide future research on the important topic of (avoiding) flaky tests."
An empirical study of the robustness of Windows NT applications using random testing,"Forrester, J.E. and Miller, B.P.",,"We report on the third in a series of studies on the reliability of application programs in the face of random input. In 1990 and 1995, we studied the reliability of UNIX application programs, both command line and X-Window based (GUI). In this study, we apply our testing techniques to applications running on the Windows NT operating system. Our testing is simple black-box random input testing; by any measure, it is a crude technique, but it seems to be effective at locating bugs in real programs. We tested over 30 GUI-based applications by subjecting them to two kinds of random input: (1) streams of valid keyboard and mouse events and (2) streams of random Win32 messages. We have built a tool that helps automate the testing of Windows NT applications. With a few simple parameters, any application can be tested. Using our random testing techniques, our previous UNIX-based studies showed that we could crash a wide variety of command-line and X-window based applications on several UNIX platforms. The test results are similar for NT-based applications. When subjected to random valid input that could be produced by using the mouse and keyboard, we crashed 21% of applications that we tested and hung an additional 24% of applications. When subjected to raw random Win32 messages, we crashed or hung all the applications that we tested. We report which applications failed under which tests, and provide some analysis of the failures."
An evaluation of exhaustive testing for data structures,"Marinov, D. and Andoni, A. and Daniliuc, D. and Khurshid, S. and Rinard, M.",,"We present an evaluation of exhaustive testing of linked data structures with sophisticated structural constraints. Specifically, we use the Korat testing framework to systematically enumerate all legal inputs within a certain size. We then evaluate the quality of this test suite according to several measurements: ability to detect injected faults in the original correct implementations, code coverage, and specification coverage. Our results indicate that it is feasible to use exhaustive testing to obtain, within a reasonable amount of time, a high-quality test suite that can detect almost all faults and achieve complete code and specification coverage. Moreover, our results show that our exhaustive tests are of higher quality than randomly selected test suites that contain the same number of inputs selected from a larger potential input set. We conclude that exhaustive testing is a practical and effective testing methodology for sophisticated linked data structures."
An evaluation of random testing,"Duran, Joe W. and Ntafos, Simeon C.",,"Random testing of programs has usually (but not always) been viewed as a worst case of program testing. Testing strategies that take into account the program structure are generally preferred. Path testing is an often proposed ideal for structural testing. Path testing is treated here as an instance of partition testing, where by partition testing is meant any testing scheme which forces execution of at least one test case from each subset of a partition of the input domain. Simulation results are presented which suggest that random testing may often be more cost effective than partition testing schemes. Also, results of actual random testing experiments are presented which confirm the viability of random testing as a useful validation tool."
An experimental determination of sufficient mutation operators,"Offutt, J. and Lee, A. and Rothermel, G. and Untch, R. and Zapf, C.",,"Mutation testing is a technique for unit-testing software that, although powerful, is computationally expensive, The principal expense of mutation is that many variants of the test program, called mutants, must be repeatedly executed. This article quantifies the expense of mutation in terms of the number of mutants that are created, then proposes and evaluates a technique that reduces the number of mutants by an order of magnitude. Selective mutation reduces. the cost of mutation testing by reducing the number of mutants, This article reports experimental results that compare selective mutation testing with standard, or nonselective, mutation testing, and results that quantify the savings achieved by selective mutation testing, The results support the hypothesis that selective mutation is almost as strong as nonselective mutation: in experimental trials selective mutation provides almost the same coverage as nonselective mutation. with a four-fold or more reduction in the number of mutants."
An investigation of three forms of the modified condition decision coverage (mcdc) criterion,"Chilenski, J.",,"This report compares three forms of Modified Condition Decision Coverage (MCDC). MCDC is a structural coverage criterion used to assist with the assessment of the adequacy of the requirements-based testing process. This level of coverage is required for Level A software. The purpose of these comparisons is to provide data to enable a rational choice for what form of structural coverage is required for Level A software. This report provides justification why structural coverage, in general, and MCDC in particular, should be part of the software system development process. Definitions for three forms of MCDC are given, along with extensions for relational operators. These three forms of MCDC are compared theoretically and empirically for minimum probability of error detection performance and ease of satisfaction. Conclusions from the data are drawn and limitations of the study methodology are identified."
App testing now consumes a quarter of IT budget,"Vizard, M.",x (Web),
Applying design of experiments to software testing: Experience report,"Dunietz, I.S. and Ehrlich, W.K. and Szablak, B.D. and Mallows, C.L. and Iannino, A.",,"Recently, a class of experimental designs has been devised that guarantee input domain coverage up to all combinations of k test factors taken t at a time. With such designs, all pairwise combinations (or triplets or quadruplets, etc.) are selected at least once. To evaluate their applicability to software testing, we analyzed the extent to which software coverage (i.e., code execution) achieved by these designs for t=1, ... ,k is representative of that achieved by exhaustively testing all factor combinations. The block coverage obtained for t;5;2 was comparable with that achieved by exhaustively testing all factor combinations but higher-order values of t were required for path coverage. Implications of these results for software testing are discussed."
Assessing test set adequacy for object oriented programs using class mutation,"Kim, S. and Clark, J. and McDermid, J.",,"The object-oriented paradigm has seen widespread acceptance by the software development community but the testing of programs written in object oriented languages is less well developed than the testing of programs written in conventional ones. This paper introduces Class Mutation which is a form of OO-directed selective mutation testing that provides a means of assessing how good developed test sets are for OO programs. Experimental results are given for the application of three particular mutation operators for the Java language to assess test sets developed to satisfy a conventional criterion."
Assessing the test suite of a large scale system based on code coverage and derived metrics,"L. Vidács, F. Horváth, D. Tengeri and Beszédes, Á.",x (not found),
"Assessing, Comparing, and Combining State Machine-Based Testing and Structural Testing: A Series of Experiments","Samar, Lionel C., Yvan, Massimiliano",,"A large number of research works have addressed the importance of models in software engineering. However, the adoption of model-based techniques in software organizations is limited since these models are perceived to be expensive and not necessarily cost-effective. Focusing on model-based testing, this paper reports on a series of controlled experiments. It investigates the impact of state machine testing on fault detection in class clusters and its cost when compared with structural testing. Based on previous work showing this is a good compromise in terms of cost and effectiveness, this paper focuses on a specific state-based technique: the round-trip paths coverage criterion. Round-trip paths testing is compared to structural testing, and it is investigated whether they are complementary. Results show that even when a state machine models the behavior of the cluster under test as accurately as possible, no significant difference between the fault detection effectiveness of the two test strategies is observed, while the two test strategies are significantly more effective when combined by augmenting state machine testing with structural testing. A qualitative analysis also investigates the reasons why test techniques do not detect certain faults and how the cost of state machine testing can be brought down."
Augmenting Automatically Generated Unit-Test Suites,"Xie, T.",,"A test case consists of two parts: a test input to exercise the program under test and a test oracle to check the correctness of the test execution. A test oracle is often in the form of executable assertions such as in the JUnit testing framework. Manually generated test cases are valuable in exposing program faults in the current program version or regression faults in future program versions. However, manually generated test cases are often insufficient for assuring high software quality. We can then use an existing test-generation tool to generate new test inputs to augment the existing test suite. However, without specifications these automatically generated test inputs often do not have test oracles for exposing faults. In this paper, we have developed an automatic approach and its supporting tool, called Orstra, for augmenting an automatically generated unit-test suite with regression oracle checking. The augmented test suite has an improved capability of guarding against regression faults. In our new approach, Orstra first executes the test suite and collects the class under test’s object states exercised by the test suite. On collected object states, Orstra creates assertions for asserting behavior of the object states. On executed observer methods (public methods with non-void returns), Orstra also creates assertions for asserting their return values. Then later when the class is changed, the augmented test suite is executed to check whether assertion violations are reported. We have evaluated Orstra on augmenting automatically generated tests for eleven subjects taken from a variety of sources. The experimental results show that an automatically generated test suite’s fault-detection capability can be effectively improved after being augmented by Orstra."
Automated software test data generation,"Korel, B.",,"An alternative approach to test-data generation based on actual execution of the program under test, function-minimization methods and dynamic data-flow analysis is presented. Test data are developed for the program using actual values of input variables. When the program is executed, the program execution flow is monitored. If during program execution an undesirable execution flow is observed then function-minimization search algorithms are used to automatically locate the values of input variables for which the selected path is traversed. In addition, dynamic data-flow analysis is used to determine those input variables responsible for the undesirable program behavior, significantly increasing the speed of the search process. The approach to generating test data is then extended to programs with dynamic data structures and a search method based on dynamic data-flow analysis and backtracking is presented. In the approach described, values of array indexes and pointers are known at each step of program execution; this information is used to overcome difficulties of array and pointer handling."
Automated test generation from a behavioral model,"Clarke, J.M.",,"The challenge for testers: reduce the testing interval without reducing quality. One answer: find a new way to approach test design and test generation. This paper will discuss an ongoing Lucent Technologies experiment in automated test generation from a behavioral model of the software product under test. Results indicate that our new approach can increase the effectiveness of our testing while reducing the cost of test design and generation."
Automatic Generation of Software Test Cases From Formal Specifications,"Meudec, Christophe",,"Software testing consumes a large percentage of total software development costs.Yet, it is still usually performed manually in a non rigorous fashion. While techniques, and limited automatic support, for the generation of test data from the actual code of the system under test have been well researched, test cases generation from a high level specification of the intended behaviour of the system being developed has hardly been addressed. In this thesis we present a rationale for using tests derived from high level formal specifications and then set to find an effcient technique for the generation of adequate test sets from specifications written in our study language, VDM-SL. In this work, we formalise the traditional high level partitioning technique used in a previously researched test cases generator prototype, and extend it to take the semantics of VDM-SL fully into account. We then discuss, and illustrate, the shortcomings of the technique as used, which results in to o few tests being generated and potentially large sections of a specification not employed by the test generation process. Another strand of research, based on test generation from Z predicates, is examined and extended using our formalism to include quantified expressions and other, more complex, constructs of formal specification languages. We then show that this more refined technique complements the previous work and that their combination should allow the generation of adequate test sets from formal specifications. Using our formalism, we illustrate that to synthesise pragmatically the two techniques, one must find heuristics for the detection of redundant test cases. We present our central heuristic, justified using probabilities, based on the independence of some divisions of the input domain of the system under test, which allows the contraction of test sets without impairing their likelihood of revealing an error in the system under test. Finally, we propose a technique for the efficient generation of adequate test cases."
Automatic Test-case Generation from Formal Models of Software,"Rayadurgam, S.",x (Book),
Automatically detecting equivalent mutants and infeasible paths,"A. Jefferson, Jie",,"Mutation testing is a technique for testing software units that has great potential for improving the quality of testing, and thereby increasing the ability to assure the high reliability of critical software. It will be shown that recent advances in mutation research have brought a practical mutation testing system closer to reality. One recent advance is a partial solution to the problem of automatically detecting equivalent mutant programs. Equivalent mutants are currently detected by hand, which makes it very expensive and time-consuming. The problem of detecting equivalent mutants is a specific instance of a more general problem, commonly called the feasible path problem, which says that for certain structural testing criteria some of the test requirements are infeasible in the sense that the semantics of the program imply that no test case satisfies the test requirements. Equivalent mutants, unreachable statements in path testing techniques, and infeasible DU-pairs in data flow testing are all instances of the feasible path problem. This paper presents a technique that uses mathematical constraints, originally developed for test data generation, to detect some equivalent mutants and infeasible paths automatically."
Basic mistakes in database testing,"Guz, S.",x (Web),
Beyond code coverage &#x2014; An approach for test suite assessment and improvement,"David, Arpad, Tamas, Laszlo, David, Tibor",,"Code coverage is successfully used to guide white box test design and evaluate the respective test completeness. However, simple overall coverage ratios are often not precise enough to effectively help when a (regression) test suite needs to be reassessed and evolved after software change. We present an approach for test suite assessment and improvement that utilizes code coverage information, but on a more detailed level and adds further evaluation aspects derived from the coverage. The main use of the method is to aid various test suite evolution situations such as removal, refactoring and extension of test cases as a result of code change or test suite efficiency enhancement. We define various metrics to express different properties of test suites beyond simple code coverage ratios, and present the assessment and improvement process as an iterative application of different improvement goals and more specific sub-activities. The method is demonstrated by applying it to improve the tests of one of our experimental systems."
Boundary values and automated component testing,"Hoffman, Daniel and Strooper, Paul and White, Lee",,"Structural coverage approaches to software testing are mature, having been thoroughly studied for decades. Significant tool support, in the form of instrumentation for statement or branch coverage, is available in commercial compilers. While structural coverage is sensitive to which code structures are covered, it is insensitive to the values of the variables when those structures are executed. Data coverage approaches, e.g. boundary value coverage, are far less mature. They are known to practitioners mostly as a few useful heuristics with very little support for automation. Because of its sensitivity to variable values, data coverage has significant potential, especially when used in combination with structural coverage. This paper generalizes the traditional notion of boundary coverage, and formalizes it with two new data coverage measures. These measures are used to generate test cases automatically and from these, sophisticated test suites for functions from the C++ Standard Template Library. Finally, the test suites are evaluated with respect to both structural coverage and discovery of seeded faults."
CUTE and jCUTE: Concolic unit testing and explicit path model-checking tools,"Sen, K. and Agha, G.",,"CUTE, a Concolic Unit Testing Engine for C and Java, is a tool to systematically and automatically test sequential C programs (including pointers) and concurrent Java programs. CUTE combines concrete and symbolic execution in a way that avoids redundant test cases as well as false warnings. The tool also introduces a race-flipping technique to efficiently test and model check concurrent programs with data inputs."
Chapter six - mutation testing advances: An analysis and survey,"Papadakis, M. and Kintis, M. and Zhang, J. and Jia, Y. and Traon, Y.L. and Harman, M.",,"Mutation testing realizes the idea of using artificial defects to support testing activities. Mutation is typically used as a way to evaluate the adequacy of test suites, to guide the generation of test cases, and to support experimentation. Mutation has reached a maturity phase and gradually gains popularity both in academia and in industry. This chapter presents a survey of recent advances, over the past decade, related to the fundamental problems of mutation testing and sets out the challenges and open problems for the future development of the method. It also collects advices on best practices related to the use of mutation in empirical studies of software testing. Thus, giving the reader a “mini-handbook”-style roadmap for the application of mutation testing as experimental methodology."
Clover Java and groovy code coverage tool homepage,Atlassian,x (not found),
Constrained mutation in c programs,"Wong, W.E. and Maldonado, J.C. and Delamaro, M.E. and Mathur, A.P.",x (not found),
Correction to: Evaluating testing methods by delivered reliability,"Frankl, Phyllis and Hamlet, Dick and Littlewood, Bev and Strigini, Lorenzo",x (no paper),
Coverage criteria for testing web applications,"Sampath, S. and Gibson, E. and Sprenkle, S. and Pollock, L.",,"As web applications evolve and their usage increases, their complexity also increases, thus creating a great demand for techniques and tools to ensure well-tested, reliable applications. While program-based coverage and fault detection capability can be used to measure the quality of test suites, the dynamic characteristics of web applications motivate additional criteria to complement these traditional test adequacy criteria. This paper presents novel dynamic coverage criteria customized for web applications—criteria intended for testing at a page level. Based on a changing universe of test requirements, as indicated by evolving usage of the application, our criteria avoid the difficulties of building an accurate static model of a web application’s structure. We define a class of dynamic coverage criteria, present the subsumption relation among them, and describe two case studies to demonstrate their usefulness. Among other possible uses, the proposed criteria can be used to compare the quality of test suites, to select test cases, and to examine how usage of a web application changes over time. The proposed criteria complement traditional program coverage and fault detection capability criteria."
DWASTIC: Automating coverage metrics for dynamic web applications,"Alalfi, M. and Cordy, J.R. and Dean, T.R.",,"Building comprehensive test suites for web applications poses new challenges in software testing. Coverage criteria used for traditional systems to assess the quality of test cases are simply not sufficient for complex dynamic applications. As a result, faults in web applications can often be traced to insufficient testing coverage of the complex interactions between the components. This paper presents a new set of coverage criteria for web applications, based on page access, use of server variables, and interactions with the database. Following an instrumentation transformation to insert dynamic tracking of these aspects, a static analysis is used to automatically create a coverage database by extracting and executing only the instrumentation statements of the program. The database is then updated dynamically during execution by the instrumentation calls themselves. We have evaluated the usefulness of our coverage criteria and the feasibility and precision of our approach on the popular bulletin board web application PhpBB."
DeepTest,"Yuchi, Kexin, Suman, Baishakhi",,"Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge."
"Defect-Based Testing,” in Dependable Software Systems Engineering","Pretschner, A.",,"What is a good test case? One that reveals potential defects with good cost-effectiveness. We provide a generic model of faults and failures, formalize it, and present its various methodological usages for test case generation."
Directed Random Testing,"Pacheco, C.",,"Random testing can quickly generate many tests, is easy to implement, scales to large software applications, and reveals software errors. But it tends to generate many tests that are illegal or that exercise the same parts of the code as other tests, thus limiting its effectiveness. Directed random testing is a new approach to test generation that overcomes these limitations, by combining a bottom-up generation of tests with runtime guidance. A directed random test generator takes a collection of operations under test and generates new tests incrementally, by randomly selecting operations to apply and finding arguments from among previously-constructed tests. As soon as it generates a new test, the generator executes it, and the result determines whether the test is redundant, illegal, error-revealing, or useful for generating more tests. The technique outputs failing tests pointing to potential errors that should be corrected, and passing tests that can be used for regression testing. The thesis also contributes auxiliary techniques that post-process the generated tests, including a simplification technique that transforms a, failing test into a smaller one that better isolates the cause of failure, and a branch-directed test generation technique that aims to increase the code coverage achieved by the set of generated tests. Applied to 14 widely-used libraries (including the Java JDK and the core .NET framework libraries), directed random testing quickly reveals many serious, previously unknown errors in the libraries. And compared with other test generation tools (model checking, symbolic execution, and traditional random testing), it reveals more errors and achieves higher code coverage. (cont.) In an industrial case study, a test team at Microsoft using the technique discovered in fifteen hours of human effort as many errors as they typically discover in a person-year of effort using other testing methods."
Directed test suite augmentation: techniques and tradeoffs,"Xu, Z. and Kim, Y. and Kim, M. and Rothermel, G. and Cohen, M.B.",,"Test suite augmentation techniques are used in regression testing to identify code elements affected by changes and to generate test cases to cover those elements. Our preliminary work suggests that several factors influence the cost and effectiveness of test suite augmentation techniques. These include the order in which affected elements are considered while generating test cases, the manner in which existing regression test cases and newly generated test cases are used, and the algorithm used to generate test cases. In this work, we present the results of an empirical study examining these factors, considering two test case generation algorithms (concolic and genetic). The results of our experiment show that the primary factor affecting augmentation is the test case generation algorithm utilized; this affects both cost and effectiveness. The manner in which existing and newly generated test cases are utilized also has a substantial effect on efficiency but a lesser effect on effectiveness. The order in which affected elements are considered turns out to have relatively few effects when using concolic test case generation, but more substantial effects when using genetic test case generation."
Early estimation of software quality using in-process testing metrics: a controlled case study,"Nagappan, N. and Vouk, M.A. and Osborne, J.A.",,"In industrial practice, information on post-release field quality of a product tends to become available too late in the software development process to affordably guide corrective actions. An important step towards remediation of this problem of late information lies in the ability to provide an early estimation of software post-release field quality. This paper presents the use of a suite of in-process metrics that leverages the software testing effort to provide (1) an estimation of potential software field quality in early software development phases, and (2) the identification of low quality software programs. A controlled case study conducted at North Carolina State University provides initial indication that our approach is effective for making an early assessment of post-release field quality."
Effective Unit Testing: A guide for Java developers,"Koskela, L.",x (Book),
Effective random testing of concurrent programs,"Sen, K.",,"Multithreaded concurrent programs often exhibit wrong behaviors due to unintended interferences among the concurrent threads. Such errors are often hard to find because they typically manifest under very specific thread schedules. Traditional testing, which pays no attention to thread schedules and non-deterministically exercises a few arbitrary schedules, often misses such bugs. Traditional model checking techniques, which try to systematically explore all thread schedules, give very high confidence in the correctness of the system, but, unfortunately, they suffer from the state explosion problem. Recently, dynamic partial order techniques have been proposed to alleviate the problem. However, such techniques fail for large programs because the state space remains large in spite of reduction. An inexpensive and a simple alternative approach is to perform random testing by choosing thread schedules at random. We show that such a naive approach often explores some states with very high probability compared to the others. We propose a random partial order sampling algorithm (or RAPOS) that partly removes this non-uniformity in sampling the state space. We empirically compare the proposed algorithm with the simple random testing algorithm and show that the former outperforms the latter"
Efficiency of mutation operators and selective mutation strategies: an empirical study,"Elfurjani S., Leonardo",,"This paper investigates the mutation scores achieved by individual operators of the Mothra mutation system and their associated costs in order to determine the most efficient operators. The cost of mutation analysis includes both test set generation and equivalent mutant detection. The score and cost information is then used as a heuristic for choosing a subset of the operators for use in efficient selective mutation testing. Experiments were performed using a sample of 11 programs and a number of test sets for each program. The results show that the use of efficient operators can provide significant efficiency gains for selective mutation if the acceptable mutation score is not very close to one. When mutation scores very close to one are required, a randomly selected proportion of the mutants provides a more efficient strategy than a subset of efficient operators."
Efficient multi-objective higher order mutation testing with genetic programming,"Langdon, W.B. and Harman, M. and Jia, Y.",,"It is said 90% of faults that survive manufacturer’s testing procedures are complex. That is, the corresponding bug fix contains multiple changes. Higher order mutation testing is used to study defect interactions and their impact on software testing for fault finding. We adopt a multi-objective Pareto optimal approach using Monte Carlo sampling, genetic algorithms and genetic programming to search for higher order mutants which are both hard-to-kill and realistic. The space of complex faults (higher order mutants) is much larger than that of traditional first order mutations which correspond to simple faults, nevertheless search based approaches make this scalable. The problems of non-determinism and efficiency are overcome. Easy to detect faults may become harder to detect when they interact and impossible to detect single faults may be brought to light when code contains two such faults. We use strong typing and BNF grammars in search based mutation testing to find examples of both in ancient heavily optimised every day C code."
Efficient mutation analysis: A new approach,"Fleyshgakker, V.N. and Weiss, S.N.",,"In previously reported research we designed and analyzed algorithms that improved upon the run time complexity of all known weak and strong mutation analysis methods at the expense of increased space complexity. Here we describe a new serial strong mutation algorithm whose running time is on the average much faster than the previous ones and that uses significantly less space than them also. Its space requirement is approximately the same as that of Mothra, a well-known and readily available implemented system. Moreover, while this algorithm can serve as basis for a new mutation system, it is designed to be consistent with the Mothra architecture, in the sense that, by replacing certain modules of that system with new ones, a much faster system will result. Such a Mothra-based implementation of the new work is in progress. Like the previous algorithms, this one, which we call Lazy Mutant Analysis or LMA, tries to determine whether a mutant is strongly killed by a given test only if it is already known that it is weakly killed by that test. Unlike those algorithms, LMA avoids executing many mutants by dynamically discovering classes of mutants that have the “same” behavior, and executing representatives of those classes. The overhead it incurs is small in proportion to the time saved, and the algorithm has a very natural parallel implementation. In comparison to the fastest known algorithms for strong mutation analysis, in the best case, LMA can improve the speed by a factor proportional to the average number of mutants per program statement. In the worst case, there is no improvement in the running time, but such a case is hard to construct. This work enables us to apply mutation analysis to significantly larger programs than is currently possible."
Efficient mutation testing using whole test suite generation,"Fraser, G. and Arcuri, A.",,"By seeding artificial faults (mutants), mutation testing can tell us how good existing tests are, and it can help to direct test generation efforts. However, mutation based test generation is hampered because there usually are simply too many mutants, and too many of these mutants are either trivially killed or equivalent. Any effort spent on test generation for equivalent mutants is per definition wasted, and misdirects resources from where they could be put to better use – for example to produce tests revealing more non-equivalent mutants. To overcome this problem, our search-based EVOSUITE test generation tool integrates two optimizations: First, we avoid redundant test executions on mutants by monitoring state infection conditions, and second we use whole test suite generation to optimize test suites towards killing the highest number of mutants, rather than selecting individual mutants. These optimizations allowed us to perform one of the largest empirical studies on mutation testing to date, where we applied EVOSUITE to a random sample of 100 open source projects consisting of a total of 8,963 classes, leading to a total of 1,380,302 mutants. The experiment not only demonstrates that our approach scales well, but it also quantifies the relations between weak and strong mutation testing as well as branch coverage, and points out current limitations."
Evaluating advantages of test driven development: A controlled experiment with professionals,"Canfora, G. and Cimitile, A. and Garcia, F. and Piattini, M. and Visaggio, C.A.",,"Test driven development (TDD) is gaining interest among practitioners and researchers: it promises to increase the quality of the code. Even if TDD is considered a development practice, it relies on the use of unit testing. For this reason, it could be an alternative to the testing after coding (TAC), which is the usual approach to run and execute unit tests after having written the code. We wondered which are the differences between the two practices, from the standpoint of quality and productivity. In order to answer our research question, we carried out an experiment in a Spanish Software House. The results suggest that TDD improves the unit testing but slows down the overall process."
Evaluating testing methods by delivered reliability,"Frankl, Phyllis G. and Hamlet, Richard G. and Littlewood, Bev and Strigini, Lorenzo",,"There are two main goals in testing software: (1) to achieve adequate quality (debug testing), where the objective is to probe the software for defects so that these can be removed, and (2) to assess existing quality (operational testing), where the objective is to gain confidence that the software is reliable. Debug methods tend to ignore random selection of test data from an operational profile, while for operational methods this selection is all-important. Debug methods are thought to be good at uncovering defects so that these can be repaired, but having done so they do not provide a technically defensible assessment of the reliability that results. On the other hand, operational methods provide accurate assessment, but may not be as useful for achieving reliability. This paper examines the relationship between the two testing goals, using a probabilistic analysis. We define simple models of programs and their testing, and try to answer the question of how to attain program reliability: is it better to test by probing for defects as in debug testing, or to assess reliability directly as in operational testing? Testing methods are compared in a model where program failures are detected and the software changed to eliminate them. The 'better' method delivers higher reliability after all test failures have been eliminated. Special cases are exhibited in which each kind of testing is superior. An analysis of the distribution of the delivered reliability indicates that even simple models have unusual statistical properties, suggesting caution in interpreting theoretical comparisons."
Evaluation of the cost of alternate mutation strategies,"Mathur, A.P. and Wong, W.E.",x (not found),
EvoSuite: automatic test suite generation for object-oriented software”,"Fraser, G. and Arcuri, A.",,"To find defects in software, one needs test cases that execute the software systematically, and oracles that assess the correctness of the observed behavior when running these test cases. This paper presents EvoSuite, a tool that automatically generates test cases with assertions for classes written in Java code. To achieve this, EvoSuite applies a novel hybrid approach that generates and optimizes whole test suites towards satisfying a coverage criterion. For the produced test suites, EvoSuite suggests possible oracles by adding small and effective sets of assertions that concisely summarize the current behavior; these assertions allow the developer to detect deviations from expected behavior, and to capture the current behavior in order to protect against future defects breaking this behavior."
Fault classes and error detection capability of specification-based testing,"Kuhn, D.R.",,"Some varieties of specification-based testing rely upon methods for generating test cases from predicates in a software specification. These methods derive various test conditions from logic expressions, with the aim of detecting different types of faults. Some authors have presented empirical results on the ability of specification-based test generation methods to detect failures. This article describes a method for cokmputing the conditions that must be covered by a test set for the test set to guarantee detection of the particular fault class. It is shown that there is a coverage hierarchy to fault classes that is consistent with, and may therefore explain, experimental results on fault-based testing. The method is also shown to be effective for computing MCDC-adequate tests."
Field-Exhaustive Testing”,"Ponzio, P. and Aguirre, N. and Frias, M. and Visser, W.",,"We present a testing approach for object oriented programs, which encompasses a testing criterion and an automated test generation technique. The criterion, that we call field-exhaustive testing, requires a user-provided limit n on the size of data domains, and is based on the idea of considering enough inputs so as to exhaustively cover the extension of class fields, within the limit n. Intuitively, the extension of a field f is the binary relation established between objects and their corresponding values for field f, in valid instances. Thus, a suite S is field-exhaustive if whenever a field f relates an object o with a value v (i.e., o.f = v) within a valid instance I of size bounded by n, then S contains at least one input I' covering such relationship, i.e., o must also be part of I', and o.f = v must hold in I'. Our test generation technique uses incremental SAT solving to produce small field-exhaustive suites: field-exhaustiveness can be achieved with a suite containing at most # F x n2 inputs, where # F is the number of fields in the class under test. We perform an experimental evaluation on two different testing domains drawn from the literature: implementations of data structures, and of a refactoring engine. The experiments show that field-exhaustive suites can be computed efficiently, and retain similar levels of code coverage and mutation killing as significantly larger bounded exhaustive and random suites, thus consuming a fraction of the cost of test execution compared to these automated testing approaches."
Foundations of Software Testing: Fundamental Algorithms and Techniques,"Mathur, A.P.",x (not found),
Generalized symbolic execution for model checking and testing”,"S. Khurshid, C. Păsăreanu and Visser, W.",,"Modern software systems, which often are concurrent and manipulate complex data structures must be extremely reliable. We present a novel framework based on symbolic execution, for automated checking of such systems. We provide a two-fold generalization of traditional symbolic execution based approaches. First, we define a source to source translation to instrument a program, which enables standard model checkers to perform symbolic execution of the program. Second, we give a novel symbolic execution algorithm that handles dynamically allocated structures (e.g., lists and trees), method preconditions (e.g., acyclicity), data (e.g., integers and strings) and concurrency. The program instrumentation enables a model checker to automatically explore different program heap configurations and manipulate logical formulae on program data (using a decision procedure). We illustrate two applications of our framework: checking correctness of multi-threaded programs that take inputs from unbounded domains with complex structure and generation of non-isomorphic test inputs that satisfy a testing criterion. Our implementation for Java uses the Java PathFinder model checker."
Generating test cases from formal specifications,"Toth, Kalman C. and Donat, Michael R. and Joyce, Jeffrey J.",,"This paper describes the possible process elements and benefits of applying “Formal Methods” to the specification and testing of software requirements. It is argued that the overall effort required to generate test cases can be significantly reduced by applying these methods. Ambiguities and inconsistencies are identified and removed from the specifications through the use of formal methods. This paper provides a sketch of a theoretic foundational for generating test cases from formalized software requirements specifications thereby reducing test development effort and providing developers and testers with a consistent interpretation of requirements. Preliminary work also supports the thesis that test case generation can be automated."
Gerard. xUnit test patterns: Refactoring test code,Meszaros,x (Book),
"Heuristics for Determining Equivalence of Program Mutations, ser. Department of Computer Science: Research report","Baldwin, D. and Sayward, F.",,"A mutant M of a program P is a program derived from P by making some well defined simple change in P. Some initial investigations on automatically detecting equivalent mutants of a program are presented. The idea is based on the observation that compiler optimization can be considered a process of altering a program to an equivalent but more efficient mutant of the program. Thus the inverse of compiler optimization techniques can be seen as, in essence, equivalent mutant detection."
Heuristics for determining equivalence of program mutations,"Baldwin, D. and Sayward, F.G.",,"A mutant M of a program P is a program derived from P by making some well defined simple change in P. Some initial investigations on automatically detecting equivalent mutants of a program are presented. The idea is based on the observation that compiler optimization can be considered a process of altering a program to an equivalent but more efficient mutant of the program. Thus the inverse of compiler optimization techniques can be seen as, in essence, equivalent mutant detection."
High performance software testing on SIMD machines,"E.W., A.P., V.J.",,"A method for high-performance, software testing, called mutant unification, is described. The method is designed to support program mutation on parallel machines based on the single instruction multiple data stream (SIMD) paradigm. Several parameters that affect the performance of unification have been identified and their effect on the time to completion of a mutation test cycle and speedup has been studied. Program mutation analysis provides an effective means for determining the reliability of large software systems and a systematic method for measuring the adequacy of test data. However, it is likely that testing large software systems using mutation is computation bound and prohibitive on traditional sequential machines. Current, implementations of mutation tools are unacceptably slow and are only suitable for testing relatively small programs. The proposed unification method provides a practical alternative to the current approaches. The method also opens up a new application domain for SIMD machines."
High-performance mutation testing,"Byoungju, C. and Mathur, A.P.",,"Testing a large software program is a time consuming operation. In addition to the time spent by the tester in identifying, locating, and correcting bugs, a significant amount of time is spent in the execution of the program under test and its instrumented or fault-induced variants, also known as mutants. When using mutation testing to achieve high reliability, there can be many such mutants. In this article, we show how a multiple instruction multiple data (MIMD) architecture can be exploited to obtain significant reductions in the total execution time of the mutants. We describe the architecture of the PM othra system, which is designed to provide the tester with a transparent interface to a parallel machine. Experimental results obtained on the Ncube/7 hypercube are presented. The near-linear speedups show the perfect match that exists between the software testing application and a local memory MIMD architecture typified by the Ncube/7 machine. The compilation bottleneck, which could have an adverse effect on the speedup, is illustrated by experimental results."
Higher order mutation testing,"Jia, Y. and Harman, M.",,"This paper introduces a new paradigm for Mutation Testing, which we call Higher Order Mutation Testing (HOM Testing). Traditional Mutation Testing considers only first order mutants, created by the injection of a single fault. Often these first order mutants denote trivial faults that are easily killed. Higher order mutants are created by the insertion of two or more faults. The paper introduces the concept of a subsuming HOM; one that is harder to kill than the first order mutants from which it is constructed. By definition, subsuming HOMs denote subtle fault combinations. The paper reports the results of an empirical study of HOM Testing using 10 programs, including several non-trivial real-world subjects for which test suites are available."
How to misuse code coverage,"Marick, B.",,"Code coverage tools measure how thoroughly tests exercise programs. I believe they are misused more often than they're used well. This paper describes common misuses in detail, then argues for a particular cautious approach to the use of coverage. There are other ways to measure the thoroughness of tests. See [Kaner96] for a list. These ways all fit under the umbrella term “test coverage.” My claims in this paper are specific to code coverage. To avoid tedious repetition of the phrase “code coverage,” I’ll follow common practice and use the shorthand term “coverage”. I’ll use the full phrase occasionally to remind you of the scope of the paper. Like code coverage itself, this paper is most useful to programmers testing their own code or to testers who read the source code while testing. It also describes coverage's relevance to the independent product tester (someone who doesn't look at the code) and to managers of developers and testers."
Improving automation in developer testing: State of the practice,"Xie, T.",,"Developer testing, a common step in software development, involves generating desirable test inputs and checking the behavior of the program unit under test during the execution of the test inputs. Existing industrial developer testing tools include various techniques to address challenges of generating desirable test inputs and checking the behavior of the program unit under test. This paper presents an overview of techniques implemented in industrial developer testing tools to address challenges in improving automation in developer testing. These techniques are summarized from two main aspects: test efficiency (e.g., with a focus on cost) and test effectiveness (e.g., with a focus on benefit)."
Improving logic-base testing,"Kaminski, G. and Amman, P. and Offutt, J.",,"Logic-based testers design tests from logical expressions that appear in software artifacts such as source code, design models, and requirements specifications. This paper presents three improvements to logic-based test design. First, in the context of mutation testing, we present fault hierarchies for the six relational operators. Applying the ROR mutation operator causes each relational operator to generate seven mutants per clause. The fault hierarchies show that only three of these seven mutants are needed. Second, we show how to bring the power of the ROR operator to logic-based test criteria such as the widely used Multiple Condition-Decision Coverage (MCDC) test criterion. Third, we present theoretical results supported by empirical data that show that the more recent coverage criterion of minimal-MUMCUT can find significantly more faults than MCDC. The paper has three specific recommendations: (1) Change the way the ROR mutation operator is defined in existing and future mutation systems. (2) Augment logic-based test criteria to incorporate relational operator replacement from mutation. (3) Replace the use of MCDC with minimal-MUMCUT, both in practice and in standards documents like FAA-DO178B."
Improving test suites via generated specifications,"Harder, Michael",,"This thesis presents a specification-based technique for generating, augmenting, and minimizing test suites. The technique is automatic but assumes the existence of a test case generator. The technique dynamically induces specifications from test suite executions. Test suites can be generated by adding cases until the induced specification stops changing. The resulting test suites have better fault detection than suites of the same size with 100% branch coverage. Augmenting an existing test suite, such as a code-covering suite, also increases its fault detection. Minimizing test suites while holding the generated specification constant compares favorably to previously-known techniques. These positive results can be explained by two insights, which the thesis also justifies experimentally. First, given an a priori specification (an oracle), the specification coverage of a test suite compares the suite's induced specification with the oracle. Experiments show that specification coverage is correlated with fault detection, even when test suite size and code coverage are held constant. Second, when tests are added at random to a suite, specification coverage increases rapidly, then levels off at a high value. Even without knowing the ideal specification that would be induced by all possible tests, it is possible to produce a specification very near that one. The thesis's test suite generation and augmentation technique increases the specification coverage of the test suite, but without knowing the oracle specification and without examining the code. In addition to improving fault detection, the technique generates a specification close to the oracle, which has many benefits in itself."
Inductive inference and software testing,"Hong, Patrick, John",,"The term ‘inductive inference’ denotes the process of hypothesizing a general rule from examples. It can be considered as the inverse process of program testing, which is a process of sampling the behaviour of a program and gathering confidence in the quality of the software from the samples. As one of the fundamental and ubiquitous components of intelligent behaviour, much effort has been spent on both the theory and practice of inductive inference as a branch of artificial intelligence. In this paper, software testing and inductive inference are reviewed to illustrate how the rich and solid theory of inductive inference can be used to study the foundations of software testing."
Is Branch Coverage a Good Measure of Testing Effectiveness?” in Empirical Software Engineering and Verification,"Wei, Y. and Meyer, B. and Oriol, M.",,"Most approaches to testing use branch coverage to decide on the quality of a given test suite. The intuition is that covering branches relates directly to uncovering faults. The empirical study reported here applied random testing to 14 Eiffel classes for a total of 2520 hours and recorded the number of uncovered faults and the branch coverage over time. For the tested classes, (1) random testing reaches 93% branch coverage (2) it exercises almost the same set of branches every time, (3) it detects different faults from execution to execution, (4) during the first 10 minutes of testing, while branch coverage increases rapidly, there is a strong correlation between branch coverage and the number of uncovered faults, (5) over 50% of the faults are detected at a time where branch coverage hardly changes, and the correlation between branch coverage and the number of uncovered faults is weak. These results provide evidence that branch coverage is not a good stopping criterion for random testing. They also show that branch coverage is not a good indicator for the effectiveness of a test suite."
Is mutation an appropriate tool for testing experiments? [software testing]”,"Andrews, J. and Briand, L. and Labiche, Y.",,"The empirical assessment of test techniques plays an important role in software testing research. One common practice is to instrument faults, either manually or by using mutation operators. The latter allows the systematic, repeatable seeding of large numbers of faults; however, we do not know whether empirical results obtained this way lead to valid, representative conclusions. This paper investigates this important question based on a number of programs with comprehensive pools of test cases and known faults. It is concluded that, based on the data available thus far, the use of mutation operators is yielding trustworthy results (generated mutants are similar to real faults). Mutants appear however to be different from hand-seeded faults that seem to be harder to detect than real faults."
Javalanche: efficient mutation testing for java,"Schuler, D. and Zeller, A.",,"To assess the quality of a test suite, one can use mutation testing - seeding artificial defects (mutations) into the program and checking whether the test suite finds them. Javalanche is an open source framework for mutation testing Java programs with a special focus on automation, efficiency, and effectiveness. In particular, Javalanche assesses the impact of individual mutations to effectively weed out equivalent mutants; it has been demonstrated to work on programs with up to 100,000 lines of code."
Jtest manuals version 4.5,Parasoft,x (User Manual),
Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs,"Cadar, C. and Dunbar, D. and Engler, D.",,"We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage -- on average over 90% per tool (median: over 94%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100% coverage on 31 of them. We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies."
Korat: Automated testing based on Java predicates”,"Boyapati, C. and Khurshid, S. and Marinov, D.",,"This paper presents Korat, a novel framework for automated testing of Java programs. Given a formal specification for a method, Korat uses the method precondition to automatically generate all (nonisomorphic) test cases up to a given small size. Korat then executes the method on each test case, and uses the method postcondition as a test oracle to check the correctness of each output.To generate test cases for a method, Korat constructs a Java predicate (i.e., a method that returns a boolean) from the method's pre-condition. The heart of Korat is a technique for automatic test case generation: given a predicate and a bound on the size of its inputs, Korat generates all (nonisomorphic) inputs for which the predicate returns true. Korat exhaustively explores the bounded input space of the predicate but does so efficiently by monitoring the predicate's executions and pruning large portions of the search space.This paper illustrates the use of Korat for testing several data structures, including some from the Java Collections Framework. The experimental results show that it is feasible to generate test cases from Java predicates, even when the search space for inputs is very large. This paper also compares Korat with a testing framework based on declarative specifications. Contrary to our initial expectation, the experiments show that Korat generates test cases much faster than the declarative framework."
Machine learning approach in mutation testing,"Strug, J. and Strug, B.",,"This paper deals with an approach based on the similarity of mutants. This similarity is used to reduce the number of mutants to be executed. In order to calculate such a similarity among mutants their structure is used. Each mutant is converted into a hierarchical graph, which represents the program’s flow, variables and conditions. On the basis of this graph form a special graph kernel is defined to calculate similarity among programs. It is then used to predict whether a given test would detect a mutant or not. The prediction is carried out with the help of a classification algorithm. This approach should help to lower the number of mutants which have to be executed. An experimental validation of this approach is also presented in this paper. An example of a program used in experiments is described and the results obtained, especially classification errors, are presented."
Mirror adaptive random testing,"T.Y., F.-C., R.G., S.P.",,"Recently, adaptive random testing (ART) has been introduced to improve the fault-detection effectiveness of random testing for non-point types of failure patterns. However, ART requires additional computations to ensure an even spread of test cases, which may render ART less cost-effective than random testing. This paper presents a new technique, namely mirror ART, to reduce these computations. It is an integration of the technique of mirroring and ART. Our simulation results clearly show that mirror ART does improve the cost-effectiveness of ART."
Model-based testing in practice,"Dalal, S.R. and Jain, A. and Karunanithi, N. and Leaton, J.M. and Lott, C.M. and Patton, G.C. and Horowitz, B.M.",,"Model-based testing is a new and evolving technique for generating a suite of test cases from requirements. Testers using this approach concentrate on a data model and generation infrastructure instead of hand-crafting individual tests. Several relatively small studies have demonstrated how combinatorial test generation techniques allow testers to achieve broad coverage of the input domain with a small number of tests. We have conducted several relatively large projects in which we applied these techniques to systems with millions of lines of code. Given the complexity of testing, the model-based testing approach was used in conjunction with test automation harnesses. Since no large empirical study has been conducted to measure efficacy of this new approach, we report on our experience with developing tools and methods in support of model-based testing. The four case studies presented here offer details and results of applying combinatorial test-generation techniques on a large scale to diverse applications. Based on the four projects, we offer our insights into what works in practice and our thoughts about obstacles to transferring this technology into testing organizations."
MuJava: a mutation system for Java,"Ma, Y.-S. and Offutt, J. and Kwon, Y.-R.",,"Mutation testing is a valuable experimental research technique that has been used in many studies. It has been experimentally compared with other test criteria, and also used to support experimental comparisons of other test criteria, by using mutants as a method to create faults. In effect, mutation is often used as a ``gold standard'' for experimental evaluations of test methods. Although mutation testing is powerful, it is a complicated and computationally expensive testing method. Therefore, automated tool support is indispensable for conducting mutation testing. This demo presents a publicly available mutation system for Java that supports both method-level mutants and class-level mutants. MuJava can be freely downloaded and installed with relative ease under both Unix and Windows. MuJava is offered as a free service to the community and we hope that it will promote the use of mutation analysis for experimental research in software testing."
Mujava: an automated class mutation system: Research articles,"Ma, Y.-S. and Offutt, J. and Kwon, Y.R.",,"Several module and class testing techniques have been applied to object-oriented (OO) programs, but researchers have only recently begun developing test criteria that evaluate the use of key OO features such as inheritance, polymorphism, and encapsulation. Mutation testing is a powerful testing technique for generating software tests and evaluating the quality of software. However, the cost of mutation testing has traditionally been so high that it cannot be applied without full automated tool support. This paper presents a method to reduce the execution cost of mutation testing for OO programs by using two key technologies, mutant schemata generation (MSG) and bytecode translation. This method adapts the existing MSG method for mutants that change the program behaviour and uses bytecode translation for mutants that change the program structure. A key advantage is in performance: only two compilations are required and both the compilation and execution time for each is greatly reduced. A mutation tool based on the MSG/bytecode translation method has been built and used to measure the speedup over the separate compilation approach. Experimental results show that the MSG/bytecode translation method is about five times faster than separate compilation."
Multithreaded java program test generation,"Edelstein, O. and Farchi, E. and Nir, Y. and Ratsaby, G. and Ur, S.",,"We describe ConTest, a tool for detecting synchronization faults in multithreaded Java™ programs. The program under test is seeded with a sleep( ), yield( ), or priority( ) primitive at shared memory accesses and synchronization events. At run time, ConTest makes random or coverage-based decisions as to whether the seeded primitive is to be executed. Thus, the probability of finding concurrent faults is increased. A replay algorithm facilitates debugging by saving the order of shared memory accesses and synchronization events."
Mutant unification for improved vectorization,"Mathur, A.P. and Krauser, E.W.",x (not found),
Mutation 2000: Uniting the Orthogonal”. English. In: Mutation Testing for the New Century,"Offutt, A. and Untch, R.",,"Mutation testing is a powerful, but computationally expensive, technique for unit testing software. This expense has prevented mutation from becoming widely used in practical situations, but recent engineering advances have given us techniques and algorithms for significantly reducing the cost of mutation testing. These techniques include a new algorithmic execution technique called schema-based mutation, an approximation technique called weak mutation, a reduction technique called selective mutation, heuristics for detecting equivalent mutants, and algorithms for automatic test data generation. This paper reviews experimentation with these advances and outlines a design for a system that will approximate mutation, but in a way that will be accessible to everyday programmers. We envision a system to which a programmer can submit a program unit and get back a set of input/output pairs that are guaranteed to form an effective test of the unit by being close to mutation adequate. We believe this system could be efficient enough to be adopted by leading-edge software developers. Full automation in unit testing has the potential to dramatically change the economic balance between testing and development, by reducing the cost of testing from the major part of the total development cost to a small fraction."
"Mutation 2000: Uniting the orthogonal,” in Mutation testing for the new century","Offutt, A.J. and Untch, R.H.",,"Mutation testing is a powerful, but computationally expensive, technique for unit testing software. This expense has prevented mutation from becoming widely used in practical situations, but recent engineering advances have given us techniques and algorithms for significantly reducing the cost of mutation testing. These techniques include a new algorithmic execution technique called schema-based mutation, an approximation technique called weak mutation, a reduction technique called selective mutation, heuristics for detecting equivalent mutants, and algorithms for automatic test data generation. This paper reviews experimentation with these advances and outlines a design for a system that will approximate mutation, but in a way that will be accessible to everyday programmers. We envision a system to which a programmer can submit a program unit and get back a set of input/output pairs that are guaranteed to form an effective test of the unit by being close to mutation adequate. We believe this system could be efficient enough to be adopted by leading-edge software developers. Full automation in unit testing has the potential to dramatically change the economic balance between testing and development, by reducing the cost of testing from the major part of the total development cost to a small fraction."
Mutation Analysis of Program Test Data”. AAI8025191,"Budd, T.",,"The testing of a computer programs is an inductive process whereby the execution of a program on a large number of different inputs causes our belief in its correctness to be increased. Unfortunately we know that sheer numbers of test inputs are not enough, and we need a method that differentiates important test cases from the vast majority of totally uninteresting ones. This thesis analyzes one such method, called mutation analysis. Mutation analysis asserts that those test cases are important which differentiate, in the sense of being correctly processed by one and incorrectly processed by the other, the original program from programs very similar in structure and meaning. These alternative programs are called mutants of the original. The power of this method is further increased by two observations: the coupling effect, which asserts that complex errors can often be detected by the analysis of a small set of simple alternatives; and the competent programmer hypothesis, which asserts that most programs are, when they reach the stage of development considered here, a close approximation to being correct. In this thesis the mutation analysis method is first described in very general terms. The thesis then pursues two very different directions: The first is to give formal meanings to the terms 'mutants,' 'errors,' 'coupling effect,' and 'competent programmer' and prove in a restricted programming domain a theorem concerning the coupling of simple and complex errors. Several results of this nature are proved for decision tables and for a set of linear recursive LISP programs. The second direction is to study a realistic programming language and to ask whether in a statistical sense the coupling effect occurs. A system to implement mutation analysis for FORTRAN programs is described and compared to other testing methods. Several further studies using this system are described, including analyses of the system's error-detection capabilities, the machine and human resources it requires, and difficulties involved in using it. The last includes the problem of deciding whether a program and its mutant are computationally equivalent. The thesis concludes with a summary and a discussion of five possible areas for future research."
Mutation Analysis: An Industrial Experiment”,"Parsai, A. and Soetens, Q.D. and Demeyer, S.",,"In order to assess the ability of a test suite to catch bugs, a quality metric is needed which can simulate realistic situations. Mutation analysis provides this metric with a reliable and repeatable approach. However, because of the computationally intensive nature of mutation analysis and the difficulties in applying such a technique to complex systems, it has not been widely adopted in industry. This study aims to determine the feasibility of using this technique on an industrial case, and to find out if the information gathered by this method is worth the performance costs."
Mutation Testing Strategies: A Collateral Approach,"Papadakis, M. and Malevris, N. and Kintis, M.",,"Mutation Testing is considered to be one of the most powerful techniques for unit testing and at the same time one of the most expensive. The principal expense of mutation is the vast number of imposed test requirements, many of which cannot be satisfied. In order to overcome these limitations, researchers have proposed many cost reduction techniques, such as selective mutation, weak mutation and a novel approach based on mutant combination, which combines first order mutants to generate second order ones. An experimental comparison involving weak mutation, strong mutation and various proposed strategies was conducted. The experiment shows that all proposed approaches are quite effective in general as they result in high collateral coverage of strong mutation (approximately 95%), while recording remarkable effort savings. Additionally, the results suggest that some of the proposed approaches are more effective than others making it possible to reduce the mutation testing application cost with only a limited impact on its effectiveness."
Mutation analysis,"Acree, A.T. and Budd, T.A. and DeMillo, R.A. and Lipton, R.J. and Sayward, F.G.",,"A new Type of software test, called mutation analysis, is introduced. A method of applying mutation analysis is described, and the design of several existing automated systems for applying mutation analysis to Fortran and Cobol programs is sketched. These systems have been the means for preliminary studies of the efficiency of mutation analysis and of the relationship between mutation and other systematic testing techniques. The results of several experiments to determine the effectiveness of mutation analysis are described, and examples are presented to illustrate the way in which the technique can be used to detect a wide class of errors, including many previously defined and studied in the literature. Finally, a number of empirical studies are suggested, the results of which may add confidence to the outcome of the mutation analysis of a program."
Mutation analysis of program test data,"Budd, T.A.",,"The testing of a computer programs is an inductive process whereby the execution of a program on a large number of different inputs causes our belief in its correctness to be increased. Unfortunately we know that sheer numbers of test inputs are not enough, and we need a method that differentiates important test cases from the vast majority of totally uninteresting ones. This thesis analyzes one such method, called mutation analysis. Mutation analysis asserts that those test cases are important which differentiate, in the sense of being correctly processed by one and incorrectly processed by the other, the original program from programs very similar in structure and meaning. These alternative programs are called mutants of the original. The power of this method is further increased by two observations: the coupling effect, which asserts that complex errors can often be detected by the analysis of a small set of simple alternatives; and the competent programmer hypothesis, which asserts that most programs are, when they reach the stage of development considered here, a close approximation to being correct."
Mutation analysis of program test data[ph. d. thesis,"Budd, T.A.",x (duplicate),
Mutation analysis of relational database schemas,"Wright, C.",,"The schema is the key artefact used to describe the structure of a relational database, specifying how data will be stored and the integrity constraints used to ensure it is valid. It is therefore surprising that to date little work has addressed the problem of schema testing, which aims to identify mistakes in the schema early in software development. Failure to do so may lead to critical faults, which may cause data loss or degradation of data quality, remaining undetected until later when they will prove much more costly to fix. This thesis explores how mutation analysis – a technique commonly used in software testing to evaluate test suite quality – can be applied to evaluate data generated to exercise the integrity constraints of a relational database schema. By injecting faults into the constraints, modelling both faults of omission and commission, this enables the fault-finding capability of test suites generated by different techniques to be compared. This is essential to empirically evaluate further schema testing research, providing a means of assessing the effectiveness of proposed techniques. To mutate the integrity constraints of a schema, a collection of novel mutation operators are proposed and implementation described. These allow an empirical evaluation of an existing data generation approach, demonstrating the effectiveness of the mutation analysis technique and identifying a configuration that killed 94% of mutants on average. Cost-effective algorithms for automatically removing equivalent mutants and other ineffective mutants are then proposed and evaluated, revealing a third of mutation scores to be mutation adequate and reducing time taken by an average of 7%. Finally, the execution cost problem is confronted, with a range of optimisation strategies being applied that consistently improve efficiency, reducing the time taken by several hours in the best case and as high as 99% on average for one DBMS."
Mutation analysis using program schemata,"Untch, R. and Offutt, A.J. and Harrold, M.J.",,"Mutation analysis is a powerful technique for assessing and improving the quality of test data used to unit test software. Unfortunately, current automated mutation analysis systems suffer from severe performance problems. This paper presents a new method for performing mutation analysis that uses program schemata to encode all mutants for a program into one metaprogram, which is subsequently compiled and run at speeds substantially higher than achieved by previous interpretive systems. Preliminary performance improvements of over 300% are reported. This method has the additional advantages of being easier to implement than interpretive systems, being simpler to port across a wide range of hardware and software platforms, and using the same compiler and run-time support system that is used during development and/or deployment."
Mutation clustering,"Hussain, S.",,"Mutation testing, a type of white box testing is one of the most important and powerful testing techniques, which guarantees to improve the software quality. This form of testing deals with mutating parts of the program intentionally and then detecting them. The purpose is not to find the faults but to generate an effective test suite, which can detect all the faults in the program. Mutation testing, in spite of being effective and most powerful, is not widely used in software engineering. Basically because of high computational cost associated with it. The computational cost is due to too many mutants for even small programs. We have experimented with different programs of variable sizes, and was able to come up with the solution to the problem. We have tried to reduce the computational cost of the mutation testing, reducing the number of the mutants by clustering. K-means clustering algorithm and agglomerative hierarchical clustering algorithm are implemented to cluster the mutants. Thereby, reducing the size of mutants by selecting one mutant from eacßh cluster. The outcome of the results shows that the test set generated from the clusters are more efficient, having a mutation score of 100%, than the test set generated from the random mutants. This report elaborates the experimental steps and results."
Mutation operators for UML Class Diagrams,"Granda, M.F. and Condori-Fernández, N. and Vos, T.E.J. and Pastor, O.",,"Mutation Testing is a well-established technique for assessing the quality of test cases by checking how well they detect faults injected into a software artefact (mutant). Using this technique, the most critical activity is the adequate design of mutation operators so that they reflect typical defects of the artefact under test. This paper presents the design of a set of mutation operators for Conceptual Schemas (CS) based on UML Class Diagrams (CD). In this paper, the operators are defined in accordance with an existing defects classification for UML CS and relevant elements identified from the UML-CD meta-model. The operators are subsequently used to generate first order mutants for a CS under test. Finally, in order to analyse the usefulness of the mutation operators, we measure some basic characteristics of mutation operators with three different CSs under test."
Mutation operators for cognitive agent programs,"Savarimuthu, S. and Winikoff, M.",,"Testing multi-agent systems is a challenge, since by definition such systems are distributed, and are able to exhibit autonomous and flexible behaviour. One specific challenge in testing agent programs is developing a collection of tests (a 'test suite') that is adequate for testing a given agent program. This requires a way of assessing the adequacy of a test suite. A well-established technique for assessing test suite adequacy is the use of mutation testing, where a test suite is assessed in terms of its ability to distinguish a program from its variants ('mutants'). However, work in this area has focussed largely on the mutation of procedural and object-oriented languages. This paper proposes a set of (systematically derived) mutation operators for AgentSpeak."
Mutation testing for Java based on model-driven development (in spanish,"González, A. and Luna, C. and Bressan, G.",,"This article presents an implementation, based on model-driven development, that supports mutation testing techniques for the evaluation of test cases. The mutation of the code is carried out through a process of model transformations that starts with a transformation of a JAVA program to a representation of it in XMI, which satisfies the requirements of the JAVA metamodel. Later, mutation rules are applied to the model by means of a transformation, model by model, to generate a mutated version of the original program. Finally, JAVA code mutated again through a transformation, model to text, defined with MOF2Text. This last version is the one used to experiment with the different test cases. The main contribution of this work is the proposal of a mutation mechanism of JAVA programs that makes use of existing standards and tools in the context of model-driven development."
Mutation testing from probabilistic and stochastic finite state machines,"Hierons, R.M. and Merayo, M.G.",,"Specification mutation involves mutating a specification, and for each mutation a test is derived that distinguishes the behaviours of the mutated and original specifications. This approach has been applied with finite state machine based models. This paper extends mutation testing to finite state machine models that contain non-functional properties. The paper describes several ways of mutating a finite state machine with probabilities (PFSM) or stochastic time (PSFSM) attached to its transitions and shows how we can generate test sequences that distinguish between such a model and its mutants. Testing then involves applying each test sequence multiple times, observing the resultant behaviours and using results from statistical sampling theory in order to compare the observed frequency and execution time of each output sequence with that expected."
Mutation testing of software using MIMD computer,"Offutt, A.J. and Pargas, R.P. and Fichter, S.V. and Khambekar, P.K.",,"Mutation testing is a fault-based method for testing software that is computationally expensive. Mothra is an interpreter-based mutation testing system that is centered around an interpreter. This paper presents a parallel implementation of Mothra's interpreter on a MIMD machine. The parallel interpreter, HyperMothra, is implemented on a sixteen processor Intel iPSC/2 hypercube. Our goal was to demonstrate that the expense of software testing schemes such as mutation can be reduced by using parallel processing, and we demonstrate this by measuring the performance gains of the parallel interpreter over the Mothra interpreter. Results are presented using ten test programs, three different static work distribution schemes, and various numbers of processors. On our test programs, we found that our parallel interpreter achieved almost linear speedup over Mothra's sequential interpreter. With larger, faster high-performance computers available, mutation testing can be done at signicantly less expense."
Mutation testing of software using a MIMD computer,"Offutt, A.J. and Pargas, R.P. and Fichter, S.V. and Khambekar, P.K.",,"Mutation testing is a fault-based method for testing software that is computationally expensive. Mothra is an interpreter-based mutation testing system that is centered around an interpreter. This paper presents a parallel implementation of Mothra's interpreter on a MIMD machine. The parallel interpreter, HyperMothra, is implemented on a sixteen processor Intel iPSC/2 hypercube. Our goal was to demonstrate that the expense of software testing schemes such as mutation can be reduced by using parallel processing, and we demonstrate this by measuring the performance gains of the parallel interpreter over the Mothra interpreter. Results are presented using ten test programs, three different static work distribution schemes, and various numbers of processors. On our test programs, we found that our parallel interpreter achieved almost linear speedup over Mothra's sequential interpreter. With larger, faster high-performance computers available, mutation testing can be done at signicantly less expense."
Mutation-based fuzzing,"Zeller, A. and Gopinath, R. and Böhme, M. and Fraser, G. and Holler, C.",x (not found),
Mutatis mutandis: Evaluating DBMS test adequacy with mutation testing,"Bowman, I.T.",,"Testing consumes significant human and machine resources, especially for large, complex systems such as database servers. While a variety of testing approaches have been proposed to improve the efficiency of the testing process, it is difficult to evaluate these approaches. Mutation testing has been proposed as a way to assess the adequacy of a test suite, assigning a score that can be used to compare testing approaches. While promising, serious obstacles appear to prevent mutation testing with large software systems. Recent advances in mutation testing have scaled to medium-sized programs of around 100,000 lines of code but to our knowledge there are no reported studies working with large systems with millions of lines of code and other features of database systems that complicate testing. In this paper we explore using mutation testing on a database server to evaluate its suitability for comparing test suites or testing approaches."
On mutation,"Acree, A.T.",,"Program Mutation is a method for testing computer programs which is effective at uncovering errors and is less expensive to apply than other techniques. Working mutation systems have demonstrated that mutation analysis can be performed at an attractive cost on realistic programs. In this work, the effectiveness of the method is studied by experiments with programs in the target application spaces."
On mutation and data flow,"Wong, W.E.",,"Several researchers have reported results based on comparisons among data flow adequacy criteria. However, there is a lack of such comparisons between mutation and data flow. In the first part of this dissertation, we report experiments to compare the relative strength, cost, and fault detection effectiveness of mutation, its variants, and data flow based adequacy criteria. The results of these experiments can benefit a tester in selecting an adequacy criterion to construct and/or evaluate a test set under different time, budget, and criticality constraints. In spite of the empirically demonstrated superiority of mutation over the path-oriented testing strategies in fault detection, it is not used in practice primarily because of its high operational cost. In the second part of this dissertation, we propose alternate mechanisms to improve the performance of mutation testing. Results from an empirical study to evaluate these, mechanisms favor the use of mutation, for example, to test safety-critical parts of a software. It is often impossible to run all test cases generated to satisfy a software’s release criterion during regression testing. This inspired us to explore how regression testing can be conducted economically and effectively. In the third part of this dissertation, we examine the effect of test set minimization on the fault detection capability of data flow criteria. An answer to this question provides guidelines to a tester on how to select a representative subset of test cases from a test suite."
On redundant mutants and strong mutation,"Lindström, B. and Márki, A.",,"This study evaluates a theory of subsumption relations among mutants created by the ROR mutation operator, thus making most of these mutants redundant. A redundant mutant can be skipped during mutation analysis without decreasing the quality of the resulting test suite. This theory is interesting since mutation testing is computationally expensive and the theory states that the set of ROR mutants can be reduced by 57%. The reduced set of ROR mutants has therefore, been used in several recent studies. However, we provide proof that this theory do not hold for strong mutation and that part of the theory is incorrect. The theory itself has to our knowledge, never before been evaluated empirically. By finding counter examples, we prove that a test suite, which is 100% adequate for the non-redundant ROR mutants might not be 100% adequate for the mutants, which are supposed to be redundant. The subsumption relations do not hold for strong mutation. We have also proved that more than one top-level mutant can be detected by the same test. This should not be possible according to the theory. Hence, this part of the theory is incorrect, independent of strong or weak mutation. Our findings are important since strong mutation is frequently used to evaluate test suites and testing criteria. Just as redundant mutants can give an overestimation of the mutation score for a test suite, using the reduced set can give an underestimation. Results reported from such studies should therefore, be accompanied by information on whether the reduced or complete set of ROR was used and if the researchers used strong or weak mutation."
On strong mutation and subsuming mutants. IEEE workshop on mutation analysis (mutation 2016,"Lindstrm, B. and Mrki, A.",,"Mutation analysis is a powerful technique for software testing but it is also known to be computationally expensive. The main reason for the high computational cost is that many of the mutants are redundant and thus, do not contribute to the quality of the test suite. One of the most promising approaches to avoid producing redundant mutants is to identify subsumption relations among mutants, preferably before these are generated. Such relations have for example, been identified at an operator level for mutants created by the ROR operator. This reduced set of non-redundant mutants has been used in several recent studies and is also the default option in at least one mutation testing tool that supports strong mutation. This raises questions on whether the identified subsumption relations between the mutants hold in a context of strong mutation or variants of weak mutation that require some limited error propagation (firm mutation). We have conducted an experimental study to investigate the subsumption relations in the context of strong or firm mutation. We observed that it is possible to create a test suite that is 100% adequate for the reduced set of mutants while not being 100% adequate for the complete set. This shows that the subsumption relations do not hold for strong or firm mutation. We provide several examples on this behavior and discuss the root causes. Our findings are important since strong and firm mutation both are frequently used to evaluate test suites and testing criteria. The choice of whether to use a reduced set of mutants or an entire set should however, not be made without consideration of the context in which they are used (i.e., strong, firm or weak mutation) since the subsumption relations between ROR mutants do not hold for strong or firm mutation. Just as redundant mutants can give an overestimation of the mutation score for a test suite, using the reduced set of mutants can give an underestimation if used together with strong or firm mutation. Results reported from such studies should therefore, be accompanied by information on whether the reduced or complete set of mutants was used and if the researchers used strong, firm or weak mutation."
Pairwise testing in the real world: Practical extensions to test-case scenarios,"Czerwonka, J.",,"Pairwise testing has become an indispensable tool in a software tester’s toolbox. This article pays special attention to usability of the pairwise-testing technique. In particular, it focuses on ways in which the pure pairwise-testing approach must be modified to become practically applicable, and on the features that tools must offer to support the tester who is trying to use pairwise testing in practice."
Palus: A hybrid automated test generation tool for Java,"Zhang, S.",,"In object-oriented programs, a unit test often consists of a sequence of method calls that create and mutate objects. It is challenging to automatically generate sequences that are legal and behaviorally-diverse, that is, reaching as many different program states as possible. This paper proposes a combined static and dynamic test generation approach to address these problems, for code without a formal specification. Our approach first uses dynamic analysis to infer a call sequence model from a sample execution, then uses static analysis to identify method dependence relations based on the fields they may read or write. Finally, both the dynamically-inferred model (which tends to be accurate but incomplete) and the statically-identified dependence information (which tends to be conservative) guide a random test generator to create legal and behaviorally-diverse tests. Our Palus tool implements this approach. We compared it with a pure random approach, a dynamic-random approach (without a static phase), and a static-random approach (without a dynamic phase) on six popular open-source Java programs. Tests generated by Palus achieved 35% higher structural coverage on average. Palus is also internally used in Google, and has found 22 new bugs in four well-tested products."
Pit mutation testing,"Coles, H.",x (not found),
Pit mutation testing: Mutators,"Coles, H.",x (not found),
Predicting Test Suite Effectiveness for Java Programs,"Inozemtseva, L.",,"The coverage of a test suite is often used as a proxy for its effectiveness. However, previous studies that investigated the influence of code coverage on test suite effectiveness have failed to reach a consensus about the nature and strength of the relationship between these test suite characteristics. Moreover, many of the studies were done with small or synthetic programs, making it unclear that their results generalize to larger programs. In addition, some of the studies did not account for the confounding influence of test suite size. We have extended these studies by evaluating the relationship between test suite size, block coverage, and effectiveness for large Java programs. Our test subjects were four Java programs from different application domains: Apache POI, HSQLDB, JFreeChart, and Joda Time. All four are actively developed open source programs; they range from 80,000 to 284,000 source lines of code. For each test subject, we generated between 5,000 and 7,000 test suites by randomly selecting test methods from the program's entire test suite. The suites ranged in size from 3 to 3,000 methods. We used the coverage tool Emma to measure the block coverage of each suite and the mutation testing tool Javalanche to evaluate the effectiveness of each suite. We found that there is a low correlation between block coverage and effectiveness when the number of tests in the suite is controlled for. This suggests that block coverage, while useful for identifying under-tested parts of a program, should not be used as a quality target because it is not a good indicator of test suite effectiveness."
Procedures for reducing the size of coverage-based test sets,"Offutt, J. and Pan, J. and Voas, J.M.",,"This paper addresses the problem of reducing the size of test sets for regression testing and test output inspection. Since regression testing requires the execution of some, and in the worst case, all test cases, reducing the number of tests can have a large benefit. Additionally, testers generally have to examine the output of each test case, both during initial and regression testing. Since this is done by hand, reducing the number of outputs that need to be examined can reduce the cost of testing. We observe that for mutation-based test sets, the order in which the test cases are executed impacts the size of the test sets. This paper presents several strategies for selecting a smaller number of test cases by reordering the test tests. We illustrate our technique using a proof-of-concept empirically study using mutation testing, achieving approximately a 33% reduction in size, and a corresponding reduction in the cost of regression testing, with a cost of only one extra run of the test case set. We suggest that these results should be extendable to apply to any test strategy that includes a quantifiable measure of test case effectiveness, such as data flow testing and branch testing, and try it with statement coverage with positive results."
Property based coverage criterion,"Fadi, Wes",,"Coverage metrics answer the question of whether we adequately checked a given software artifact. For example, statement coverage metrics measure how many and how often lines of code were executed. Path coverage metrics measure the frequency of execution of interleaving branches of code. In recent years, researchers have introduced several effective static analysis techniques for checking software artifacts. Consequently, more and more developers started embedding properties in code. Also, some techniques and tools emerged that automatically infer system properties where they do not explicitly exist. We hypothesize that it is often more effective to evaluate test suites based on their coverage of system properties than than of structural program elements. In this paper, we present a novel coverage criterion and metrics that evaluate test cases with respect to their coverage of properties, and measure the completeness of the properties themselves."
Proteum–A tool for the assessment of test adequacy for C programs,"Delamaro, M.E. and Maldonado, J.C.",,"This technical report presents the main features of Proteum (Program Testing Using Mutants), a testing tool that supports Mutation Analysis criterion. Proteum can be configured for testing programs in many procedural programming languages. This guide reports the version 1.1 - C that works with the C language on SUN workstations, under OPENWINDOWS environment. Proteum has been developed at University of São Paulo (USP), São Carlos, SP, Brazil [DEL93] and used in teaching and researching activities at USP and at SERC/Purdue University."
QuickCheck: a lightweight tool for random testing of Haskell programs”,"Claessen, K. and Hughes, J.",,"Quick Check is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test."
Random testing,"Hamlet, D.",,"In computer science, originally in its rarefied offshoots centered around artificial-intelligence laboratories at Stanford and MIT, the adjective “random” is slang with a number of derogatory connotations ranging from “assorted, various” to “not well organized” or “gratuitously wrong”. “Random testing” of a program in this sense describes testing badly or hastily done, the opposite of systematic testing such as functional testing or structural testing. This slang colloquial meaning, which might be rendered “haphazard testing” in normal parlance, is probably the common one, as in the sentence “Random testing, of course, is the most used and least useful method.” In contrast, the technical, mathematical meaning of “random testing” refers to an explicit lack of “system” in the choice of test data, so that there is no correlation among different tests. If the technical meaning contrasts “random” with “systematic,” it is in the sense that fluctuations in physical measurements are random (unpredictable or chaotic) vs. systematic (causal or lawful). It desirable to be “unsystematic” on purpose in selecting test data for a program. Because there are efficient methods of selecting random points algorithmically, by computing pseudorandom numbers; thus a vast number of tests can be easily defined. Also statistical independence among test points allows statistical prediction of significance in the observed results. In this article it will be seen that point (1) may be compromised because the required result of an easily generated test is not so easy to generate and (2) is the more important quality of random testing, both in practice and for the theory of software testing. To make an analogy with the case of physical measurement, it is only random fluctuations that can be “averaged out” to yield an improved measurement over many trials; systematic fluctuations might in principle be eliminated, but if their cause (or even their existence) is unknown, they forever invalidate the measurement. The analogy is better than it seems; in program testing, with systematic methods, we know what we are doing, but not what it means; only by giving up all systematization can the significance of testing be known."
Reachability testing of concurrent programs,"Y., R.H.",,"One approach to testing concurrent programs, called reachability testing, generates synchronization sequences automatically and on-the-fly, without constructing any static models. In this paper, we present a general execution model for concurrent programs that allows reachability testing to be applied to several commonly used synchronization constructs. We also present a new method for performing reachability testing. This new method guarantees that every partially ordered synchronization sequence will be exercised exactly once without having to save any sequences that have already been exercised. We describe a prototype reachability testing tool called RichTest and report some empirical results, including a comparison between RichTest and a partial order reduction-based tool called VeriSoft. RichTest performed significantly better for the programs in our study"
Refactoring test code,"Deursen, A. and Moonen, L. and Bergh, A. and Kok, G.",," 	Two key aspects of extreme programming (XP) are unit testing and merciless refactoring. Given the fact that the ideal test code / production code ratio approaches 1:1, it is not surprising that unit tests are being refactored. We found that refactoring test code is different from refactoring production code in two ways: (1) there is a distinct set of bad smells involved, and (2) improving test code involves additional test-specific refactorings. To share our experiences with other XP practitioners, we describe a set of bad smells that indicate trouble in test code, and a collection of test refactorings to remove these smells."
Regression test selection for java software,"Harrold, M.J. and Jones, J.A. and Li, T. and Liang, D. and Orso, A. and Pennings, M. and Sinha, S. and Spoon, S.A. and Gujarathi, A.",,"Regression testing is applied to modified software to provide confidence that the changed parts behave as intended and that the unchanged parts have not been adversely affected by the modifications. To reduce the cost of regression testing, test cases are selected from the test suite that was used to test the original version of the software---this process is called regression test selection. A safe regression-test-selection algorithm selects every test case in the test suite that may reveal a fault in the modified software. Safe regression-test-selection technique that, based on the use of a suitable representation, handles the features of the Java language. Unlike other safe regression test selection techniques, the presented technique also handles incomplete programs. The technique can thus be safely applied in the (very common) case of Java software that uses external libraries of components; the analysis of the external code is note required for the technique to select test cases for such software. The paper also describes RETEST, a regression-test-selection algorithm can be effective in reducing the size of the test suite."
Regression testing,"Kapfhammer, G.M.",,"Regression testing techniques execute a test suite whenever the addition of defect fixes or new functionality changes the program under test. The repeated execution of a test suite aims to establish a confidence in the correctness of the software application and identify defects that were introduced by the program modifications. Industry experiences suggest that regression testing often improves the quality of the application under test. However, testing teams may not always perform regression testing because the frequent execution of the tests often incurs high time and space overheads. Test suite selection techniques try to reduce the cost of testing by running a subset of the tests, such as those that execute the modified source code, in order to ensure that the updated program still operates correctly. Alternatively, reduction methods decrease testing time overheads by discarding the tests that redundantly cover the test requirements. Approaches to test suite prioritization reorder the test cases in an attempt to maximize the rate at which the tests achieve a testing goal such as code coverage. After describing a wide variety of metrics for empirically evaluating different regression testing methods, this chapter considers the efficiency and effectiveness trade-offs associated with these techniques. The conclusion of this article summarizes the state-of-the-art in the field of regression testing and then offers suggestions for future work and resources for further study."
Scented since the beginning: On the diffuseness of test smells in automatically generated test code,"Giovanni, Fabio, Dario, Andrea, Harald C.",,"Software testing represents a key software engineering practice to ensure source code quality and reliability. To support developers in this activity and reduce testing effort, several automated unit test generation tools have been proposed. Most of these approaches have the main goal of covering as more branches as possible. While these approaches have good performance, little is still known on the maintainability of the test code they produce, i.e.,whether the generated tests have a good code quality and if they do not possibly introduce issues threatening their effectiveness. To bridge this gap, in this paper we study to what extent existing automated test case generation tools produce potentially problematic test code. We consider seven test smells, i.e.,suboptimal design choices applied by programmers during the development of test cases, as measure of code quality of the generated tests, and evaluate their diffuseness in the unit test classes automatically generated by three state-of-the-art tools such as Randoop, JTExpert, and Evosuite. Moreover, we investigate whether there are characteristics of test and production code influencing the generation of smelly tests. Our study shows that all the considered tools tend to generate a high quantity of two specific test smell types, i.e.,Assertion Roulette and Eager Test, which are those that previous studies showed to negatively impact the reliability of production code. We also discover that test size is correlated with the generation of smelly tests. Based on our findings, we argue that more effective automated generation algorithms that explicitly take into account test code quality should be further investigated and devised."
Sequential statistical procedures for approving test sets using mutation-based software testing,"Sahinoglu, M. and Spafford, E.H.",,"Mutation analysis is a well-studied method of measuring test-case adequacy. Mutation analysis involves the mutation of a program by introduction of a small syntactic change in the software. Existing test data sets are then executed against all these mutant programs. If the test data set is adequate for testing the original program, it will distinguish all of the incorrect mutant programs from the original program. As an ad-hoc procedure, a stopping criterion is conventionally based on a given 'Y% of the mutants to be distinguished' with a certain 'confidence level of X%' over a multiplicity of random test cases. Alternatively, we propose a Bayes sequential procedure for testing H 0 : p = p 1 (acceptable fraction of live mutants to demonstrate good quality) vs. HA : p = p 2 (unacceptable fraction of live mutants to demonstrate bad quality). This derives a sequential probability ratio testing (SPRT) that is the most economical sampling scheme with given prior probabilities, decision and sampling cost functions. The implementation of our proposed method on a sample program shows the cost effectiveness of the new technique as compared to the current, deterministic approach, which was not structured by statistical hypothesis testing. To appear in Proceedings of the IFIP Conference on Approving Software Products (ASP-90),Garmisch-Partenkirchen , Germany, 17 September 1990. Currently visiting Purdue University from Middle East Technical University"
Software Testing Techniques,"Beizer, B.",x (Book),
Software error analysis: A real case study involving real faults and mutations,"Daran, M. and Thévenod-Fosse, P.",,"The paper reports on a first experimental comparison of software errors generated by real faults and by 1st-order mutations. The experiments were conducted on a program developed by a student from the industrial specification of a critical software from the civil nuclear field. Emphasis was put on the analysis of errors produced upon activation of 12 real faults by focusing on the mechanisms of error creation, masking, and propagation up to failure occurrence, and on the comparison of these errors with those created by 24 mutations. The results involve a total of 3730 errors recorded from program execution traces: 1458 errors were produced by the real faults, and the 2272 others by the mutations. They are in favor of a suitable consistency between errors generated by mutations and by real faults: 85% of the 2272 errors due to the mutations were also produced by the real faults. Moreover, it was observed that although the studied mutations were simple faults, they can create erroneous behaviors as complex as those identified for the real faults. This lends support to the representativeness of errors due to mutations."
"Software testing and analysis: process, principles, and techniques","Pezze, M. and Young, M.",x (Book),
Specifying and testing software components using ADL,"Hayes, Roger and Sankar, Sriram",,"This paper presents a novel approach to unit testing of software components. This approach uses the specification language ADL, that is particularly well-suited for testing, to formally document the intended behavior of software components. Another related language, TDD, is used to systematically describe the test-data on which the software components will be tested. This paper gives a detailed overview of the ADL language, and a brief presentation of the TDD language. Some details of the actual test system are also presented, along with some significant results."
State Coverage: A Structural Test Adequacy Criterion for Behavior Checking Matching Checks to Definitions,"Koster, K. and Kao, D.",,"We propose a new language-independent, structural test adequacy criterion called state coverage. State coverage measures whether unit-level tests check the outputs and side effects of a program. State coverage differs in several respects from existing test adequacy criteria, such as code coverage and mutation adequacy. Unlike other coverage-based criteria, state coverage measures the extent of checks of program behavior. And unlike existing fault-based criteria such as mutation adequacy, state coverage has been designed to be readily automated and to present users with easily understood test inadequacy reports. An experiment showed strong positive correlations between the number of behavior checks and both state coverage and mutation adequacy."
State Coverage: Software Validation Metrics beyond code coverage - extended version,"Vanoverberghe, D. and Halleux, J.D. and Tillmann, N. and Piessens, F.",,"Currently, testing is still the most important approach to reduce the amount of software defects. Software quality metrics help to prioritize where additional testing is necessary by measuring the quality of the code. Most approaches to estimate whether some unit of code is sufficiently tested are based on code coverage, which measures what code fragments are exercised by the test suite. Unfortunately, code coverage does not measure to what extent the test suite checks the intended functionality. We propose state coverage, a metric that measures the ratio of state updates that are read by assertions with respect to the total number of state updates, and we present efficient algorithms to measure state coverage. Like code coverage, state coverage is simple to understand and we show that it is effective to measure and easy to aggregate. During a preliminary evaluation on several open-source libraries, state coverage helped to identify multiple unchecked properties and detect several bugs."
State coverage,"Ken, David",x (not found),
State coverage for the dynamic analysis of concurrent programs,"Sherman, E.",x (not found),
State coverage: a structural test adequacy criterion for behavior checking,"Koster, K. and Kao, D.",,"We propose a new language-independent, structural test adequacy criterion called state coverage. State coverage measures whether unit-level tests check the outputs and side effects of a program. State coverage differs in several respects from existing test adequacy criteria, such as code coverage and mutation adequacy. Unlike other coverage-based criteria, state coverage measures the extent of checks of program behavior. And unlike existing fault-based criteria such as mutation adequacy, state coverage has been designed to be readily automated and to present users with easily understood test inadequacy reports. An experiment showed strong positive correlations between the number of behavior checks and both state coverage and mutation adequacy."
Structural specification-based testing: Automated support and experimental evaluation,"Chang, Juei and Richardson, Debra J.",,"In this paper, we describe a testing technique, called structural specification-based testing (SST), which utilizes the formal specification of a program unit as the basis for test selection and test coverage measurement. We also describe an automated testing tool, called ADLscope, which supports SST for program units specified in Sun Microsystems’ Assertion Definition Language (ADL). ADLscope automatically generates coverage conditions from a program’s ADL specification. While the program is tested, ADLscope determines which of these conditions are covered by the tests. An uncovered condition exhibits aspects of the specification inadequately exercised during testing. The tester uses this information to develop new test data to exercise the uncovered conditions. We provide an overview of SST’s specification-based test criteria and describe the design and implementation of ADLscope. Specification-based testing is guided by a specification, whereby the testing activity is directly related to what a component under test is supposed to do, rather than what it actually does. Specification-based testing is a significant advance in testing, because it is often more straightforward to accomplish and it can reveal failures that are often missed by traditional code-based testing techniques. As an initial evaluation of the capabilities of specification-based testing, we conducted an experiment to measure defect detection capabilities, code coverage and usability of SST/ADLscope; we report here on the results."
Structural testing of concurrent programs,"Taylor, R.N. and Levine, D.L. and Kelly, C.D.",,"Although structural testing techniques are among the weakest available with regard to developing confidence in sequential programs, they are not without merit. The authors extend the notion of structural testing criteria to concurrent programs and propose a hierarchy of supporting structural testing techniques. Coverage criteria described include concurrency state coverage, state transition coverage and synchronization coverage. Requisite support tools include a static concurrency analyzer and either a program transformation system or a powerful run-time monitor. Also helpful is a controllable run-time scheduler. The techniques proposed are suitable for Ada or CSP-like languages. Best results are obtained for programs having only static naming of tasking objects."
Subsumption of condition coverage techniques by mutation testing,"Offutt, A.J. and Voas, J.M.",,"Condition coverage testing is a family of testing techniques that are based on the logical flow of control through a program. The condition coverage techniques include a variety of requirements, including that each statement in the program is executed and that each branch is executed. Mutation testing is a fault-based testing technique that is widely considered to be very powerful, and that imposes requirements on testing that include, and go beyond, many other techniques. In this paper, we consider the six common condition coverage techniques, and formally show that these techniques are subsumed by mutation testing, in the sense that if mutation testing is satisfied, then the condition coverage techniques are also satisfied. The fact that condition coverage techniques are subsumed by mutation has immediate practical significance because the extensive research that has already been done for mutation can be used to support condition coverage techniques, including automated tools for performing mutation testing and generating test cases."
Symbolic execution and program testing,"King, J.C.",,"This paper describes the symbolic execution of programs. Instead of supplying the normal inputs to a program (e.g. numbers) one supplies symbols representing arbitrary values. The execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. The difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. A particular system called EFFIGY which provides symbolic execution for program testing and debugging is also described. It interpretively executes programs written in a simple PL/I style programming language. It includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. A brief discussion of the relationship between symbolic execution and program proving is also included."
Symbolic execution for software testing in practice,"Cristian, Patrice, Sarfraz, Corina S., Koushik, Nikolai, Willem",,"We present results for the 'Impact Project Focus Area' on the topic of symbolic execution as used in software testing. Symbolic execution is a program analysis technique introduced in the 70s that has received renewed interest in recent years, due to algorithmic advances and increased availability of computational power and constraint solving technology. We review classical symbolic execution and some modern extensions such as generalized symbolic execution and dynamic test generation. We also give a preliminary assessment of the use in academia, research labs, and industry."
Symbolic execution for software testing: Three decades later,"Cadar, C. and Sen, K.",,"Recent years have witnessed a surge of interest in symbolic execution for software testing, due to its ability to generate high-coverage test suites and find deep errors in complex software applications. In this article, we give an overview of modern symbolic execution techniques, discuss their key challenges in terms of path exploration, constraint solving, and memory modeling, and discuss several solutions drawn primarily from the authors’ own work."
Teaching Mutation Testing using Gamification,"Rojas, J.M. and Fraser, G.",,"Software quality and testing are at the heart of software engineering, but they are not always at the heart of software engineering education. As a consequence, advanced techniques such as mutation testing are often neglected and do not become part of the standard repertoire of a graduate software engineer. We propose the use of gamification to teach mutation testing and to strengthen testing skills. We introduce Code Defenders, a mutation testing game, which can assist educators in delivering complex mutation testing concepts and is intended to make the learning experience more enjoyable and fruitful for students."
Test Driven Development: By Example,"Beck, K.",,"Policymakers and economist disagree about the impact of bank regulations on the distribution of income. In this paper, we test whether liberalizing restrictions on intra-state branching in the states of the United States from the mid-1970s to the mid-1990s intensified, ameliorated, or had no effect on the Gini coefficient of income distribution. Besides boosting average incomes, branch deregulation lowered income inequality. Furthermore, deregulation reduced income inequality among female wage and salary earners and among the self-employed."
Test case prioritization: An empirical study,"Rothermel, G. and Untch, R.H. and Chu, C. and Harrold, M.J.",,"Test case prioritization techniques schedule test cases for execution in an order that attempts to maximize some objective function. A variety of objective functions are applicable; one such function involves rate of fault detection-a measure of how quickly faults are detected within the testing process. An improved rate of fault detection during regression testing can provide faster feedback on a system under regression test and let debuggers begin their work earlier than might otherwise be possible. In this paper we describe several techniques for prioritizing test cases and report our empirical results measuring the effectiveness of these techniques for improving rate of fault detection. The results provide insights into the tradeoffs among various techniques for test case prioritization."
Test suite prioritization by interaction coverage,"Bryce, R.C. and Memon, A.M.",,"Event-driven software (EDS) is a widely used class of software that takes sequences of events as input, changes state, and outputs new event sequences. Managing the size of tests suites for EDS is difficult as the number of event combinations and sequences grow exponentially with the number of events. We propose a new testing technique that extends software interaction testing. Traditional software interaction testing systematically examines all t-way interactions of parameters for a program. This paper extends the notion to t-way interactions over sequences of events. The technique applies to many classes of software; we focus on that of EDS. As a proof-of-concept, we prioritize existing test suites for four GUI-based programs by t-way interaction coverage. We compare the rate of fault detection with that of several other prioritization criteria. Results show that prioritization by interaction coverage has the fastest rate of fault detection in half of our experiments, making the most impact when tests have high interaction coverage."
Test-Suite Augmentation for Evolving Software,"Raul, Pavan Kumar, Taweesup, Alessandro, Mary Jean",,"One activity performed by developers during regression testing is test-suite augmentation, which consists of assessing the adequacy of a test suite after a program is modified and identifying new or modified behaviors that are not adequately exercised by the existing test suite and, thus, require additional test cases. In previous work, we proposed MATRIX, a technique for test-suite augmentation based on dependence analysis and partial symbolic execution. In this paper, we present the next step of our work, where we (I) improve the effectiveness of our technique by identifying all relevant change-propagation paths, (2) extend the technique to handle multiple and more complex changes, (3) introduce the first tool that fully implements the technique, and (4) present an empirical evaluation performed on real software. Our results show that our technique is practical and more effective than existing test-suite augmentation approaches in identifying test cases with high fault-detection capabilities."
Testability explorer: using byte-code analysis to engineer lasting social changes in an organization’s software development process,"Hevery, M.",,"Testability Explorer is an open-source tool that identifies hard-to-test Java code. Testability Explorer provides a repeatable objective metric of "testability." This metric becomes a key component of engineering a social change within an organization of developers. The TE report provides actionable information to developers which can be used as (1) measure of progress towards a goal and (2) a guide to refactoring towards a more testable code-base."
Testability transformation,"Harman, M. and Hu, L. and Hierons, R. and Wegener, J. and Sthamer, H. and Baresel, A. and Roper, M.",,"A testability transformation is a source-to-source transformation that aims to improve the ability of a given test generation method to generate test data for the original program. We introduce testability transformation, demonstrating that it differs from traditional transformation, both theoretically and practically, while still allowing many traditional transformation rules to be applied. We illustrate the theory of testability transformation with an example application to evolutionary testing. An algorithm for flag removal is defined and results are presented from an empirical study which show how the algorithm improves both the performance of evolutionary test data generation and the adequacy level of the test data so-generated."
Testing context-aware middleware-centric programs: a data flow approach and an RFID-based experimentation,"Lu, H. and Chan, W. and Tse, T.",,"Pervasive context-aware software is an emerging kind of application. Many of these systems register parts of their context-aware logic in the middleware. On the other hand, most conventional testing techniques do not consider such kind of application logic. This paper proposes a novel family of testing criteria to measure the comprehensiveness of their test sets. It stems from context-aware data flow information. Firstly, it studies the evolution of contexts, which are environmental information relevant to an application program. It then proposes context-aware data flow associations and testing criteria. Corresponding algorithms are given. It uses a prototype testing tool to conduct experimentation on an RFID-based location sensing software running on top of context-aware middleware. The experimental results show that our approach is applicable, effective, and promising."
Testing first: emphasizing testing in early programming courses,"Marrero, W. and Settle, A.",,"The complexity of languages like Java and C++ can make introductory programming classes in these languages extremely challenging for many students. Part of the complexity comes from the large number of concepts and language features that students are expected to learn while having little time for adequate practice or examples. A second source of difficulty is the emphasis that object-oriented programming places on abstraction. We believe that by placing a larger emphasis on testing in programming assignments in these introductory courses, students have an opportunity for extra practice with the language, and this affords them a gentler transition into the abstract thinking needed for programming. In this paper we describe how we emphasized testing in introductory programming assignments by requiring that students design and implement tests before starting on the program itself. We also provide some preliminary results and student reactions."
Testing models and model transformations using classifying terms,"Hilken, F. and Gogolla, M. and Burgueño, L. and Vallecillo, A.",,"This paper proposes the use of equivalence partitioning techniques for testing models and model transformations. In particular, we introduce the concept of classifying terms, which are general OCL terms on a class model enriched with OCL constraints. Classifying terms permit defining equivalence classes, in particular for partitioning the source and target model spaces of the transformation, defining for each class a set of equivalent models with regard to the transformation. Using these classes, a model validator tool is able to automatically construct object models for each class, which constitute relevant test cases for the transformation. We show how this approach of guiding the construction of test cases in an orderly, systematic and efficient manner can be effectively used in combination with Tracts for testing both directional and bidirectional model transformations and for analyzing their behavior."
Testing real-time embedded software using uppaal-tron: an industrial case study,"Larsen, K.G. and Mikucionis, M. and Nielsen, B. and Skou, A.",,"UPPAAL-TRON is a new tool for model based online black-box conformance testing of real-time embedded systems specified as timed automata. In this paper we present our experiences in applying our tool and technique on an industrial case study. We conclude that the tool and technique is applicable to practical systems, and that it has promising error detection potential and execution performance."
Testing with respect to concerns,"Souter, A.L. and Shepherd, D. and Pollock, L.L.",,"Often the code regions that are assigned for a maintenance task do not follow the modularization of the original application program, but instead include parts of code from many different units scattered throughout the application. In this paper, we investigate an approach to testing which we call concern-based testing, which leverages existing tools to help software maintainers identify the relevant code for their assigned task, their concern. The main contribution is a demonstration of the possible savings in test suite execution overhead and the increased precision in coverage information that can be obtained for a software maintainer if testing tasks are performed with respect to concerns. Based on a concern graph representation of the concern, a framework for guiding selective instrumentation for scalable coverage analysis is also presented."
Testq: Exploring structural and maintenance characteristics of unit test suites,"Breugelmans, M. and Rompaey, B.V.",,"The increasing interest in unit testing in recent years has resulted in lots of persistent test code that has to co-evolve with production code in order to remain effective. Moreover, poor test design decisions, and complexity introduced during the course of evolution harm the maintenance of these test suites – making test cases harder to understand and modify. Literature about xUnit – the de facto family of unit testing frameworks – has a fairly clear set of anti-patterns (called test smells). In this paper we present TestQ , a tool that allows developers to (i) visually explore test suites and (ii) quantify test smelliness. We present the feature set of this tool as well as its architecture, and demonstrate its use on a C++ test suite of considerable size."
The Art of Application Performance Testing,"Molyneaux, I.",x (Book),
The Art of Unit Testing With Examples in .NET,"Osherove, R.",x (Book),
The Economics of Unit Testing,"Ellims, M. and Bridges, J. and Ince, D.C.",,"Conventional wisdom and anecdote suggests that testing takes between 30 to 50% of a project's effort. However testing is not a monolithic activity as it consists of a number of different phases such as unit testing, integration testing and finally system and acceptance test. Unit testing has received a lot of criticism in terms of the amount of time that it is perceived to take and its perceived costs. However it still remains an important verification activity being an effective means to test individual software components for boundary value behavior and ensure that all code has been exercised adequately. We examine the available data from three safety-related, industrial software projects that have made use of unit testing. Using this information we argue that the perceived costs of unit testing may be exaggerated and that the likely benefits in terms of defect detection are quite high in relation to those costs. We also discuss the different issues that have been found applying the technique at different phases of the development and using different methods to generate those tests. We also compare results we have obtained with empirical results from the literature and highlight some possible weakness of research in this area."
The Mothra Software Testing Environment,"DeMillo, R.A. and Spafford, E.H.",,"The value of software testing in the development of large software systems is well-documented. Unfortunately, the development and employment of an integrated test plan is often avoided due to the costs associated with testing. These costs include more than just capital expenses associated with obtaining test systems and software. They also include the time and effort involved in educating personnel in the use of the testing system, the time taken to run the tests, and the costs of rerunning the tests after errors are found and corrected. Furthermore, some forms of testing are difficult or impossible to run incrementally, and they produce results which may be difficult to use in correcting or enhancing the tested software. The MOTHRA Environment is an integrated set of tools and interfaces that support the planning, definition, preparation, execution, analysis and evaluation of tests of software systems. The support provided by MOTHRA is applicable from the earliest stages of software design and development through the progressively later stages of system integration, acceptance testing, operation and maintenance. MOTHRA has been designed to address some of the cost concerns mentioned above. Two primary design criteria, in particular, are significant in this regard. First, the MOTHRA interfaces-particularly user interfaces-are high-bandwidth. This allows us to present more information during testing and retesting. Coupled with proper design and integration with familiar displays, it should obviate the need for extensive training to use MOTHRA. Secondly, the overall MOTHRA architecture imposes no a priori constraints on the size of the software systems that can be tested in the environment. The practical meaning of this criterion is that the same architecture is able to service programs varying in size from individual module of less than 10 source lines to fully integrated systems of more than 10 lines. The human user-the tester-is able to apply comparable functions across a familiar interface as the software being tested evolves in size and complexity by several orders of magnitude. In fact, the only indicators of size or complexity that have ties to the MOTHRA architecture are the operating system cost penalties and performance delays inherent in manipulating massive objects. All other costs and resource demands are under the direct control of the tester. In most cases, the tester will choose to allow critical resources such as time or memory to grow linearly with program size and complexity. The tester may, however, choose to conserve these resources by sacrificing other resources (e.g., dollars) or even by reducing the fidelity of the test. These are ultimately economic decisions determined by the relative costs of tests and failures-MOTHRA does not legislate or even favor one kind of decision in preference to another. An important mechanism for meeting these criteria is that MOTHRA is reconfigurable, allowing the integration of user and system tools with which the tester may already be familiar, and allowing the system to make use of different underlying hardware architectures of differing capabilities. We address this in MOTHRA by the use of thematic tools for software testing. It has been our experience that software testing is most effective when the test procedures can be reduced to a set of well-understood and natural activities. Since MOTHRA supports tests of both very small and very large programs, the details of the tools that are actually invoked vary in power and scope. However, even very different tools can implement basic themes that are carried along throughout the several phases of testing. For example, programmers in modern development environments interact increasingly with an array of very powerful source language debuggers. Even though formal testing methodologies and debugging are very different activities, the debugging theme can be used as a metaphor to carry the tester from tool to tool as the software being tested evolves. One MOTHRA system has been constructed using the AT&T Bell Labs Blit interactive bitmap display terminal running under the control of a UNIX window manager called Layers. The host environment is a modestly configured VAX 11/780 running UNIX 4.3 BSD. Another version has been implemented on V AXstationsS running Ultrix 1.2 and the X Window System. However, the architecture of MOTHRA encourages re-hosting. Furthermore, explicit operations allow MOTHRA processes to spawn parallel and vectorized processes for execution by a Cyber 205 (or any other powerful parallel machine)."
The Mothra software testing environment user’s manual,"DeMillo, R.A. and Martin, R.J.",x (User Manual),
The art of software testing,"Myers, Glenford J. and Sandler, Corey and Badgett, Tom",x (Book),
The chaining approach for software test data generation,"Ferguson, R. and Korel, B.",,"Software testing is very labor intensive and expensive and accounts for a significant portion of software system development cost. If the testing process could be automated, the cost of developing software could be significantly reduced. Test data generation in program testing is the process of identifying a set of test data that satisfies a selected testing criterion, such as statement coverage and branch coverage. In this article we present a chaining approach for automated software test data generation which builds on the current theory of execution-oriented test data generation. In the chaining approach, test data are derived based on the actual execution of the program under test. For many programs, the execution of the selected statement may require prior execution of some other statements. The existing methods of test data generation may not efficiently generate test data for these types of programs because they only use control flow information of a program during the search process. The chaining approach uses data dependence analysis to guide the search process, i.e., data dependence analysis automatically identifies statements that affect the execution of the selected statement. The chaining approach uses these statements to form a sequence of statements that is to be executed prior to the execution of the selected statement. The experiments have shown that the chaining approach may significantly improve the chances of finding test data as compared to the existing methods of automated test data generation."
The dynamic domain reduction approach to test data generation,"Offutt, A.J. and Jin, Z. and Pan, J.",,"Test data generation is one of the most technically challenging steps of testing software, but most commercial systems currently incorporate very little automation for this step. This paper presents results from a project that is trying to find ways to in corporate test data generation into practical test processes. The results include a new procedure for automatically generating test data that incorporates ideas from symbolic evaluation, constraint-based testing, and dynamic test data generation. It takes an initial set of values for each input, and dynamically 'pushes' the values through the control-flow graph of the program, modifying the sets of values as branches in the program are taken. The result is usually a set of values for each input parameter that has the property that any choice from the sets will cause the path to be traversed. This procedure uses new analysis techniques, offers improvements over previous research results in constraint-based testing, and combines several steps into one coherent process. The dynamic nature of this procedure yields several benefits. Moving through the control-flow graph dynamically allows path constraints to be resolved immediately, which is more efficient both in space and time, and more often successful than constraint-based testing. This new procedure also incorporates an intelligent search technique based on bisection. The dynamic nature of this procedure also allows certain improvements to be made in the handling of arrays, loops, and expressions; language features that are traditionally difficult to handle in test data generation systems. The paper presents the test data generation procedure, examples to explain the working of the procedure, and results from a proof-of-concept implementation."
The dynamic domain reduction procedure for test data generation,"Offutt, A.J. and Jin, Z. and Pan, J.",,"Test data generation is one of the most technically challenging steps of testing software, but most commercial systems currently incorporate very little automation for this step. This paper presents results from a project that is trying to find ways to incorporate test data generation into practical test processes. The results include a new procedure for automatically generating test data that incorporates ideas from symbolic evaluation, constraint-based testing, and dynamic test data generation. It takes an initial set of values for each input, and dynamically ‘pushes’ the values through the control-flow graph of the program, modifying the sets of values as branches in the program are taken. The result is usually a set of values for each input parameter that has the property that any choice from the sets will cause the path to be traversed. This procedure uses new analysis techniques, offers improvements over previous research results in constraint-based testing, and combines several steps into one coherent process. The dynamic nature of this procedure yields several benefits. Moving through the control flow graph dynamically allows path constraints to be resolved immediately, which is more efficient both in space and time, and more often successful than constraint-based testing. This new procedure also incorporates an intelligent search technique based on bisection. The dynamic nature of this procedure also allows certain improvements to be made in the handling of arrays, loops, and expressions; language features that are traditionally difficult to handle in test data generation systems. The paper presents the test data generation procedure, examples to explain the working of the procedure, and results from a proof-of-concept implementation"
The economic impacts of inadequate infrastructure for software testing,"Tassey, G.",x (Book),
The growth of software testing,"Gelperin, D. and Hetzel, B.",,"We can trace the evolution of software test engineering by examining changes in the testing process model and the level of professionalism over the years. The current definition of a good software testing practice involves some preventive methodology."
Theoretical and empirical studies on using program mutation to test the functional correctness of programs,"Budd, T.A. and DeMillo, R.A. and Lipton, R.J. and Sayward, F.G.",,"In testing for program correctness, the standard approaches [11,13,21,22,23,24,34] have centered on finding data D, a finite subset of all possible inputs to program P, such that 1) if for all x in D, P(x) = f(x), then P* = f where f is a partial recursive function that specifies the intended behavior of the program and P* is the function actually computed by program P. A major stumbling block in such formalizations has been that the conclusion of (1) is so strong that, except for trivial classes of programs, (1) is bound to be formally undecidable [23]. There is an undeniable tendency among practitioners to consider program testing an ad hoc human technique: one creates test data that intuitively seems to capture some aspect of the program, observes the program in execution on it, and then draws conclusions on the program's correctness based on the observations. To augment this undisciplined strategy, techniques have been proposed that yield quantitative information on the degree to which a program has been tested. (See Goodenough [14] for a recent survey.) Thus the tester is given an inductive basis for confidence that (1) holds for the particular application. Paralleling the undecidability of deductive testing methods, the inductive methods all have had trivial examples of failure [14,18,22,23]. These deductive and inductive approaches have had a common theme: all have aimed at the strong conclusion of (1). Program mutation [1,7,9,27], on the other hand, is a testing technique that aims at drawing a weaker, yet quite realistic, conclusion of the following nature: (2) if for all x in D, P(x) = f(x), then P* = f OR P is 'pathological.' To paraphrase, 3) if P is not pathological and P(x) = f(x) for all x in D then P* = f. Below we will make precise what is meant by 'P is pathological'; for now it suffices to say that P not pathological means that P was written by a competent programmer who had a good understanding of the task to be performed. Therefore if P does not realize f it is 'close' to doing so. This underlying hypothesis of program mutation has become known as the competent programmer hypothesis: either P* = f or some program Q 'close' to P has the property Q* = f. To be more specific, program mutation is a testing method that proposes the following version of correctness testing: Given that P was written by a competent programmer, find test data D for which P(D) = f(D) implies P* = f. Our method of developing D, assuming either P or some program close to P is correct, is by eliminating the alternatives. Let &phis; be the set of programs close to P. We restate the method as follows: Find test data D such that: i) for all x in D P(x) = f(x) and ii) for all Q in &phis; either Q* = P* or for some x in D, Q(x) ≠ P(x). If test data D can be developed having properties (i) and (ii), then we say that D differentiates P from &phis;, alternatively P passes the &phis; mutant test. The goal of this paper is to study, from both theoretical and experimental viewpoints, two basic questions: Question 1: If P is written by a competent programmer and if P passes the &phis; mutant test with test data D, does P* = f? Note that, after formally defining &phis; for P in a fixed programming language L, an affirmative answer to question 1 reduces to showing that the competent programmer hypothesis holds for this L and &phis;. We have observed that under many natural definitions of &phis; there is often a strong coupling between members of &phis; and a small subset µ. That is, often one can reduce the problem of finding test data that differentiates P from &phis; to that of finding test data that differentiates P from µ. We will call this subset µ the mutants of P and the second question we will study involves the so-called coupling effect [9]: Question 2 (Coupling Effect): If P passes the µ mutant test with data D, does P pass the &phis; mutant test with data D? Intuitively, one can think of µ as representing the programs that are 'very close' to P. In the next section we will present two types of theoretical results concerning the two questions above: general results expressed in terms of properties of the language class L, and specific results for a class of decision table programs and for a subset of LISP. Portions of the work on decision tables and LISP have appeared elsewhere [5,6], but the presentations given here are both simpler and more unified. In the final section we present a system for applying program mutation to FORTRAN and we introduce a new type of software experiment, called a 'beat the system' experiment, for evaluating how well our system approximates an affirmative response to the program mutation questions."
Tool support for unit testing of aspect-oriented software,"Zhao, J.",,"In this paper, we present a data flow based unit testing approach and its tool support for aspect-oriented software. Our approach tests two types of units for an aspect-oriented program, i.e., aspects that are modular units of crosscutting implementation of the program, and those classes whose behaviors may be affeted by one or more aspects. We use the control flow graph as a basis to compute def-use pairs of aspects or classes being tested in an aspect-oriented program and use such information to perform data-flow testing on the aspects and classes of the program."
Toward a framework and benchmark for testing tools for multi-threaded programs,"Eytani, Y. and Havelund, K. and Stoller, S.D. and Ur, S.",,"Multi-threaded code is becoming very common, both on the server side, and very recently for personal computers as well. Consequently, looking for intermittent bugs is a problem that is receiving more and more attention. As there is no silver bullet, research focuses on a variety of partial solutions. We outline a road map for combining the research within the different disciplines of testing multi-threaded programs and for evaluating the quality of this research. We have three main goals. First, to create a benchmark that can be used to evaluate different solutions. Second, to create a framework with open application programming interfaces that enables the combination of techniques in the multi-threading domain. Third, to create a focus for the research in this area around which a community of people who try to solve similar problems with different techniques can congregate. We have started creating such a benchmark and describe the lessons learned in the process. The framework will enable technology developers, for example, developers of race detection algorithms, to concentrate on their components and use other ready made components (e.g. an instrumentor) to create a testing solution."
Towards a model-driven engineering solution for language independent mutation testing,"Gómez-Abajo, P. and Guerra, E. and Lara, J. and Merayo, M.G.",,"Mutation testing is a technique to assess test suite adequacy to distinguish between correct and incorrect programs. Mutation testing applies one or more small changes to a program to obtain variants called mutants. The adequacy of a test suite is measured by determining how many of the mutants it distinguishes from the original program. There are many works about mutation testing, but the existing approaches focus on a specific programming language, and usually, it is not easy to customize the set of mutation operators. In this paper, we present Wodel-Test, an extension of the Wodel tool that implements a language-independent mutation testing framework based on MDE principles."
Towards a practical approach to test aspect-oriented software,"Zhou, Y. and Richardson, D. and Ziv, H.",,"Aspect-Oriented Programming (AOP) provides new constructs and tools to handle cross-cutting concerns in programs. Fully realizing the potentials of Aspect-Oriented Software Development requires new abstractions and techniques for testing. This paper proposes a first step towards a practical approach to test aspect-oriented software. The proposed approach is accompanied by a selection algorithm that can select test cases that are relevant to aspects under test. A new testing coverage definition is proposed to specify the sufficiency of test cases on the aspect being tested. A tool is developed to support the approach, automating test case selection and coverage calculation. A detailed case study of banking account processing illustrates this initial approach."
Towards a taxonomy of SUnit tests,"Gaelli, Markus and Lanza, Michele and Nierstrasz, Oscar",,"Not all unit tests are alike. Some tests are simple one-liners, while others contain a battery of assertions. Certain tests focus on a single method, while others test interactions between methods. There are even tests that do not contain assertions at all. This can make it difficult for a developer to understand which methods are tested by which tests, to what degree they are tested, and what to take into account while refactoring. We have manually analyzed the test base of a large existing object-oriented system in order to derive a first taxonomy of unit tests. We have then developed some simple tools to semi-automatically categorize tests according to this taxonomy, and applied it to two case studies. Beside explaining our taxonomy, we report on our initial results using it, namely that a majority of unit tests focus on single methods and that our lightweight automatic categorization could already classify more than 50% of these single method commands."
Towards automated unit testing of state-chart implementations,"Burton, Simon",,"This report describes an automated method of unit test design based on requirements specified in a subset of the statechart notation. The behaviour under test is first extracted from the requirements and specified in the Z notation. Existing methods and tools are then applied to this specification to derive the tests. Using Z to model the requirements and specify the tests allows for a deductive approach to verifying test satisfiability, test result correctness and certain properties of the requirements. An examination of the specification coverage achieved by the tests is provided and the report concludes with an evaluation of the work to date and a set of directions for future work."
Towards the systematic testing of aspect-oriented programs,"Alexander, R.T. and Bieman, J.M. and Andrews, A.A.",,"The code that provides solutions to key software requirements, such as security and fault-tolerance, tends to be spread throughout (or cross-cut) the program modules that implement the “primary functionality” of a software system. Aspect-oriented programming is an emerging programming paradigm that supports implementing such cross-cutting requirements into named program units called “aspects”. To construct a system as an aspect-oriented program (AOP), one develops code for primary functionality in traditional modules and code for cross-cutting functionality in aspect modules. Compiling and running an AOP requires that the aspect code be “woven” into the code. Although aspect-oriented programming supports the separation of concerns into named program units, explicit and implicit dependencies of both aspects and traditional modules will result in systems with new testing challenges, which include new sources for program faults. This paper introduces a candidate fault model, along with associated testing criteria, for AOPs based on interactions that are unique to AOPs. The paper also identifies key issues relevant to the systematic testing of AOPs."
Transforming mutation testing from the technology of the future into the technology of the present,"Ammann, P.",x (Presentation),
Unit Test Frameworks: Tools for High-Quality Software Development,"Hamill, Paul",x (Book),
Unit testing aspectual behavior,"Lopes, C.V. and Ngo, T.",,"In the Java Aspect Markup Language (JAML), aspects are represented using two kinds of modules: a) regular java classes, encapsulating aspectual behavior; and b) XML binders, defining aspectual compositions. Besides leveraging the abundance of software engineering tools available for Java and XML, this approach for aspect-oriented programming also provides opportunities for testing aspects as independent units. In this position paper, JamlUnit, an extension of JUnit, is proposed as a framework for performing unit testing of aspects written in JAML. More specifically, this paper focus on testing aspectual behavior, i.e. behavior implemented in pieces of advice. JamlUnit uses mock objects that emulate execution context (join point) information. JamlUnit shows that performing unit testing on aspectual behavior is possible and relatively straightforward, as long as the AOP language observes a couple of simple requirements."
Unit testing with JUnit - tutorial,"Vogella, L.",x (Web),
UnitPlus: Assisting Developer Testing in Eclipse,"Song, Y. and Thummalapenta, S. and Xie, T.",,"In the software development life cycle, unit testing is an important phase that helps in early detection of bugs. A unit test case consists of two parts: a test input, which is often a sequence of method calls, and a test oracle, which is often in the form of assertions. The effectiveness of a unit test case depends on its test input as well as its test oracle because the test oracle helps in exposing bugs during the execution of the test input. The task of writing effective test oracles is not trivial as this task requires domain or application knowledge and also needs knowledge of the intricate details of the class under test. In addition, when developers write new unit test cases, much test code (including code in test inputs or oracles) such as method argument values is the same as some previously written test code. To assist developers in writing test code in unit test cases more efficiently, we have developed an Eclipse plugin for JUnit test cases, called UnitPlus, that runs in the background and recommends test-code pieces for developers to choose (and revise when needed) to put in test oracles or test inputs. The recommendation is based on static analysis of the class under test and already written unit test cases. We have conducted a feasibility study for our UnitPlus plugin with four Java libraries to demonstrate its potential utility."
Using program slicing to assist in the detection of equivalent mutants,"Rob, Mark, Sebastian",,"While mutation testing has proved to be an effective way of finding software faults, currently it is only applied to relatively small programs. One of the main reasons for this is the human analysis required in detecting equivalent mutants. Here program slicing is used to simplify this problem. Progam slicing is also used to reduce the number of equivalent mutants produced."
Using software testing to move students from trial-and-error to reflection-in-action,Stephen H.,,"Introductory computer science students rely on a trial and error approach to fixing errors and debugging for too long. Moving to a reflection in action strategy can help students become more successful. Traditional programming assignments are usually assessed in a way that ignores the skills needed for reflection in action, but software testing promotes the hypothesis-forming and experimental validation that are central to this mode of learning. By changing the way assignments are assessed--where students are responsible for demonstrating correctness through testing, and then assessed on how well they achieve this goal--it is possible to reinforce desired skills. Automated feedback can also play a valuable role in encouraging students while also showing them where they can improve."
Using state infection conditions to detect equivalent mutants and speed up mutation analysis,"Just, R. and Ernst, M.D. and Fraser, G.",,"Mutation analysis evaluates test suites and testing techniques by measuring how well they detect seeded defects (mutants). Even though well established in research, mutation analysis is rarely used in practice due to scalability problems --- there are multiple mutations per code statement leading to a large number of mutants, and hence executions of the test suite. In addition, the use of mutation to improve test suites is futile for mutants that are equivalent, which means that there exists no test case that distinguishes them from the original program. This paper introduces two optimizations based on state infection conditions, i.e., conditions that determine for a test execution whether the same execution on a mutant would lead to a different state. First, redundant test execution can be avoided by monitoring state infection conditions, leading to an overall performance improvement. Second, state infection conditions can aid in identifying equivalent mutants, thus guiding efforts to improve test suites."
Whispec: White-box testing of libraries using declarative specifications”,"Shao, D. and Khurshid, S. and Perry, D.E.",,"We present a novel framework, Whispec, for white-box testing of methods that manipulate structurally complex data, such as those that pervade library classes. Given method preconditions as declarative constraints, our framework systematically generates test inputs for the methods to maximize their code coverage. The constraints are written in Alloy, a first-order language based on relations. To test a method, given its precondition constraint, we first solve that constraint using the Alloy Analyzer and translate a solution into a test input. Next, we execute the method on that input and build the path condition for the resulting execution path. Then, we run the analyzer on a conjunction of the precondition and a new path condition that represents a previously unexplored path. The solution is translated to a new test input, which triggers the next round of test generation. The iterative execution of Whispec can systematically enumerate inputs that maximize code coverage. Experiments using a variety of data structure implementations from the Java libraries show that our framework generates significantly smaller test suites (while maximizing coverage) than those generated by previous specification-based approaches."
Wodel: a domain-specific language for model mutation,"Gómez-Abajo, P. and Guerra, E. and Lara, J.",,"Model-Driven Engineering (MDE) is a software engineering paradigm that uses models as main assets in all development phases. While many languages for model manipulation exist (e.g., for model transformation or code generation), there is a lack of frameworks to define and apply model mutations. A model mutant is a variation of an original model, created by specific model mutation operations. Model mutation has many applications, for instance, in the areas of model transformation testing, model-based testing or education. In this paper, we present a domain-specific language, called Wodel, for the specification and generation of model mutants. Wodel is domain-independent, as it can be used to generate mutants of models conforming to arbitrary metamodels. Its development environment is extensible, permitting the incorporation of post-processors for different applications. As an example, we show an application consisting on the automated generation of exercises for particular domains (automata, class diagrams, electronic circuits, etc.)."
xUnit Test Patterns: Refactoring Test Code,"Meszaros, G.",x (Book),
A comparative study of manual and automated testing in industrial embedded software,"['EP Enoiu', 'D Sundmark', 'A Causevic']",,"Testing is an important activity in engineering of industrial embedded software. In certain application domains (e.g., railway industry) engineering software is certified according to safety standards that require extensive software testing procedures to be applied for the development of reliable systems. Mutation analysis is a technique for creating faulty versions of a software for the purpose of examining the fault detection ability of a test suite. Mutation analysis has been used for evaluating existing test suites, but also for generating test suites that detect injected faults (i.e., mutation testing). To support developers in software testing, we propose a technique for producing test cases using an automated test generation approach that operates using mutation testing for software written in IEC 61131-3 language, a programming standard for safety-critical embedded software, commonly used for Programmable Logic Controllers (PLCs). This approach uses the Uppaal model checker and is based on a combined model that contains all the mutants and the original program. We applied this approach in a tool for testing industrial PLC programs and evaluated it in terms of cost and fault detection. For realistic validation we collected industrial experimental evidence on how mutation testing compares with manual testing as well as automated decision-coverage adequate test generation. In the evaluation, we used manually seeded faults provided by four industrial engineers. The results show that even if mutation-based test generation achieves better fault detection than automated decision coverage-based test generation, these mutation-adequate test suites are not better at detecting faults than manual test suites. However, the mutation-based test suites are significantly less costly to create, in terms of testing time, than manually created test suites. Our results suggest that the fault detection scores could be improved by considering some new and improved mutation operators (e.g., Feedback Loop Insertion Operator (FIO)) for PLC programs as well as higher-order mutations."
A comprehensive framework for testing database-centric software applications,['GM Kapfhammer'],,"The database is a critical component of many modern software applications. Recent reports indicate that the vast majority of database use occurs from within an application program. Indeed, database-centric applications have been implemented to create digital libraries, scientific data repositories, and electronic commerce applications. However, a database-centric application is very different from a traditional software system because it interacts with a database that has a complex state and structure. This dissertation formulates a comprehensive framework to address the challenges that are associated with the efficient and effective testing of database-centric applications. The database-aware approach to testing includes: (i) a fault model, (ii) several unified representations of a program's database interactions, (iii) a family of test adequacycriteria, (iv) a test coverage monitoring component, and (v) tools for reducing and re-ordering a test suite during regression testing.This dissertation analyzes the worst-case time complexity of every important testing algorithm. This analysis is complemented by experiments that measure the efficiency and effectiveness of thedatabase-aware testing techniques. Each tool is evaluated by using it to test six database-centric applications. The experiments show thatthe database-aware representations can be constructed with moderate time and space overhead. The adequacy criteria call for test suitesto cover 20% more requirements than traditional criteria and this ensures the accurate assessment of test suite quality. It is possibleto enumerate data flow-based test requirements in less than one minute and coverage tree path requirements are normally identified in no morethan ten seconds. The experimental results also indicate that the coverage monitor can insert instrumentation probes into all six of theapplications in fewer than ten seconds. Although instrumentation may moderately increase the static space overhead of an application, the coverage monitoring techniques only increase testing time by 55% on average. A coverage tree often can be stored in less than five seconds even though the coverage report may consume up to twenty-fivemegabytes of storage. The regression tester usually reduces or prioritizes a test suite in under five seconds. The experiments also demonstrate that the modified test suite is frequently more streamlined than the initial tests."
A context-sensitive coverage criterion for test suite reduction,['SD McMaster'],,"Modern software is increasingly developed using multi-language implementations, large supporting libraries and frameworks, callbacks, virtual function calls, reflection, multithreading, and object- and aspect-oriented programming. The predominant example of such software is the graphical user interface (GUI), which is used as a front-end to most of today’s software applications. The characteristics of GUIs and other modern software present new challenges to software testing. Because recently developed techniques for automated test case generation can generate more tests than are practical to regularly execute, one important challenge is test suite reduction. Test suite reduction seeks to decrease the size of a test suite without overly compromising its original fault detection ability. This research advances the state-of-the-art in test suite reduction by empirically studying a coverage criterion which considers the context in which program concepts are covered. Conventional approaches to test suite reduction were developed and evaluated on batch-style applications and, due to the aforementioned considerations, are not always easily applicable to modern software. Furthermore, many existing techniques fail to consider the context in which code executes inside an event-driven paradigm, where programs wait for and interactively respond to user- and system-generated events. Consequently, they yield reduced test suites with severely impaired fault detection ability. The novel feature of this research is a test suite reduction technique based on the call stack coverage criterion which addresses many of the challenges associated with coverage-based test suite reduction in modern applications. Results show that reducing test suites while maintaining call stack coverage yields good tradeoffs between size reduction and fault detection effectiveness compared to traditional techniques. The output of this research includes models, metrics, algorithms, and techniques based upon this approach."
A machine learning approach for classification of equivalent mutants,"['MR Naeem', 'T Lin', 'H Naeem']",,"Mutation testing is a fault-based technique to test the quality of test suites by inducing artificial syntactic faults or mutants in a source program. However, some mutants have the same semantics as original program and cannot be detected by any test suite input known as equivalent mutants. Equivalent mutant problem (EMP) is undecidable as it requires manual human effort to identify a mutant as equivalent or killable. The constraint-based testing (CBT) theory suggests the use of mathematical constraints which can help reveal some equivalent mutants using mutant features. In this paper, we consider three metrics of CBT theory, ie, reachability, necessity, and sufficiency to extract feature constraints from mutant programs. Constraints are extracted using program dependency graphs. Other features such as degree of significance, semantic distance, and information entropy of mutants are also extracted to build a binary classification model. Machine learning algorithms such as Random Forest, GBT, and SVM are applied under two application scenarios (split-project and cross-project) on ten Java programs to predict equivalent mutants. The analysis of the study demonstrates that that the proposed techniques not only improves the efficiency of the equivalent mutant detection but also reduces the effort required to perform it with small accuracy loss."
A model‐driven framework to enhance the consistency of logical integrity constraints: Introducing integrity regression testing,['M Nooraei Abadeh'],,"Although the importance of models continuously grows in software development, common development approaches are less able to integrate the automatic management of model integrity into the development process. These critically important constraints may ensure the coherence of models in the evolution process to prevent manipulations that could violate defined constraints on a model. This paper proposes an integrity framework in the context of model-driven architecture to achieve sufficient structural code coverage at a higher program representation level than machine code. Our framework offers to propagate the modifications from a platform-independent specification to the corresponding test template model while keeping the consistency and integrity constraints after system evolution. To examine the efficiency of the proposed framework, a quantitative analysis plan is evaluated based on two experimental case studies. In addition, we propose coverage criteria for integrity regression testing (IRT), derived from logic coverage criteria that apply different conceptual levels of testing for the formulation of integrity requirements. The defined criteria for IRT reduce the inherent complexity and cost of verifying complex design changes in regression testing while keeping the fault detection capability with respect to the changes. The framework aims to keep pace with IRT in a formal way. The framework can solve a number of restricted outlooks in model integrity and some limiting factors of incremental maintenance and retesting. The framework satisfies several valuable quality attributes in software testing, such as safety percentage, precision, abstract fault detection performance measurable coverage level, and generality."
A mutation analysis framework for simulink models,['H Runge'],,"Mutation analysis is a fault-based method used for introducing small changes into a program, producing mutants based on mutation operators, classes of commonly occurring faults. Mutation analysis has been used in the last couple of decades for evaluating how good test cases produced by software testing are at detecting faults. Software testing is the process of executing software based on certain input parameters and evaluating its behavior with the purpose of finding faults and making sure that the software works as expected. In automotive systems, MATLAB Simulink is the facto standard for implementing the electronic control software of vehicle functions. As such, the application of software testing and mutation analysis to Simulink models becomes a crucial aspect for providing a framework to evaluate existing test cases by introducing mutations into these models. In this thesis, we propose a mutation generation framework for Simulink by using a set of mutation operators defined based on our own classification based on the Simulink project structure and previously defined operators. Our method is supported by the tool SIMUTATOR, which we also introduce and apply on an industrial prototype called the Brake-By-Wire system. This work enables the mutation analysis of industrial Simulink models. In addition, we show how SIMUTATOR can be used together with SIMPAAL (a tool for transforming Simulink models to timed automata) and MATS (a tool for test generation) for mutation testing. The results show that SIMUTATOR is efficient and can be used successfully on industrial-sized Simulink software"
A new perspective on the competent programmer hypothesis through the reproduction of bugs with repeated mutations,"['E Stein', 'S Herbold', 'F Trautsch', 'J Grabowski']",,"The competent programmer hypothesis states that most programmers are competent enough to create correct or almost correct source code. Because this implies that bugs should usually manifest through small variations of the correct code, the competent programmer hypothesis is one of the fundamental assumptions of mutation testing. Unfortunately, it is still unclear if the competent programmer hypothesis holds and past research presents contradictory claims. Within this article, we provide a new perspective on the competent programmer hypothesis and its relation to mutation testing. We try to re-create real-world bugs through chains of mutations to understand if there is a direct link between mutation testing and bugs. The lengths of these paths help us to understand if the source code is really almost correct, or if large variations are required. Our results indicate that while the competent programmer hypothesis seems to be true, mutation testing is missing important operators to generate representative real-world bugs."
A new similarity-based greedy approach for generating effective test suite,"['S Singh', 'R Shree']",,"Software regression testing is one of the most critical phases of software development life cycle, used by developers with the intent of detecting new faults to validate modified software prior to delivery to the customer. To validate updated features, new test cases are generated by the testers which increment the test suite size automatically. The resulting test suite may contain obsolete, redundant, and ambiguous test cases. Therefore, there is a strong requirement of an intelligent testing approach to reduce the test suite size by removing those unessential test cases economically. This paper proposed an interesting approach, which involves the combination of regression testing techniques: minimization, and prioritization both. The main focus is on multiple regression activities with multiple criteria rather than using only single activity to produce an optimal solution. In this paper clustering approach is also considered, which could simplify and enhance the minimization and prioritization task. To evaluate the effectiveness of the strategy, we performed an experimental investigation together with an eminent heuristic Harrold Gupta and Soffa (HGS), considering the testing measures of the minimized test suite size and fault coverage. The results show that, similarity-based greedy approach with multiple coverage criteria can be quite effective in terms of fault detection loss of reduced test suite without much affecting the percentage of suite size reduction."
A novel approach for mutant diversity-based fault localization: DAM-FL,"['N Gupta', 'A Sharma', 'MK Pachariya']",,"Locating faults after detecting is one of the important steps in software debugging. For fault localization, many approaches are there. Mutant based approaches are also available for fault localization and they have performed better compared to statement based approaches. In the present paper, a new mutant based fault localization approach named “DAM-FL” is proposed which is based on diversity aware mutation adequacy criterion. It uses diversified or distinguished mutants and their respective test suites for locating faults. Experiments on projects of defects4j repository show that for single line faults, proposed approach with a reduced number of mutants performs better or gives similar results compared to the traditional mutant based fault localization approach. For multi-line faults, it can be said that the proposed approach is equivalent to the traditional approaches."
A novel test case generation method based on program structure diagram,"['X Wu', 'M Qu', 'Y Tao', 'G Wang']",,"At present, embedded software has the problems of test lag, non-visual and low efficiency, depending on the test design of testers. It cannot guarantee the quality of the test cases and cannot guarantee the quality of the test. In this paper, a software program structure diagram model is established to verify the model, and the test points are planned manually. Finally, fill in the contents of the test items, and generate the corresponding set of test cases according to the algorithm, and save them into the database for management. This method can improve the reliability and efficiency of test, ensure the visual tracking and management of the use case, and have a strong auxiliary function to the planning and generation of the test case."
A requirement-based systematic test-case generation method for safety-critical embedded systems,['S Kandl'],,"Safety-critical systems have to be tested exhaustively to ensure that there is no erroneous behavior, because failures may have serious impact. In relevant standards requirements for the testing process are defined, for instance, the required coverage metrics (like MC/DC) or 'traceability', that means that the generated test cases have to map to the requirements originally defined in the system specification. There exist many test-case generation methods, but it is still a challenge to generate the test cases systematically (based on the requirements) and to guarantee that the resulting test set achieves full MC/DC on the system under test. The aim of this PhD thesis is to make a significant contribution to solve this problem. In this PhD thesis a testing framework is developed that provides a test-case generation method that is able to generate the test cases based on the requirements. The resulting test cases are traceable back to the system requirements. With the generated test set we achieve maximum possible MC/DC on the code of the SUT for a safety-critical application from the automotive domain. Furthermore we evaluate the actual error detection rate of the test set by defining three different error scenarios (errors in the value domain, errors in the variable domain, and errors in the operator domain). The results show that the error detection probability for the value domain is quite sufficient, whereas the error detection rates for the variable and operator domain are significantly less than expected. The results are important for the discussion about whether MC/DC is a suitable coverage metric for safety-critical systems."
A survey on data-flow testing,"['T Su', 'K Wu', 'W Miao', 'G Pu', 'J He', 'Y Chen']",,"Data-flow testing (DFT) is a family of testing strategies designed to verify the interactions between each program variable’s definition and its uses. Such a test objective of interest is referred to as a def-use pair. DFT selects test data with respect to various test adequacy criteria (i.e., data-flow coverage criteria) to exercise each pair. The original conception of DFT was introduced by Herman in 1976. Since then, a number of studies have been conducted, both theoretically and empirically, to analyze DFT’s complexity and effectiveness. In the past four decades, DFT has been continuously concerned, and various approaches from different aspects are proposed to pursue automatic and efficient data-flow testing. This survey presents a detailed overview of data-flow testing, including challenges and approaches in enforcing and automating it: (1) it introduces the data-flow analysis techniques that are used to identify def-use pairs; (2) it classifies and discusses techniques for data-flow-based test data generation, such as search-based testing, random testing, collateral-coverage-based testing, symbolic-execution-based testing, and model-checking-based testing; (3) it discusses techniques for tracking data-flow coverage; (4) it presents several DFT applications, including software fault localization, web security testing, and specification consistency checking; and (5) it summarizes recent advances and discusses future research directions toward more practical data-flow testing."
A survey on regression test-case prioritization,"['Y Lou', 'J Chen', 'L Zhang', 'D Hao']",,"Regression testing is crucial for ensuring the quality of modern software systems, but can be extremely costly in practice. Test-case prioritization has been proposed to improve the effectiveness of regression testing by scheduling the execution order of test cases to detect regression bugs faster. Since its first proposal, test-case prioritization has been intensively studied in the literature. In this chapter, we perform an extensive survey and analysis on existing test-case prioritization techniques, as well as pointing out future directions for test-case prioritization. More specifically, we collect 191 papers on test-case prioritization from 1997 to 2016 and conduct a detailed survey to systematically investigate these work from six aspects, i.e., algorithms, criteria, measurements, constraints, empirical studies, and scenarios. For each of the six aspects, we discuss the existing work and the trend during the evolution of test-case prioritization. Furthermore, we discuss the current limitations/issues in test-case prioritization research, as well as potential future directions on test-case prioritization. Our analyses provide the evidence that test-case prioritization topic is attracting increasing interests, while the need for practical test-case prioritization tools remains."
A systematic literature review of how mutation testing supports test activities,"['Q Zhu', 'A Panichella', 'A Zaidman']",,"Mutation testing has been very actively investigated by researchers since the 1970s, and remarkable advances have been achieved in its concepts, theory, technology, and empirical evidence. While the most influential realisations have been summarised by existing literature reviews, we lack insight into how mutation testing is actually applied. Our goal is to identify and classify the main applications of mutation testing and analyse the level of replicability of empirical studies related to mutation testing. To this aim, this paper provides a systematic literature review on the application perspective of mutation testing based on a collection of 191 papers published between 1981 and 2015. In particular, we analysed in which quality assurance processes mutation testing is used, which mutation tools and which mutation operators are employed. Additionally, we also investigated how the inherent core problems of mutation testing, ie, the equivalent mutant problem and the high computational cost, are addressed during the actual usage. The results show that most studies use mutation testing as an assessment tool targeting unit tests, and many of the supporting techniques for making mutation testing applicable in practice are still underdeveloped. Based on our observations, we made 9 recommendations for future work, including an important suggestion on how to report mutation testing in testing experiments in an appropriate manner."
A systematic literature review of techniques and metrics to reduce the cost of mutation testing,"['AV Pizzoleto', 'FC Ferrari', 'J Offutt', 'L Fernandes']",,"Historically, researchers have proposed and applied many techniques to reduce the cost of mutation testing. It has become difficult to find all techniques and to understand the cost-benefit tradeoffs among them, which is critical to transitioning this technology to practice. This paper extends a prior workshop paper to summarize and analyze the current knowledge about reducing the cost of mutation testing through a systematic literature review. We selected 175 peer-reviewed studies, from which 153 present either original or updated contributions. Our analysis resulted in six main goals for cost reduction and 21 techniques. In the last decade, a growing number of studies explored techniques such as selective mutation, evolutionary algorithms, control-flow analysis, and higher-order mutation. Furthermore, we characterized 18 metrics, with particular interest in the number of mutants to be executed, test cases required, equivalent mutants generated and detected, and mutant execution speedup. We found that cost reduction for mutation is increasingly becoming interdisciplinary, often combining multiple techniques. Additionally, measurements vary even for studies that use the same techniques. Researchers can use our results to find more detailed information about particular techniques, and to design comparable and reproducible experiments."
A technique to test apis specified in natural language.,['FB Pontes'],,"Developers of widely used Application Programming Interfaces (APIs) implement and test APIs based on a document, which is commonly specified using natural language. How- ever, there is limited knowledge on whether API developers are able to systematically reveal i) underdetermined specifications; and ii) non-conformances between their implementation and the specification. To better understand the problem, we analyze test suites of Java Reflection API, and we conduct two surveys. A survey with 130 developers who use the Java Reflection API, and a survey with 128 C# developers who use and implement the .NET Reflection API to see whether the specification impacts on their understanding. We also propose a technique to detect underdetermined specifications and non-conformances between the specification and the implementations of the APIs. It automatically creates test cases, and executes them using different implementations. It saves objects yielded by methods to be used to create more test cases. If results differ, it detects an underdetermined specification or a non-conformance candidate between the specification and at least one implementation of the API. We evaluate our technique using the Java Reflection API in 446 input programs. Our technique identifies underdetermined specification and non-conformance candidates in 32 Java Reflection API public methods of 7 classes. We report underdetermined specification candidates in 12 Java Reflection API methods. Java Reflection API specifiers accept 3 underdetermined specification candidates (25%). We also report 24 non-conformance candidates to Eclipse OpenJ9 JVM, and 7 to Oracle JVM. Eclipse OpenJ9 JVM developers accept and fix 21 candidates (87.5%), and Oracle JVM developers accept 5 and fix 4 non-conformance candidates. Twelve test cases are now part of the Eclipse OpenJ9 JVM test suite. We also evaluate our technique using the Java Collections API. Even being a very popular Java API, our technique identifies 29 underdetermined specification and non-conformance candidates. Our technique identifies 17 candidates that cannot be detected by popular automatic test suite generators. We report 5 underdetermined specification candidates to the Java Collections API specifiers. We also report 9 non-conformance candidates to Eclipse OpenJ9 JVM, and 4 to Oracle JVM. Oracle JVM developers accept and fix 3 non-conformance candidates. Eclipse OpenJ9 JVM developers accept and fix 1 non-conformance candidate."
A theoretical and empirical study of diversity-aware mutation adequacy criterion,"['D Shin', 'S Yoo', 'DH Bae']",,"Developers of widely used Application Programming Interfaces (APIs) implement and test APIs based on a document, which is commonly specified using natural language. How- ever, there is limited knowledge on whether API developers are able to systematically reveal i) underdetermined specifications; and ii) non-conformances between their implementation and the specification. To better understand the problem, we analyze test suites of Java Reflection API, and we conduct two surveys. A survey with 130 developers who use the Java Reflection API, and a survey with 128 C# developers who use and implement the .NET Reflection API to see whether the specification impacts on their understanding. We also propose a technique to detect underdetermined specifications and non-conformances between the specification and the implementations of the APIs. It automatically creates test cases, and executes them using different implementations. It saves objects yielded by methods to be used to create more test cases. If results differ, it detects an underdetermined specification or a non-conformance candidate between the specification and at least one implementation of the API. We evaluate our technique using the Java Reflection API in 446 input programs. Our technique identifies underdetermined specification and non-conformance candidates in 32 Java Reflection API public methods of 7 classes. We report underdetermined specification candidates in 12 Java Reflection API methods. Java Reflection API specifiers accept 3 underdetermined specification candidates (25%). We also report 24 non-conformance candidates to Eclipse OpenJ9 JVM, and 7 to Oracle JVM. Eclipse OpenJ9 JVM developers accept and fix 21 candidates (87.5%), and Oracle JVM developers accept 5 and fix 4 non-conformance candidates. Twelve test cases are now part of the Eclipse OpenJ9 JVM test suite. We also evaluate our technique using the Java Collections API. Even being a very popular Java API, our technique identifies 29 underdetermined specification and non-conformance candidates. Our technique identifies 17 candidates that cannot be detected by popular automatic test suite generators. We report 5 underdetermined specification candidates to the Java Collections API specifiers. We also report 9 non-conformance candidates to Eclipse OpenJ9 JVM, and 4 to Oracle JVM. Oracle JVM developers accept and fix 3 non-conformance candidates. Eclipse OpenJ9 JVM developers accept and fix 1 non-conformance candidate."
A unified test case prioritization approach,"['D Hao', 'L Zhang', 'L Zhang', 'G Rothermel']",,"Test case prioritization techniques attempt to reorder test cases in a manner that increases the rate at which faults are detected during regression testing. Coverage-based test case prioritization techniques typically use one of two overall strategies: a total strategy or an additional strategy. These strategies prioritize test cases based on the total number of code (or code-related) elements covered per test case and the number of additional (not yet covered) code (or code-related) elements covered per test case, respectively. In this article, we present a unified test case prioritization approach that encompasses both the total and additional strategies. Our unified test case prioritization approach includes two models (basic and extended) by which a spectrum of test case prioritization techniques ranging from a purely total to a purely additional technique can be defined by specifying the value of a parameter referred to as the fp value. To evaluate our approach, we performed an empirical study on 28 Java objects and 40 C objects, considering the impact of three internal factors (model type, choice offp value, and coverage type) and three external factors (coverage granularity, test case granularity, and programming/testing paradigm), all of which can be manipulated by our approach. Our results demonstrate that a wide range of techniques derived from our basic and extended models with uniform fp values can outperform purely total techniques and are competitive with purely additional techniques. Considering the influence of each internal and external factor studied, the results demonstrate that various values of each factor have nontrivial influence on test case prioritization techniques."
APTE: Automated pointcut testing for AspectJ programs,"['P Anbalagan', 'T Xie']",,"Aspect-Oriented Programming (AOP) has been proposed as a methodology that provides new modularization of software systems by allowing encapsulation of cross-cutting concerns. AspectJ, an aspect-oriented programming language, provides two major constructs: advice and pointcuts. The scope of pointcuts spans across various objects instantiated from the classes. With the increase in the number of objects, classes, and integration of source code, it is likely that a developer writes a pointcut that does not serve its intended purpose. Therefore, there is a need to test pointcuts for validating the correctness of their expressions.In this paper, we propose APTE, an automated framework that tests pointcuts in AspectJ programs with the help of AJTE, an existing unit-testing framework without weaving. Our new APTE framework identifies joinpoints that satisfy a pointcut expression and a set of boundary joinpoints, which are events that do not satisfy a pointcut expression but are close to the matched joinpoints. The boundary joinpoints are identified as those unmatched join-point candidates whose distance from the matched joinpoints are less than a predefined threshold value. A developer could inspect these matched joinpoints and boundary joinpoints for correctness of the pointcuts."
Adaptive random testing based on flexible partitioning,"['C Mao', 'X Zhan', 'J Chen', 'J Chen', 'R Huang']",,"Adaptive random testing (ART) achieves better failure-detection effectiveness than random testing due to its even spreading of test cases. ART by random partitioning (RP-ART) is a lightweight method, but its advantage over random testing is relatively low. Although iterative partition testing (IPT) method has good performance for detecting failures in a block pattern, it loses randomness during the test case generation. To overcome the shortcomings of the above two algorithms, a new algorithm named ART by flexible partitioning (FP-ART) is proposed. In the FP-ART, a set of random candidates is used to select an appropriate test case by considering their boundary distance. Accordingly, the corresponding sub-domain is also partitioned by the new test case. Based on this kind of flexible partitioning, the randomness of test case selection can be guaranteed and the spatial distribution of test cases is even more diverse. According to the results in simulation and empirical experiments, FP-ART demonstrates better failure-detection effectiveness than RP-ART and is more suitable to detect the failures in strip patterns than the IPT method. Meanwhile, its failure-detection ability is much stronger than that of fixed-size-candidate-set ART in the cases of a relatively high failure rate."
Adequate system-level testing of distributed systems,['MJ Rutherford'],,"Software testing is about risk management. Typically, engineers use test adequacy criteria to balance the cost and efficacy of the testing activity. Test adequacy criteria are rules that provide an objective stopping condition on test input creation by defining a finite set of test requirements that must be satisfied. While adequacy criteria have been a focus of research activity for many years, existing testing criteria do not address the unique features of distributed applications. The contributions of this dissertation are: (1) a study of reported failure scenarios of seven distributed applications; (2) a novel testing technique based on discrete-event simulations that serves as a basis for adequacy criteria for distributed systems; (3) a fault-based analysis technique that allows testers to addresses the fundamental risks associated with using adequacy criteria; and (4) a case-study evaluation of the simulation-based and fault-based techniques. The failure study involves the categorization of test inputs and observations needed to replicate failures reported by users. The results show that failure-producing scenarios are amenable to categorization, that simple system topologies are likely to be quite effective, and that a significant proportion of failure-producing scenarios involve distributed inputs. Thus, the results confirm our intuition that distributed systems need their own class of adequacy criteria. Rather than inventing a new specification formalism, we instead adapt the common practice of using discrete-event simulations for the design and understanding of distributed systems to testing. Our key observation is that these simulations can be viewed as specifications of the expected behavior of the system. Using simulations to test the implementation of a system is therefore a matter of selecting inputs to cover the simulation according to some criterion, and then mapping the inputs into the implementation domain. As simulations are sequential programs themselves, virtually all black- and white-box criteria can be used with a simulation-based technique. When using any adequacy criterion for testing, there is generally no way for engineers to know a priori how effective a test suite or the criterion itself is going to be on their system. To mitigate this risk within the context of simulation-based testing, we propose a fault-based analysis technique that uses code mutation operators to create a set of incorrect simulations. Candidate test cases are executed against each of these specification mutants and the number killed is used as a surrogate measure of effectiveness. We evaluate the simulation-based technique and the companion fault-based analysis method on 28 implementations of three distributed systems. The results of these experiments are striking. First, we confirm that discrete-event simulations can indeed be used in testing, and that white-box techniques based on the simulation are both effective, and cost-effective when compared to randomly selected test suites of the same size. Second, in a significant advancement of the state of the art, we demonstrate the power of the fault-based analyses by improving the effectiveness of adequate suites within each criterion, and by predicting exactly the overall relationships between different criteria."
Advances in combinatorial testing,['R Tzoref-Brill'],,"Since their introduction into software testing in the mid-1980s, combinatorial methods for test design gathered popularity as a testing best practice and as a prominent software testing research area. This chapter reviews recent advances in combinatorial testing, with special focus on the research since 2011. It provides a brief background on the theory behind combinatorial testing and on its use in practice. Requirements from industry usage have led to advances in various areas examined in this chapter, including constraints handling in combinatorial algorithms, support for the combinatorial modeling process, and studies on metrics to support the effectiveness of combinatorial testing. We also highlight recent case studies describing novel use cases for test and field quality improvement in the context of system test, and for optimization of test data. Finally, we examine recent developments in advanced topics such as utilization of existing tests, test case prioritization, fault localization, and evolution of combinatorial models."
An analysis of Mutation testing and Code coverage during progress of projects,['O Alfsson'],,"In order to deliver high quality software projects, a developing team probably needs a well-developed test suite. There are several methods that aim to evaluate test suites in some way, such as Code coverage and Mutation testing. Code coverage describes the degree of source code that a program executes when running a test suite. Mutation testing measures the test suite effectiveness. More development teams use code coverage to a greater extent than mutation testing. With code coverage being monitored throughout a project, could the development team risk drop of the test suite effectiveness as the codebase getting bigger with each version? In this thesis, a mutation testing tool called PIT is used during progress of four well known open source projects. The reason for this is to show that mutation testing is an important technique to ensure continuously high test suite effectiveness, and does not only rely on code coverage measurements. In general, all projects perform well in both code coverage and test suite effectiveness, with the exception of one project inwhich the test suite effectiveness drops drastically. This drop shows that all projects are at risk of low test suite effectiveness, by not using mutation testing techniques."
An analysis of the effectiveness of different coverage criteria for testing relational database schema integrity constraints,"['P McMinn', 'CJ Wright', 'GM Kapfhammer']",,"Despite industry advice to the contrary, there has been little work that has sought to test that a relational database’s schema has correctly specified integrity constraints. These critically important constraints ensure the coherence of data in a database, defending it from manipulations that could violate requirements such as “usernames must be unique” or “the host name cannot be missing or unknown”. This paper is the first to propose coverage criteria, derived from logic coverage criteria, that establish different levels of testing for the formulation of integrity constraints in a database schema. These range from simple criteria that mandate the testing of successful and unsuccessful INSERT statements into tables to more advanced criteria that test the formulation of complex integrity constraints such as multi-column PRIMARY KEYs and arbitrary CHECK constraints. Due to different vendor interpretations of the structured query language (SQL) specification with regard to how integrity constraints should actually function in practice, our criteria crucially account for the underlying semantics of the database management system (DBMS). After formally defining these coverage criteria and relating them in a subsumption hierarchy, we present two approaches to automatically generating tests that satisfy the criteria. We then describe the results of an empirical study that uses mutation analysis to investigate the fault-finding capability of data generated when our coverage criteria are applied to a wide variety of relational schemas hosted by three well-known and representative DBMSs — HyperSQL, PostgreSQL and SQLite. In addition to revealing the complementary fault-finding capabilities of the presented criteria, the results show that mutation scores range from as low as just 12% of mutants being killed with the simplest of criteria to 96% with the most advanced."
An approach for testing pointcut descriptors in aspectj,"['R Delamare', 'B Baudry', 'S Ghosh']",,"Aspect-oriented programming (AOP) promises better software quality through enhanced modularity. Crosscutting concerns are encapsulated in separate units called aspects and are introduced at specific points in the base program at compile time or runtime. However, aspect-oriented mechanisms also introduce new risks for reliability that must be tackled by specific testing techniques in order to fully benefit from the use of AOP. This paper focuses on the pointcut descriptor (PCD) that declares the set of points in the base program's execution where the crosscutting concern must be woven. A fault in the PCD can have a ripple effect and result in many different faults. New behavior may be added in unexpected places, or places where new behavior should be added may be missed. When implementing aspect-oriented programs with AspectJ, JUnit is most commonly used to test the program. However, JUnit does not offer any mechanism to look for faults specifically located in the PCD. As a consequence, these faults can be detected only through complex test scenarios and side effects that are difficult to trigger and observe. This paper proposes to monitor the execution of advices in an aspect-oriented program and use this information to build test cases that target faults in PCDs. The AdviceTracer tool has been developed to automatically monitor and store all information related to advice executions. It also offers a set of operations that can be used to check the presence or absence of advices at specific points in the execution. These operations improve the definition of an oracle for PCD test cases. An empirical study is performed to compare JUnit and AdviceTracer for testing PCDs in terms of the complexity of test cases and their ability to detect faults. The study is performed on a Healthwatcher system that has 93 classes and 19 PCDs. It reveals that test cases that use AdviceTracer to test PCDs are easier to write (shorter test cases and written in less time than with JUnit) and detect more faults."
An empirical comparison of fixed-strength and mixed-strength for interaction coverage based prioritization,"['R Huang', 'Q Zhang', 'TY Chen', 'J Hamlyn-Harris']",,"Test case prioritization (TCP) plays an important role in identifying, characterizing, diagnosing, and correcting faults quickly. The TCP has been widely used to order test cases of different types, including model inputs (also called abstract test cases). Model inputs are constructed by modeling the program according to its input parameters, values, and constraints, and has been used in different testing methods, such as combinatorial interaction testing and software product line testing. The Interaction coverage-based TCP (ICTCP) uses interaction coverage information derived from the model input to order inputs. Previous studies have focused generally on the fixed-strength ICTCP, which adopts a fixed strength (i.e., the level of parameter interactions) to support the ICTCP process. It is generally accepted that using more strengths for ICTCP, i.e., mixed-strength ICTCP, may give better ordering than fixed-strength. To confirm whether mixed-strength is better than fixed-strength, in this paper, we report on an extensive empirical study using five real-world programs (written in C), each of which has six versions. The results of the empirical studies show that mixed-strength has better rates of interaction coverage overall than fixed-strength, but they have very similar rates of fault detection. Our results also show that fixed-strength should be used instead of the mixed-strength at the later stage of software testing. Finally, we offer some practical guidelines for testers when using interaction coverage information to prioritize model inputs, under different testing scenarios and resources."
An empirical comparison of mutant selection approaches,"['R Gopinath', 'A Alipour', 'I Ahmed', 'C Jensen', 'A Groce']",,"Mutation analysis is a well-known method for measuring the quality of test suites. However, it is computationally intensive compared to other measures, which makes it hard to use in practice. Choosing a smaller subset of mutations to run is a simple approach that can alleviate this problem. Mutation operator selection has been heavily researched. Recently, researchers have found that sampling mutants can achieve accuracy and mutant reduction similar to operator selection. However, the empirical support for these conclusions has been limited, due to the small number of subject programs investigated. The best sampling technique is also an open problem. Our research compares a large number of sampling and operator selection criteria based on their ability to predict the full mutation score as well as the consistency of mutation reduction ratios achieved. Our results can be used to choose an appropriate mutation reduction technique by the reduction and level of fidelity to full mutation results required. We find that all sampling approaches perform better than operator selection methods, when considering ability to predict the full mutation score as well as the consistency of mutation reduction ratios achieved."
An empirical study of test suites in practice against test suites generated by dynamic symbolic execution,['P Tanofsky'],,"Software testing performs a vital function in the software development lifecycle of quality assurance. Due to the time-intensive and often prohibitive costs of software testing, research efforts attempt to identify and improve approaches to automated test-case generation. Research efforts for these automated techniques provide evaluations of effectiveness and performance of the generated test cases, but rarely compare the effectiveness against test suites used in popular, real-world projects, which are developed in part by professional software developers and testers. Without the direct comparison of the two types of test suites, the strengths and weaknesses of the automatically-generated test cases are difficult to determine, which makes the added benefit or potential replacement value of the automatically-generated test cases hard to establish. Our research provides an empirical study of automatically-generated test suites and the test suites in practice by comparing their respective test sufficiency and test efficiency. The study provides insight into the similarities and differences between the two types of test suites. We begin by locating test cases in practice which are test cases included with the real-world project and developed by software developers and testers. Then, the second test suite is built from test cases created by a mature off-the-shelf, automated test-generation tool using dynamic symbolic execution (i.e., KLEE). The results of the study show the automatically-generated test suites typically outperform the code coverage of the test suites in practice but achieve poorer results in killing mutants and solving hard-testing problems. The automatically-generated test suites exhibit stronger data validation capabilities, while the test suites in practice present better focus on meaningful paths of code execution."
An ensemble‐based predictive mutation testing approach that considers impact of unreached mutants,['A Aghamohammadi'],,"Predictive mutation testing (PMT) is a technique to predict whether a mutant is killed, using machine learning approaches. Researchers have proposed various methods for PMT over the years. However, the impact of unreached mutants on PMT is not fully addressed. A mutant is unreached if the statement on which the mutant is generated is not executed by any test cases. We aim at showing that unreached mutants can inflate PMT results. Moreover, we propose an alternative approach to PMT, suggesting a different interpretation for PMT. To this end, we replicated the previous PMT research. We empirically evaluated the suggested approach on 654 Java projects provided by prior literature. Our results indicate that the performance of PMT drastically decreases in terms of area under a receiver operating characteristic curve (AUC) from 0.833 to 0.517. Furthermore, PMT performs worse than random guesses on 27% of the projects. The proposed approach improves the PMT results, achieving the average AUC value of 0.613. As a result, we recommend researchers to remove unreached mutants when reporting the results."
An experience report on applying software testing academic results in industry: we need usable automated test generation,['A Arcuri'],,"What is the impact of software engineering research on current practices in industry? In this paper, I report on my direct experience as a PhD/post-doc working in software engineering research projects, and then spending the following five years as an engineer in two different companies (the first one being the same I worked in collaboration with during my post-doc). Given a background in software engineering research, what cutting-edge techniques and tools from academia did I use in my daily work when developing and testing the systems of these companies? Regarding validation and verification (my main area of research), the answer is rather short: as far as I can tell, only FindBugs. In this paper, I report on why this was the case, and discuss all the challenging, complex open problems we face in industry and which somehow are “neglected” in the academic circles. In particular, I will first discuss what actual tools I could use in my daily work, such as JaCoCo and Selenium. Then, I will discuss the main open problems I faced, particularly related to environment simulators, unit and web testing. After that, popular topics in academia are presented, such as UML, regression and mutation testing. Their lack of impact on the type of projects I worked on in industry is then discussed. Finally, from this industrial experience, I provide my opinions about how this situation can be improved, in particular related to how academics are evaluated, and advocate for a greater involvement into open-source projects."
An integrated approach to software testing and learning,['M Zhang'],,"Software testing – the most commonly used approach for findings bugs – and machine learning – the most popular approach for extracting information from data – are two classic yet disparate approaches that serve largely different purposes and employ fairly unique techniques. Our thesis is that there is a novel bi-directional integration of the approaches that can make each of them more effective. In one direction, we define techniques based on the fundamentals of machine learning to enhance finding and removing bugs in various software systems. In the other direction, we define techniques based on the fundamentals of software testing to enhance the quality of machine learning systems. Our research consists of three thrusts. One, we define ePRFL, which uses the PageRank algorithm and Method-level aggregation technique to boost the accuracy of traditional techniques for localizing bugs in code. Two, we define DeepRoad, a GAN-Based Metamorphic Testing and Input Validation framework for DNN-based autonomous driving systems. Three, we define an analysis approach based on symbolic execution to study properties of deep neural networks. We embody the techniques in automated tools and evaluate them using standard benchmarks. The experimental results show the usefulness of our techniques."
An iterative metamorphic testing technique for web services and case studies,"['C Sun', 'A Fu', 'Y Liu', 'Q Wen', 'Z Wang']",,"Metamorphic testing (MT) is an innovative approach to alleviating the oracle problem in software testing, which uses metamorphic relations of the program under test, instead of the test oracles, to verify its outputs. To alleviate the oracle problem of testing web services, we had previously proposed an MT framework for web services. In this paper, we further improve the efficiency and automation of this framework by leveraging metamorphic relations to iteratively generate test cases. We present a fixed-size iterative MT algorithm and implement it in the MT framework. We conduct three case studies to evaluate the fault detection effectiveness and efficiency of the proposed approach. Experimental results suggest that, compared with the conventional MT, iterative MT can achieve a comparable fault detection effectiveness, but with significantly fewer resources. Observations and limitations are summarised to provide new insights into the application of iterative MT."
"An “objects first, tests second” approach for software engineering education","['V Thurner', 'A Böttcher']",,"Since unit testing is a skill required of professional software developers, lecturers have to develop this skill in their software engineering students. Therefore, we introduce the approach of “objects first, tests second”, which incorporates unit testing into introductory programming classes. We discuss requirements that teaching materials must meet to effectively support this approach, and present a concept for assessing the quality of student written tests. An analysis of students' results illustrates the effectiveness of this teaching approach."
Analysis and validation of test case redundancy in testing suites of Java libraries,['M Wolfart'],,"When studying the test suites from some Java libraries, it is possible to observe a certain redundancy in the execution paths that some of the test cases take, whose reason is not known. In order to understand this issue, we establish two hypotheses: one that this redundancy happens due to the suite being an automatically generated suite, and one that it comes from test cases that test inputs of different natures, such as empty strings or null strings. To validate these hypotheses, we perform a detailed study by analysing the behavior of the test cases and the associated application code. We consider a code coverage criterion, computed by generating the test path of each test case in the suite and comparing these with the prime path coverage of the tested methods. For this procedure we first adapted a coverage analysis tool that considers the prime path coverage criterion, and afterwards we collected additional data about the application code and the test suite in order to understand the rationale behind the tests. Finally, a manual analysis is made in the source code of the methods being tested and their respective test cases. Results show that the projects’ suites are closer to a developer-implemented suite, and not a generated one. It also shows that, when studying the tests with redundant test paths, most consist of cases that test different types of input - our second hypothesis. There are some cases that do not have a clear purpose and test very similar inputs, with some being even duplicated, but this occurs in a considerably insignificant scale."
Analysis of test coverage metrics in a business critical setup,['S Mishra'],,"Test coverage is an important parameter of analyzing how well the product is being tested in any domain within the IT industry. Unit testing is one of the important processes that have gained even more popularity with the rise in Test driven development (TDD) culture.This degree project, conducted at NASDAQ Technology AB, analyzes the existing unit tests in one of the products, and compares various coverage models in terms of quality. Further, the study examines the factors that affect code coverage, presents the best practices for unit testing, and a proven test process used in a real world project.To conclude, recommendations are given to NASDAQ based on the findings of this study and industry standards."
Analysis of test suite reduction with enhanced tie-breaking techniques,"['JW Lin', 'CY Huang']",,"Test suite minimization techniques try to remove redundant test cases of a test suite. However, reducing the size of a test suite might reduce its ability to reveal faults. In this paper, we present a novel approach for test suite reduction that uses an additional testing criterion to break the ties in the minimization process. We integrated the proposed approach with two existing algorithms and conducted experiments for evaluation. The experiment results show that our approach can improve the fault detection effectiveness of reduced suites with a negligible increase in the size of the suites. Besides, under specific conditions, the proposed approach can also accelerate the process of minimization."
Angels and monsters: An empirical investigation of potential test effectiveness and efficiency improvement from strongly subsuming higher order mutation,"['M Harman', 'Y Jia', 'P Reales Mateo', 'M Polo']",,"We study the simultaneous test effectiveness and efficiency improvement achievable by Strongly Subsuming Higher Order Mutants (SSHOMs), constructed from 15,792 first order mutants in four Java programs. Using SSHOMs in place of the first order mutants they subsume yielded a 35%-45% reduction in the number of mutants required, while simultaneously improving test efficiency by 15% and effectiveness by between 5.6% and 12%. Trivial first order faults often combine to form exceptionally non-trivial higher order faults; apparently innocuous angels can combine to breed monsters. Nevertheless, these same monsters can be recruited to improve automated test effectiveness and efficiency."
Ante up: A framework to strengthen student-based testing of assignments,['MK Bradshaw'],,"We introduce the Ante framework to automate the evaluation of student tests in such a way that students will see them as an integral part of the software development process. Our unique approach is to evaluate student testing before students are allowed to submit implementations of the assignment. By evaluating student testing, we can ensure that 1) students understand the assignment before moving on to implementing it and 2) students have a set of tests to aid in implementing their assignment. In this paper we will describe the existing tools and techniques to evaluate student testing, discuss the process of utilizing this framework from both the student and instructor points of view, describe the technical and usability issues in crafting Ante, and report preliminary feedback of student attitudes towards testing in the context of this new paradigm."
Applying automated testing in an existing client-server game: A pursuit for fault localization in Quake 3,"['H Kljajic', 'O Karlsson']",,"This paper addresses the question formulation “Is it possible to implement automated testing in an existing client-server game in order to pinpoint faults and achieve credibility to tests?” The gaming industry’s goal, in most cases, is to release games that appeal to both their financial goals and the enjoyment factor of the players. In order to fulfill these goals, the game will need to function properly and the process to assure this is testing the game to find possible faults. This process is time and cost consuming in an exponential rate in accordance to game extensiveness, which makes this problem a very important decision in the process of development. The problem is most commonly tackled by using massive manual testing session, called alpha or beta sessions. In these session the game is at an early stage of development and gets released to a set player base to test and report issues encountered. We believe that the process of testing games could be more effective by utilizing automated testing. This thesis will investigate the possibilities to our claim. The result is a visual representation of the tests we managed to apply, while focusing on the client-server connectivity of Quake 3 and a graph of measurements for our improvised fault localization. This paper describes a solution in form of automated tests within a existing client-server game and a start to what could be early stages of a pattern obtained throughout this project."
Are mutation scores correlated with real fault detection? a large scale empirical study on the relationship between mutants and real faults,"['M Papadakis', 'D Shin', 'S Yoo']",,"Empirical validation of software testing studies is increasingly relying on mutants. This practice is motivated by the strong correlation between mutant scores and real fault detection that is reported in the literature. In contrast, our study shows that correlations are the results of the confounding effects of the test suite size. In particular, we investigate the relation between two independent variables, mutation score and test suite size, with one dependent variable the detection of (real) faults. We use two data sets, CoreBench and De-fects4J, with large C and Java programs and real faults and provide evidence that all correlations between mutation scores and real fault detection are weak when controlling for test suite size. We also found that both independent variables significantly influence the dependent one, with significantly better fits, but overall with relative low prediction power. By measuring the fault detection capability of the top ranked, according to mutation score, test suites (opposed to randomly selected test suites of the same size), we found that achieving higher mutation scores improves significantly the fault detection. Taken together, our data suggest that mutants provide good guidance for improving the fault detection of test suites, but their correlation with fault detection are weak."
Are unit and integration test definitions still valid for modern Java projects? An empirical study on open-source projects,"['F Trautsch', 'S Herbold', 'J Grabowski']",,"Context: Unit and integration testing are popular testing techniques. However, while the software development context evolved over time, the definitions remained unchanged. There is no empirical evidence, if these commonly used definitions still fit to modern software development. Objective: We analyze, if the existing standard definitions of unit and integration tests are still valid in modern software development contexts. Hence, we analyze if unit and integration tests detect different types of defects, as expected from the standard literature. Method: We classify 38,782 test cases into unit and integration tests according to the definition of the IEEE and use mutation testing to assess their defect detection capabilities. All integrated mutations are classified into five different defect types. Afterwards, we evaluate if there are any statistically significant differences in the results between unit and integration tests. Results: We could not find any evidence that one test type is more capable of detecting certain defect types than the other one. Our results suggest that the currently used definitions do not fit modern software development contexts. Conclusions: This finding implies that we need to reconsider the definitions of unit and integration tests and suggest that the current property-based definitions may be exchanged with usage-based definitions."
Aspect-oriented program testing: An annotated bibliography,"['AAA Ghani', 'RM Parizi']",,"Research in aspect-oriented software testing has resulted in many approaches as reported in literature. A few papers have devoted to literature survey in this field of research. However, the survey only focuses on certain selected topic and particular approaches rather than providing a comprehensive set of references that cover most of the work related to aspect-oriented software testing as a whole. In this case, there is no work yet reported in the literature to tackle this shortage. Therefore, in this paper a collection of 81 references drawn from journals, conference and workshop proceedings, thesis, and technical reports on the subject of testing aspect-oriented software is presented. Each reference is accompanied by a summary of important finding. The aim when selecting the references was to cover as many related articles starting from the first work on the subject in 2002 until the year 2011. For this reason, the bibliography is intended to help the researcher or practitioner, who is relatively new, in gathering information on the subject. The bibliography is organized according to the following sections: general introduction; background on the subject; issues in testing aspect-oriented software; fault models and types; testing coverage criteria; aspect-oriented testing techniques; and automated support for testing aspect-oriented software."
Assessing test artifact quality—A tertiary study,"['HKV Tran', 'M Unterkalmsteiner', 'J Börstler']",,"Context: Modern software development increasingly relies on software testing for an ever more frequent delivery of high quality software. This puts high demands on the quality of the central artifacts in software testing, test suites and test cases. Objective: We aim to develop a comprehensive model for capturing the dimensions of test case/suite quality, which are relevant for a variety of perspectives. Methods: We have carried out a systematic literature review to identify and analyze existing secondary studies on quality aspects of software testing artifacts. Results: We identified 49 relevant secondary studies. Of these 49 studies, less than half did some form of quality appraisal of the included primary studies and only 3 took into account the quality of the primary study when synthesizing the results. We present an aggregation of the context dimensions and factors that can be used to characterize the environment in which the test case/suite quality is investigated. We also provide a comprehensive model of test case/suite quality with definitions for the quality attributes and measurements based on findings in the literature and ISO/IEC 25010:2011. Conclusion: The test artifact quality model presented in the paper can be used to support test artifact quality assessment and improvement initiatives in practice. Furthermore, the model can also be used as a framework for documenting context characteristics to make research results more accessible for research and practice."
Assessing test quality,['D Schuler'],,"When developing tests, one is interested in creating tests of good quality that thoroughly test the program. This work shows how to assess test quality through mutation testing with impact metrics, and through checked coverage. Although there a different aspects that contribute to a test's quality, the most important factor is its ability to reveal defects, because software testing is usually carried out with the aim to detect defects. For this purpose, a test has to provide inputs that execute the defective code under such conditions that it causes an infection. This infection has to propagate and result in a failure, which can be detected by a check of the test. In the past, the aspect of test input quality has been extensively studied while the quality of checks has received less attention. The traditional way of assessing the quality of a test suite's checks is mutation testing. Mutation testing seeds artificial defects (mutations) into a program, and checks whether the tests detect them. While this technique effectively assesses the quality of checks, it also has two drawbacks. First, it places a huge demand on computing resources. Second, equivalent mutants, which are mutants that are semantically equivalent to the original program, dilute the quality of the results. In this work, we address both of these issues. We present the JAVALANCHE framework that applies several optimizations to enable automated and efficient mutation testing for real-life programs. Furthermore, we address the problem of equivalent mutants by introducing impact metrics to detect non-equivalent mutants. Impact metrics compare properties of tests suite runs on the original program with runs on mutated versions, and are based on abstractions over program runs such as dynamic invariants, covered statements, and return values. The intention of these metrics is that mutations that have a graver influence on the program run are more likely to be non-equivalent. Moreover, we introduce checked coverage, an alternative approach to measure the quality of a test suite's checks. Checked coverage determines the parts of the code that were not only executed, but that actually contribute to the results checked by the test suite, by computing dynamic backward slices from all explicit checks of the test suite."
Assessment of class mutation operators for C++ with the MuCPP mutation system,"['P Delgado-Pérez', 'I Medina-Bulo']",,"Context: Mutation testing has been mainly analyzed regarding traditional mutation operators involving structured programming constructs common in mainstream languages, but mutations at the class level have not been assessed to the same extent. This fact is noteworthy in the case of C++ despite being one of the most relevant languages including object-oriented features. Objective: This paper provides a complete evaluation of class operators for the C++ programming language. MuCPP, a new system devoted to the application of mutation testing to this language, was developed to this end. This mutation system implements class mutation operators in a robust way, dealing with the inherent complexity of the language. Method: MuCPP generates the mutants by traversing the abstract syntax tree of each translation unit with the Clang API, and stores mutants as branches in the Git version control system. The tool is able to detect duplicate mutants, avoid system headers, and drive the compilation process. Then, MuCPP is used to conduct experiments with several open-source C++ programs. Results: The improvement rules listed in this paper to reduce unproductive class mutants have a significant impact in the computational cost of the technique. We also calculate the quantity and distribution of mutants generated with class operators, which generate far fewer mutants than their traditional counterparts. Conclusions: We show that the tests accompanying these programs cannot detect faults related to particular object-oriented features of C++. In order to increase the mutation score, we create new test scenarios to kill the surviving class mutants for all the applications. The results confirm that, while traditional mutation operators are still needed, class operators can complement them and help testers further improve the test suite."
Automated Test Case Implantation to Test Untested Configurations: A Cost-Effective Search-Based Approach,"['D Pradhan', 'S Wang', 'T Yue', 'S Ali', 'M Liaaen']",,"Context: Modern large-scale software systems are highly configurable, and thus require a large number of test cases to be implemented and revised for testing a variety of system configurations. This makes testing highly configurable systems very expensive and time-consuming. Objective: Driven by our industrial collaboration with a video conferencing company, we aim to automatically analyze and implant existing test cases (i.e., an original test suite) to test the untested configurations. Method: We propose a search-based test case implantation approach (named as SBI) consisting of two key components: 1) Test case analyzer that statically analyzes each test case in the original test suite to obtain the program dependence graph for test case statements and 2) Test case implanter that uses multi-objective search to select suitable test cases for implantation using three operators, i.e., selection, crossover, and mutation (at the test suite level) and implants the selected test cases using a mutation operator at the test case level including three operations (i.e., addition, modification, and deletion). Results: We empirically evaluated SBI with an industrial case study and an open source case study by comparing the implanted test suites produced by SBI with the original test suite using evaluation metrics such as statement coverage (SC), branch coverage (BC), mutation score (MS). Results show that for both the case studies, the implanted test suites performed significantly better than the original test suites with on average 21.9% higher coverage of configuration variable values. For the open source case study, SBI managed to improve SC, BC, and MS with 4.8%, 7.5%, and 2.6%, respectively. Conclusion: SBI can be applied to automatically implant an existing test suite with the aim of testing untested configurations and thus achieving higher configuration coverage."
"Automated assessment of programming assignments: visual feedback, assignment mobility, and assessment of students' testing skills",['P Ihantola'],,"The main objective of this thesis is to improve the automated assessment of programming assignments from the perspective of assessment tool developers. We have developed visual feedback on functionality of students' programs and explored methods to control the level of detail in visual feedback. We have found that visual feedback does not require major changes to existing assessment platforms. Most modern platforms are web based, creating an opportunity to describe visualizations in JavaScript and HTML embedded into textual feedback. Our preliminary results on the effectiveness of automatic visual feedback indicate that students perform equally well with visual and textual feedback. However, visual feedback based on automatically extracted object graphs can take less time to prepare than textual feedback of good quality. We have also developed programming assignments that are easier to port from one server environment to another by performing assessment on the client-side. This not only makes it easier to use the same assignments in different server environments but also removes the need for sandboxing the execution of students' programs. The approach will likely become more important in the future together with interactive study materials becoming more popular. Client-side assessment is more suitable for self-studying material than for grading because assessment results sent by a client are often too easy to falsify. Testing is an important part of programming and automated assessment should also cover students' self-written tests. We have analyzed how students behave when they are rewarded for structural test coverage (e.g. line coverage) and found that this can lead students to write tests with good coverage but with poor ability to detect faulty programs. Mutation analysis, where a large number of (faulty) programs are automatically derived from the program under test, turns out to be an effective way to detect tests otherwise fooling our assessment systems. Applying mutation analysis directly for grading is problematic because some of the derived programs are equivalent with the original and some assignments or solution strategies generate more equivalent mutants than others."
Automated isolation for white-box test generation,"['D Honfi', 'Z Micskei']",,"Context: White-box test generation is a technique used for automatically selecting test inputs using only the code under test. However, such techniques encounter challenges when applying them to complex programs. One of the challenges is handling invocations to external modules or dependencies in the code under test. Objective: Without using proper isolation, like mocks, generated tests cannot cover all parts of the source code. Moreover, invoking external dependencies may cause unexpected side effects (e.g., accessing the file system or network). Our goal was to tackle this issue while maintaining the advantages of white-box test generation. Method: In this paper, we present an automated approach addressing the external dependency challenge for white-box test generation. This technique isolates the test generation and execution by transforming the code under test and creating a parameterized sandbox with generated mocks. We implemented the approach in a ready-to-use tool using Microsoft Pex as a test generator, and evaluated it on 10 open-source projects from GitHub having more than 38.000 lines of code in total. Results: The results from the evaluation indicate that if the lack of isolation hinders white-box test generation, then our approach is able to help: it increases the code coverage reached by the automatically generated tests, while it prevents invoking any external module or dependency. Also, our results act as a unique baseline for the test generation performance of Microsoft Pex on open-source projects. Conclusion: Based on the results, our technique might serve well for handling external dependencies in white-box test generation as it increases the coverage reached in such situations, while maintaining the practical applicability of the tests generated on the isolated code."
Automated regression unit test generation for program merges,"['T Ji', 'L Chen', 'X Mao', 'X Yi', 'J Jiang']",,"Merging other branches into the current working branch is common in collaborative software development. However, developers still heavily rely on the textual merge tools to handle the complicated merge tasks. The latent semantic merge conflicts may fail to be detected and degrade the software quality. Regression testing is able to prevent regression faults and has been widely used in real-world software development. However, the merged software may fail to be well examined by rerunning the existing whole test suite. Intuitively, if the test suite fails to cover the changes of different branches at the same time, the merge conflicts would fail to be detected. Recently, it has been proposed to conduct verification on 3-way merges, but this approach does not support even some common cases such as different changes made to different parts of the program. In this paper, we propose an approach of regression unit test generation specifically for checking program merges according to our proposed test oracles. And our general test oracles support us to examine not only 3-way merges, but also 2-way and octopus merges. Considering the conflicts may arise in other locations besides changed methods of the project, we design an algorithm to select UUTs based on the dependency analysis of the whole project. On this basis, we implement a tool called TOM to generate unit tests for Java program merges. We also design the benchmark MCon4J consisting of 389 conflict 3-way merges and 389 conflict octopus merges to facilitate further studies on this topic. The experimental results show that TOM finds 45 conflict 3- way merges and 87 conflicts octopus merges, while the verification based tool fails to work on MCon4J."
Automated search for good coverage criteria: moving from code coverage to fault coverage through search-based software engineering,"['P McMinn', 'M Harman', 'G Fraser']",,"We propose to use Search-Based Software Engineering to automatically evolve coverage criteria that are well correlated with fault revelation, through the use of existing fault databases. We explain how problems of bloat and overfitting can be ameliorated in our approach, and show how this new method will yield insight into faults --- as well as better guidance for Search-Based Software Testing."
Automated strong mutation testing of XACML policies,"['D Xu', 'R Shrestha', 'N Shen']",,"While the existing methods for testing XACML policies have varying levels of effectiveness, none of them can reveal the majority of policy faults. The undisclosed faults may lead to unauthorized access and denial of service. This paper presents an approach to strong mutation testing of XACML policies that automatically generates tests from the mutants of a given policy. Such mutants represent the targeted faults that may appear in the policy. In this approach, we first compose the strong mutation constraints that capture the semantic difference between each mutant and its original policy. Then, we use a constraint solver to derive an access request (i.e., test). The test suite generated from all the mutants of a policy can achieve a perfect mutation score, thus uncover all hypothesized faults or demonstrate their absence. Based on the mutation-based approach, this paper further explores optimal test suite that achieves a perfect mutation score without duplicate tests. To evaluate the proposed approach, our experiments have included all the subject policies in the relevant literature and used a number of new policies. The results demonstrate that: (1) it is scalable to generate a mutation-based test suite to achieve a perfect mutation score, (2) it can be impractical to generate the optimal test suite due to the expensive removal of duplicate tests, (3) different from the results of the existing study, the modified-condition/decision coverage-based method, currently the most effective one, has low mutation scores for several policies."
Automated techniques for improving the quality of existing test suites,['C Huo'],,"Testing is playing a crucial and fundamental role in modern software development. Although software tests are conceptually simple – they are composed of two primary parts: inputs that are used to execute the program under test and an oracle that is used to verify that the execution induced by the inputs produces the expected results – they are often difficult to write in practice. The software engineering research community provided many techniques that can help developers determine whether they have written effective and efficient tests, including various coverage metrics which have been widely adopted. While they have been proven successful in practice, many follow-up studies show that there is still a lot to improve for the test quality measurements, including false negatives in alarming the lack of tests and constructive suggestions for improvements. ☐ This dissertation focuses on improving the quality of existing test suites based on interpretations on test inputs and test oracles. If a test oracle checks the values which the test developers did not or can not control, it would make the test brittle. I developed a novel technique based on dynamic tainting which can identify the values that can make tests brittle. An empirical study on real-world applications shows that the technique can reveal brittle assertions and the values that cause the brittleness within reasonable cost. I also developed two techniques that can identify insufficiently tested code by interpreting traditional coverage information. One is a new approach based on the concepts of direct coverage and indirect coverage. The other is a new approach to discover incidentally tested code. Both techniques have shown efficiency and effectiveness in the empirical studies on real-world applications."
Automated test case generation to validate non-functional software requirements,['P Zhang'],,"A software system is bounded by a set of requirements. Functional requirements describe what the system must do, in terms of inputs, the behavior, and outputs. Non-functional requirements describe how well these functional requirements are satisfied, in terms of qualities or constraints on the design or implementation of a system. Both requirements are integral parts of software design specification, and should be revisited constantly during all software development phases. In practice, however, technique support for validating these requirements, does not receive equal emphasis. Techniques for validating functional requirements target all levels of software testing phases, and explore both black box and white box approaches. Techniques for validating non-functional requirements, on the other hand, largely operate in a black box manner, and only focus on system testing level. As a result, most software companies put more efforts in validating functional requirements, and only assess non-functional requirements after functional validation is complete. We propose a set of exhaustive white-box testing techniques that enable cost-effective validation of non-functional requirements from two perspectives. For non-functional requirements defined as qualities of a system, we targeted load testing for the purpose of performance validation. We present a load test suite generation approach that uses symbolic execution to exhaustively traverse program execution paths and produce test cases for the ones that expose worst-case resource consumption scenarios. An assessment of the approach on a set of Java applications shows it generates test suites that induce program response times and memory consumption several times worse than the compared alternatives, it scales to large and complex inputs, and it exposes a diversity of resource consuming program behavior. For non-functional requirements defined as constraints on a system, we present an approach for validating contextual constraints that are imposed by external resources with which the software interacts. The approach amplifies existing tests in an exhaustive manner to validate exception handling constructs that are used to handle such constraints. Our assessment of the approach on a set of Android mobile applications indicates that it can be fully automated, is powerful enough to detect 65% of the faults reported in the bug reports of this kind, and is precise enough that 77% of the detected anomalies correspond to faults fixed by the developers. Combined, the two proposed techniques complement the field of automated software testing by providing exhaustive support for non-functional validation. In this proposal we will discuss the completed work as well as the work yet to be done. Once completed, this research will provide benefits for both researchers and practitioners. For researchers, our work paves the way for research on developing precise white box techniques for validating non-functional requirements. For practitioners, our approach provides support for generating non-functional test cases at all levels of software testing phases, especially at the unit testing level, where current tool support for non-functional validation is scarce."
Automatic software diversity in the light of test suites,"['B Baudry', 'S Allier', 'M Rodriguez-Cancio']",,"A few works address the challenge of automating software diversification, and they all share one core idea: using automated test suites to drive diversification. However, there is is lack of solid understanding of how test suites, programs and transformations interact one with another in this process. We explore this intricate interplay in the context of a specific diversification technique called 'sosiefication'. Sosiefication generates sosie programs, i.e., variants of a program in which some statements are deleted, added or replaced but still pass the test suite of the original program. Our investigation of the influence of test suites on sosiefication exploits the following observation: test suites cover the different regions of programs in very unequal ways. Hence, we hypothesize that sosie synthesis has different performances on a statement that is covered by one hundred test case and on a statement that is covered by a single test case. We synthesize 24583 sosies on 6 popular open-source Java programs. Our results show that there are two dimensions for diversification. The first one lies in the specification: the more test cases cover a statement, the more difficult it is to synthesize sosies. Yet, to our surprise, we are also able to synthesize sosies on highly tested statements (up to 600 test cases), which indicates an intrinsic property of the programs we study. The second dimension is in the code: we manually explore dozens of sosies and characterize new types of forgiving code regions that are prone to diversification."
Automatic test generation for industrial control software,['E Enoiu'],,"Since the early days of software testing, automatic test generation has been suggested as a way of allowing tests to be created at a lower cost. However, industrially useful and applicable tools for automatic test generation are still scarce. As a consequence, the evidence regarding the applicability or feasibility of automatic test generation in industrial practice is limited. This is especially problematic if we consider the use of automatic test generation for industrial safety-critical control systems, such as are found in power plants, airplanes, or trains. In this thesis, we improve the current state of automatic test generation by developing a technique based on model-checking that works with IEC 61131-3 industrial control software. We show how automatic test generation for IEC 61131-3 programs, containing both functional and timing information, can be solved as a model checking problem for both code and mutation coverage criteria. The developed technique has been implemented in the CompleteTest tool. To evaluate the potential application of our technique, we present several studies where the tool is applied to industrial control software. Results show that CompleteTest is viable for use in industrial practice; it is efficient in terms of the time required to generate tests that satisfy both code and mutation coverage and scales well for most of the industrial programs considered. However, our results also show that there are still challenges associated with the use of automatic test generation. In particular, we found that while automatically generated tests, based on code coverage, can exercise the logic of the software as well as tests written manually, and can do so in a fraction of the time, they do not show better fault detection compared to manually created tests. Specifically, it seems that manually created tests are able to detect more faults of certain types (i.e, logical replacement, negation insertion and timer replacement) than automatically generated tests. To tackle this issue, we propose an approach for improving fault detection by using mutation coverage as a test criterion. We implemented this approach in the CompleteTest tool and used it to evaluate automatic test generation based on mutation testing. While the resulting tests were more effective than automatic tests generated based on code coverage, in terms of fault detection, they still were not better than manually created tests. In summary, our results highlight the need for improving the goals used by automatic test generation tools. Specifically, fault detection scores could be increased by considering some new mutation operators as well as higher-order mutations. Our thesis suggests that automatically generated test suites are significantly less costly in terms of testing time than manually created test suites. One conclusion, strongly supported by the results of this thesis, is that automatic test generation is efficient but currently not quite as effective as manual testing. This is a significant progress that needs to be further studied; we need to consider the implications and the extent to which automatic test generation can be used in the development of reliable safety-critical systems."
Automatic testing and improvement of machine translation,"['Z Sun', 'JM Zhang', 'M Harman', 'M Papadakis']",,"This paper presents TransRepair, a fully automatic approach for testing and repairing the consistency of machine translation systems. TransRepair combines mutation with metamorphic testing to detect inconsistency bugs (without access to human oracles). It then adopts probability-reference or cross-reference to post-process the translations, in a grey-box or black-box manner, to repair the inconsistencies. Our evaluation on two state-of-the-art translators, Google Translate and Transformer, indicates that TransRepair has a high precision (99%) on generating input pairs with consistent translations. With these tests, using automatic consistency metrics and manual assessment, we find that Google Translate and Transformer have approximately 36% and 40% inconsistency bugs. Black-box repair fixes 28% and 19% bugs on average for Google Translate and Transformer. Grey-box repair fixes 30% bugs on average for Transformer. Manual inspection indicates that the translations repaired by our approach improve consistency in 87% of cases (degrading it in 2%), and that our repairs have better translation acceptability in 27% of the cases (worse in 8%)."
Automatic unit test amplification for DevOps,['B Danglot'],,"Over the last decade, strong unit testing has become an essential component of any serious software project, whether in industry or academia. The agile development movement has contributed to this cultural change with the global dissemination of test-driven development techniques. More recently, the DevOps movement has further strengthened the testing practice with an emphasis on continuous and automated testing. However, testing is tedious and costly for industry: it is hard to evaluate return on investment. Thus, developers under pressure, by lack of discipline or time might skip writing the tests. To overcome this problem, research investigates the automation of creating strong tests. The dream was that a command-line would give you a complete test suite, that verifies the whole program. Even if automatically generated test suites achieve high coverage, there are still obstacles on the adoption of such techniques by the industry. This can be explained by the difficulties to understand, integrate and maintain generated test suite. Also, most of the tools rely on weak or partial oracles, \eg absence of run-time errors, which limits their ability to find bugs. In this thesis, I aim at addressing the lack of a tool that assists developers in regression testing. To do so, I use test suite amplification. In this thesis, I define test amplification and review research works that are using test amplification. Test amplification consists of exploiting the knowledge of test methods, in which developers embed input data and expected properties, in order to enhance these manually written tests with respect to an engineering goal. In the state of the art, I reveal main challenges of test amplification and the main lacks. I propose a new approach based on both test inputs transformation and assertions generation to amplify the test suite. This algorithm is implemented in a tool called DSpot. In this thesis, I evaluate DSpot on open-source projects from GitHub. First, I improve the \ms of test suites and propose these improvements to developers through pull-requests. This evaluation shows that developers value the output of \dspot and thus accepted to integrate amplified test methods into their test suite. This proves that DSpot can improve the quality of real projects' test suites. Second, I use DSpot to detect the behavioral difference between two versions of the same program particularly to detect the behavioral change introduced by a commit. This shows that \dspot can be used in the continuous integration to achieve two crucial tasks: 1) generate amplified test methods that specify a behavioral change; 2) generate amplified test methods to improve the ability to detect potential regressions. In this thesis, I also expose three transversal contributions, related to the correctness of program. First, I study the programs' correctness under runtime perturbations. Second, I study the presence of pseudo-tested methods that are methods revealing weaknesses of the tests. Third, I study overfitting patches and test generation for automatic repair."
Automatically identifying special and common unit tests based on inferred statistical algebraic abstractions,"['T Xie', 'D Notkin']",,"Common and special test inputs can be created to exercise some common and special behavior of the class under test, respectively. Although manually created tests are valuable, programmers often overlook some special or even common test inputs. We have developed a new approach for automatically identifying special and common unit tests for a class without requiring any specification. Given a class, we automatically generates test inputs and identifies common and special tests among the generated tests. Programmers can inspect these identified tests and use them to augment existing tests. Our approach is based on statistical algebraic abstractions, program properties (in the form of algebraic specifications) dynamically inferred from test executions. We use statistical algebraic abstractions to characterize program behavior and identify special and common tests. Our initial experience has shown that many interesting test inputs could be identified among a large number of generated tests."
Automatically repairing programs using both tests and bug reports,"['M Motwani', 'Y Brun']",,"The success of automated program repair (APR) depends significantly on its ability to localize the defects it is repairing. For fault localization (FL), APR tools typically use either spectrum-based (SBFL) techniques that use test executions or information-retrieval-based (IRFL) techniques that use bug reports. These two approaches often complement each other, patching different defects. No existing repair tool uses both SBFL and IRFL. We develop RAFL (Rank-Aggregation-Based Fault Localization), a novel FL approach that combines multiple FL techniques. We also develop Blues, a new IRFL technique that uses bug reports, and an unsupervised approach to localize defects. On a dataset of 818 real-world defects, SBIR (combined SBFL and Blues) consistently localizes more bugs and ranks buggy statements higher than the two underlying techniques. For example, SBIR correctly identifies a buggy statement as the most suspicious for 18.1% of the defects, while SBFL does so for 10.9% and Blues for 3.1%. We extend SimFix, a state-of-the-art APR tool, to use SBIR, SBFL, and Blues. SimFix using SBIR patches 112 out of the 818 defects; 110 when using SBFL, and 55 when using Blues. The 112 patched defects include 55 defects patched exclusively using SBFL, 7 patched exclusively using IRFL, 47 patched using both SBFL and IRFL and 3 new defects. SimFix using Blues significantly outperforms iFixR, the state-of-the-art IRFL-based APR tool. Overall, SimFix using our FL techniques patches ten defects no prior tools could patch. By evaluating on a benchmark of 818 defects, 442 previously unused in APR evaluations, we find that prior evaluations on the overused Defects4J benchmark have led to overly generous findings. Our paper is the first to (1) use combined FL for APR, (2) apply a more rigorous methodology for measuring patch correctness, and (3) evaluate on the new, substantially larger version of Defects4J."
Automating program verification and repair using invariant analysis and test input generation,['TVH Nguyen'],,"Software bugs are a persistent feature of daily life—crashing web browsers, allowing cyberattacks, and distorting the results of scientific computations. One approach to improving software uses program invariants—mathematical descriptions of program behaviors—to verify code and detect bugs. Current invariant generation techniques lack support for complex yet important forms of invariants, such as general polynomial relations and properties of arrays. As a result, we lack the ability to conduct precise analysis of programs that use this common data structure. This dissertation presents DIG, a static and dynamic analysis framework for discovering several useful classes of program invariants, including (i) nonlinear polynomial relations, which are fundamental to many scientific applications; disjunctive invariants, (ii) which express branching behaviors in programs; and (iii) properties about multidimensional arrays, which appear in many practical applications. We describe theoretical and empirical results showing that DIG can efficiently and accurately find many important invariants in real-world uses, e.g., polynomial properties in numerical algorithms and array relations in a full AES encryption implementation. Automatic program verification and synthesis are long-standing problems in computer science. However, there has been a lot of work on program verification and less so on program synthesis. Consequently, important synthesis tasks, e.g., generating program repairs, remain difficult and time-consuming. This dissertation proves that certain formulations of verification and synthesis are equivalent, allowing for direct applications of techniques and tools between these two research areas. Based on these ideas, we develop CETI, a tool that leverages existing verification techniques and tools for automatic program repair. Experimental results show that CETI can have higher success rates than many other standard program repair methods."
Automating test oracles generation,['A Goffi'],,"    Software systems play a more and more important role in our everyday life. Many relevant human activities nowadays involve the execution of a piece of software. Software has to be reliable to deliver the expected behavior, and assessing the quality of software is of primary importance to reduce the risk of runtime errors. Software testing is the most common quality assessing technique for software. Testing consists in running the system under test on a finite set of inputs, and checking the correctness of the results. Thoroughly testing a software system is expensive and requires a lot of manual work to define test inputs (stimuli used to trigger different software behaviors) and test oracles (the decision procedures checking the correctness of the results). Researchers have addressed the cost of testing by proposing techniques to automatically generate test inputs. While the generation of test inputs is well supported, there is no way to generate cost-effective test oracles: Existing techniques to produce test oracles are either too expensive to be applied in practice, or produce oracles with limited effectiveness that can only identify blatant failures like system crashes. Our intuition is that cost-effective test oracles can be generated using information produced as a byproduct of the normal development activities. The goal of this thesis is to create test oracles that can detect faults leading to semantic and non-trivial errors, and that are characterized by a reasonable generation cost. We propose two ways to generate test oracles, one derives oracles from the software redundancy and the other from the natural language comments that document the source code of software systems. We present a technique that exploits redundant sequences of method calls encoding the software redundancy to automatically generate test oracles named CCOracles. We describe how CCOracles are automatically generated, deployed, and executed. We prove the effectiveness of CCOracles by measuring their fault-finding effectiveness when combined with both automatically generated and hand-written test inputs. We also present Toradocu, a technique that derives executable specifications from Javadoc comments of Java constructors and methods. From such specifications, Toradocu generates test oracles that are then deployed into existing test suites to assess the outputs of given test inputs. We empirically evaluate Toradocu, showing that Toradocu accurately translates Javadoc comments into procedure specifications. We also show that Toradocu oracles effectively identify semantic faults in the SUT. CCOracles and Toradocu oracles stem from independent information sources and are complementary in the sense that they check different aspects of the system undertest."
Boundary sampling to boost mutation testing for deep learning models,"['W Shen', 'Y Li', 'Y Han', 'L Chen', 'D Wu', 'Y Zhou']",,"Context: The prevalent application of Deep Learning (DL) models has raised concerns about their reliability. Due to the data-driven programming paradigm, the quality of test datasets is extremely important to gain accurate assessment of DL models. Recently, researchers have introduced mutation testing into DL testing, which applies mutation operators to generate mutants from DL models, and observes whether the test data can identify mutants to check the quality of test dataset. However, there still exist many factors (e.g., huge labeling efforts and high running cost) hindering the implementation of mutation testing for DL models. Objective: We desire for an approach to selecting a smaller, sensitive, representative and efficient subset of the whole test dataset to promote the current mutation testing (e.g., reduce labeling and running cost) for DL Models. Method: We propose boundary sample selection (BSS), which employs the distance of samples to decision boundary of DL models as the indicator to construct the appropriate subset. To evaluate the performance of BSS, we conduct an extensive empirical study with two widely-used datasets, three popular DL models, and 14 up-to-date DL mutation operators. Results: We observe that (1) The sizes of our subsets generated by BSS are much smaller (about 3%-20% of the whole test set). (2) Under most mutation operators, our subsets are superior (about 9.94-21.63) than the whole test sets in observing mutation effects. (3) Our subsets could replace the whole test sets to a very high degree (higher than 97%) when considering mutation score. (4) The MRR values of our proposed subsets are clearly better (about 2.28-13.19 times higher) than that of the whole test sets. Conclusions: The result shows that BSS can help testers save labelling cost, run mutation testing quickly and identify killed mutants early."
Can structural test adequacy criteria be used to predict the quality of generated invariants,['SK Rad'],,"The use of invariants during software development has many advantages. Among other things, invariants can be used to formally specify programs, to check certain vital properties at run-time, improve communication between programmers and make understanding programs easier. Despite these advantages, many programs lack explicit invariants. Dynamic invariant generation can automatically derive invariants from the program source but needs an initial test suite. Moreover, the quality of the generated invariants depends on this initial test suite. Many programs have test suites for detecting errors which are designed according to structural coverage criteria. In order to reuse these test suites for invariant generation, we must investigate the ability of structural coverage criteria to produce good quality invariants. An experiment was setup to investigate this ability. Our results indicate that there is indeed a correlation between structural coverage criteria and the quality of the generated invariants, but that in some cases this correlation can become weak due to other factors."
Can this fault be detected: A study on fault detection via automated test generation,"['P Ma', 'H Cheng', 'J Zhang', 'J Xuan']",,"Automated test generation can reduce the manual effort in improving software quality. A test generation method employs code coverage, such as the widely-used branch coverage, to guide the inference of tests. These tests can be used to detect hidden faults. An automatic tool takes a specific type of code coverage as a configurable parameter. Given an automated tool of test generation, a fault may be detected by one type of code coverage, but omitted by another. In frequently released software projects, the time budget of testing is limited. Configuring code coverage for a testing tool can effectively improve the quality of projects. In this paper, we conduct a study on whether a fault can be detected by specific code coverage in automated test generation. We build predictive models with 60 metrics of faulty source code to identify detectable faults under eight types of code coverage. In the experiment, an off-the-shelf tool, EvoSuite is used to generate test data. Experimental results based on four research questions show that different types of code coverage result in the detection of different faults; a code coverage can be used as a supplement to increase the number of detected faults if another coverage is applied first; for each coverage, the number of detected faults increases with its cutoff time in test generation. Our result shows that the choice of code coverage can be learned via multi-objective optimization from sampled faults and directly applied to new faults. This study can be viewed as a preliminary result to support the configuration of code coverage in the application of automated test generation."
Can you certify your software to MC/DC? A static analysis approach to account for the number test cases,"['AL Martins', 'ACV de Melo']",,"Software testing is an important task in systems development to certify the quality of the final product. If it is not properly applied, we can end up with low-quality systems. On the other hand, applying rigorous software testing techniques can spend nearly 40-50% of the system development cost. The issue is: how to provide a good software quality, by means of testing techniques, and keep the overall system cost under control? This paper presents a study on the cost of applying the Modified Condition/Decision Coverage (MC/DC) (proposed by NASA1 and used by FAA2 [19]) to software by accounting for the number of test cases that need to be generated. In order to achieve our goal, we collected the MC/DC coverage requirements in a set of open source software to estimate the cost of this criterion application in terms of the number of test cases."
Causal testing: understanding defects' root causes,"['B Johnson', 'Y Brun', 'A Meliou']",,"Understanding the root cause of a defect is critical to isolating and repairing buggy behavior. We present Causal Testing, a new method of root-cause analysis that relies on the theory of counterfactual causality to identify a set of executions that likely hold key causal information necessary to understand and repair buggy behavior. Using the Defects4J benchmark, we find that Causal Testing could be applied to 71% of real-world defects, and for 77% of those, it can help developers identify the root cause of the defect. A controlled experiment with 37 developers shows that Causal Testing improves participants' ability to identify the cause of the defect from 80% of the time with standard testing tools to 86% of the time with Causal Testing. The participants report that Causal Testing provides useful information they cannot get using tools such as JUnit. Holmes, our prototype, open-source Eclipse plugin implementation of Causal Testing, is available at http://holmes.cs.umass.edu/."
Characterization of open-source applications and test suites,"['S Balasubramanian', 'KR Walcott']",,"Software systems that meet the stakeholders needs and expectations is the ultimate objective of the software provider. Software testing is a critical phase in the software development lifecycle that is used to evaluate the software. Tests can be written by the testers or the automatic test generators in many different ways and with different goals. Yet, there is a lack of well-defined guidelines or a methodology to direct the testers to write tests We want to understand how tests are written and why they may have been written that way. This work is a characterization study aimed at recognizing the factors that may have influenced the development of the test suite. We found that increasing the coverage of the test suites for applications with at least 500 test cases can make the test suites more costly. The correlation coeffieicent obtained was 0.543. The study also found that there is a positive correlation between the mutation score and the coverage score."
Choosing the fitness function for the job: Automated generation of test suites that detect real faults,"['A Salahirad', 'H Almulla', 'G Gay']",,"Search-based unit test generation, if effective at fault detection, can lower the cost of testing. Such techniques rely on fitness functions to guide the search. Ultimately, such functions represent test goals that approximate—but do not ensure—fault detection. The need to rely on approximations leads to two questions—can fitness functions produce effective tests and, if so, which should be used to generate tests? To answer these questions, we have assessed the fault-detection capabilities of unit test suites generated to satisfy eight white-box fitness functions on 597 real faults from the Defects4J database. Our analysis has found that the strongest indicators of effectiveness are a high level of code coverage over the targeted class and high satisfaction of a criterion's obligations. Consequently, the branch coverage fitness function is the most effective. Our findings indicate that fitness functions that thoroughly explore system structure should be used as primary generation objectives—supported by secondary fitness functions that explore orthogonal, supporting scenarios. Our results also provide further evidence that future approaches to test generation should focus on attaining higher coverage of private code and better initialization and manipulation of class dependencies."
Code coverage at Google,"['M Ivanković', 'G Petrović', 'R Just', 'G Fraser']",,"Code coverage is a measure of the degree to which a test suite exercises a software system. Although coverage is well established in software engineering research, deployment in industry is often inhibited by the perceived usefulness and the computational costs of analyzing coverage at scale. At Google, coverage information is computed for one billion lines of code daily, for seven programming languages. A key aspect of making coverage information actionable is to apply it at the level of changesets and code review. This paper describes Google’s code coverage infrastructure and how the computed code coverage information is visualized and used. It also describes the challenges and solutions for adopting code coverage at scale. To study how code coverage is adopted and perceived by developers, this paper analyzes adoption rates, error rates, and average code coverage ratios over a five-year period, and it reports on 512 responses, received from surveying 3000 developers. Finally, this paper provides concrete suggestions for how to implement and use code coverage in an industrial setting."
Comparing acceptance testing and fuzz testing: a study with wearable pulse oximeter,['A Serrano de la Cruz Parra'],,"Software testing is one of the most critical activities during the software development life cycle. Overall, software testing is carried out to verify the correctness of the software, providing objective evidence that the software works as intended. The deficiency of software testing has led the industry to a huge economic loss throughout the years. Furthermore, misbehaving software has led to the loss of human lives, especially in the aviation and medical industries where safety-critical systems are used. In such cases, the implementation of appropriate software testing is crucial to prevent the occurrence of bugs after the release of the software to the customers. Acceptance testing is a software testing approach in which the software under test is proven to work according to the specified requirements. In other words, acceptance tests assess whether the software works as explicitly intended. The main purpose of acceptance tests is to prove that the software can be accepted and deliverable to the end users or customers. On the other hand, fuzz testing is a method that intends to input random or invalid data to an application with the intention of discovering potential crashes, errors, memory leaks or unexpected situations. In other words, fuzz testing is used to challenge the software in order to conclude how well this is prepared to handle unexpected situations. The aim of this thesis is to carry out acceptance and fuzz testing with a new wearable pulse oximeter developed by General Electric Healthcare Finland. The research methodology consists of first, the analysis of the wearable pulse oximeter, which is the device under test, followed by the design, implementation and execution of different tests cases that are based on acceptance and fuzz testing. The results of acceptance tests showed a reliable pulse oximeter that meets the specified software requirements. In other words, all the features of the sensor work as intended. Nevertheless, fuzz testing showed several issues in the pulse oximeter, including performance and security issues, as well as some design flaws that had not been taken into consideration before. Overall, considering the simplicity of the technique, the obtained results from fuzz testing were eye-opening."
Comparing coverage criteria for dynamic web application: An empirical evaluation,"['S Sherin', 'MZ Iqbal', 'MU Khan', 'AA Jilani']",,"Web applications have become popular and a preferred mean for users to do various crucial tasks such as selling and buying goods, doing short tasks, controlling smart houses and bank account management. The correctness of all such applications is important and requires thorough testing. Structural testing is widely used to achieve correctness in traditional software's, however, for web applications, it is challenging because of its dynamic and heterogeneous nature. To achieve desired structural coverage of web applications different dynamic coverage criteria are used as a quality assessment indicator. However, there is a lack of empirical evidence regarding the effectiveness of the proposed coverage criteria. In this paper, we conduct an empirical evaluation by evaluating and comparing the fault detection effectiveness and efficiency of various dynamic coverage criteria by performing mutation analysis. We conduct a series of experiments to assess and compare four widely used coverage criteria on seven open-source case studies including small to large scale applications. We performed mutation analysis by first generating different faulty versions (mutants) for the case studies and then by executing test suites to record mutation score for each criterion. The results from most of the subject applications show that DOM coverage is the most effective and efficient criterion followed by Virtual DOM, HTML Element and Statement coverage criteria."
"Comparing the effectiveness of automated test generation tools"" EVOSUITE"" and"" Tpalus""",['SCR Chitirala'],,"Automated testing has been evolving over the years and the main reason behind the growth of these tools is to reduce the manual effort in checking the correctness of any software. Writing test cases to check the correctness of software is very time consuming and requires a great deal of patience. A lot of time and effort used on writing manual test cases can be saved and in turn we can focus on improving the performance of the application. Statistics show that 50% of the total cost of software development is devoted to software testing, even more in the case of critical software. The growth of these automated test generation tools lead us to a big question of 'How effective are these tools in checking the correctness of the application?' There are several challenges associated with developing automated test generation tools and currently there is no particular tool or metric to check the effectiveness of these automated test generation tools. In my thesis, I aim to measure the effectiveness of two automated test generation tools. The two automated tools on which I have experimented on are Tpalus and EVOSUITE. Tpalus and EVOSUITE are capable of generating test cases for any program written in Java. They are specifically designed to work on Java. Several metrics have to be considered in measuring the effectiveness of a tool. I use the results obtained from these tools on several open source subjects to evaluate both the tools. The metrics that were chosen in comparing these tools include code coverage, mutation scores, and size of the test suite. Code coverage tells us how well the source code is covered by the test cases. A better test suite generally aims to cover most of the source code to consider each and every statement as a part of testing. A mutation score is an indication of the test suite detecting and killing mutants. In this case, a mutant is a new version of a program that is created by making a small syntactic change to the original program. The higher mutation score, the higher the number of mutants detected and killed. Results obtained during the experiment include branch coverage, line coverage, raw kill score and normalized kill score. These results help us to decide how effective these tools are when testing critical software."
Comparison of DC and MC/DC code coverages,"['Z Szugyi', 'Z Porkoláb']",,"In software development testing plays the most important role to discover bugs and to verify that the product satisfies its requirements. Several tests methods exist to check code correctness trying to find the best balance between precision and cost. Less strict ones require fewer test cases and consume less resources, however they may discover fewer errors. Chosing test methods is always a compromise between the code correctness and the available resources. In this paper we analyse two important testing methods, the Decision Coverage and the more strict Modified Condition / Decision Coverage in several aspects. We discuss how these aspects are affected by the difference of the necessary test cases for the testing methods. The analysis is done on open source programs written in C++."
Continuous test generation: Enhancing continuous integration with automated test generation,"['J Campos', 'A Arcuri', 'G Fraser', 'R Abreu']",,"In object oriented software development, automated unit test generation tools typically target one class at a time. A class, however, is usually part of a software project consisting of more than one class, and these are subject to changes over time. This context of a class offers significant potential to improve test generation for individual classes. In this paper, we introduce Continuous Test Generation (CTG), which includes automated unit test generation during continuous integration (i.e., infrastructure that regularly builds and tests software projects). CTG offers several benefits: First, it answers the question of how much time to spend on each class in a project. Second, it helps to decide in which order to test them. Finally, it answers the question of which classes should be subjected to test generation in the first place. We have implemented CTG using the EvoSuite unit test generation tool, and performed experiments using eight of the most popular open source projects available on GitHub, ten randomly selected projects from the SF100 corpus, and five industrial projects. Our experiments demonstrate improvements of up to +58% for branch coverage and up to +69% for thrown undeclared exceptions, while reducing the time spent on test generation by up to +83%."
Contribuições ao suporte cognitivo em teste de software unitário: um framework de tarefas e uma agenda de pesquisa,['MP Prado'],x (not English),
Cost-effective techniques for user-session-based testing of web applications,['S Sampath'],,"Increased use of web-based applications by businesses, government and consumers to perform their daily operations has led to the need for reliable, well-tested web applications. A short time to market, large user community, demand for con tinuous availability, and frequent updates motivate automated cost-effective testing strategies. One promising approach to testing the functionality of web applications leverages user-session data collected by web servers. This approach, called user-session-based testing, avoids the problem of generating artificial test cases by capturing real user interactions---rather than tester interactions---and utilizing the user sessions as representative of user behavior. The user sessions provide test data not anticipated during initial stages of testing. User-session-based testing focuses testing on parts of the application frequently used by the user. However, test preparation and execution quickly become impractical with a large number of captured sessions, which is typical in a frequently used application. This dissertation presents automated cost-effective testing strategies for web-based applications developed by applying a mathematical technique called concept analysis (with varying input parameters) to cluster user-session data. The proposed testing strategies are applicable in the beta/maintenance testing phases of the lifecycle of the application. The proposed strategies are particularly useful in the absence of traditional testing requirements and specifications. The research applies concept analysis to cluster user sessions. To avoid processing large user session data sets, a set of heuristics for test suite selection are applied and incremental test suite update is performed on-the-fly in the presence of an evolving application and evolving user sessions. The clustering techniques and selection heuristics are motivated by analyzing user sessions. User sessions are also analyzed to understand the longitudinal usage of the application which assists in focusing maintenance efforts. In addition, an automated testing framework to effectively test web applications is developed. The effectiveness of the reduced suites is evaluated with several empirical studies to determine their program coverage and fault detection effectiveness."
Coverage metrics for requirements-based testing: Evaluation of effectiveness,"['M Staats', 'M Whalen', 'A Rajan', 'M Heimdahl']",,"In black-box testing, the tester creates a set of tests to exercise a system under test without regard to the internal structure of the system. Generally, no objective metric is used to measure the adequacy of black-box tests. In recent work, we have proposed three requirements coverage metrics, allowing testers to objectively measure the adequacy of a black-box test suite with respect to a set of requirements formalized as Linear Temporal Logic (LTL) properties. In this report, we evaluate the effectiveness of these coverage metrics with respect to fault finding. Specifically, we conduct an empirical study to investigate two questions: (1) do test suites satisfying a requirements coverage metric provide better fault finding than randomly generated test suites of approximately the same size?, and (2) do test suites satisfying a more rigorous requirements coverage metric provide better fault finding than test suites satisfying a less rigorous requirements coverage metric? Our results indicate (1) that test suites satisfying more rigorous coverage metrics provide better fault finding than test suites satisfying less rigorous coverage metrics and (2) only one coverage metric proposedâ€”Unique First Cause (UFC) coverageâ€”is sufficiently rigorous to ensure test suites satisfying the metric outperform randomly generated test suites of similar size."
Coverage-aware test database reduction,"['J Tuya', 'C de la Riva', 'MJ Suarez-Cabal']",,"Functional testing of applications that process the information stored in databases often requires a careful design of the test database. The larger the test database, the more difficult it is to develop and maintain tests as well as to load and reset the test data. This paper presents an approach to reduce a database with respect to a set of SQL queries and a coverage criterion. The reduction procedures search the rows in the initial database that contribute to the coverage in order to find a representative subset that satisfies the same coverage as the initial database. The approach is automated and efficiently executed against large databases and complex queries. The evaluation is carried out over two real life applications and a well-known database benchmark. The results show a very large degree of reduction as well as scalability in relation to the size of the initial database and the time needed to perform the reduction."
Coverage-based software testing: Beyond basic test requirements,"['W Masri', 'FA Zaraket']",,"Code coverage is one of the core quality metrics adopted by software testing practitioners nowadays. Researchers have devised several coverage criteria that testers use to assess the quality of test suites. A coverage criterion operates by: (1) defining a set of test requirements that need to be satisfied by the given test suite and (2) computing the percentage of the satisfied requirements, thus yielding a quality metric that quantifies the potential adequacy of the test suite at revealing program defects. What differentiates one coverage criterion from another is the set of test requirements involved. For example, function coverage is concerned with whether every function in the program has been called, and statement coverage is concerned with whether every statement in the program has executed. The use of code coverage in testing is not restricted to assessing the quality of test suites. For example, researchers have devised test suite minimization and test case generation techniques that also leverage coverage. Early coverage-based software testing techniques involved basic test requirements such as functions, statements, branches, and predicates, whereas recent techniques involved (1) test requirements that are complex code constructs such as paths, program dependences, and information flows or (2) test requirements that are not necessarily code constructs such as program properties and user-defined test requirements. The focus of this chapter is to compare these two generations of techniques in regard to their effectiveness at revealing defects. The chapter will first present preliminary background and definitions and then describe impactful early coverage techniques followed by selected recent work."
Creation of mutants by using centrality criteria in social network analysis,['S Takan'],,"Mutation testing is a method widely used to evaluate the effectiveness of the test suite in hardware and software tests or to design new software tests. In mutation testing, the original model is systematically mutated using certain error assumptions. Mutation testing is based on well-defined mutation operators that imitate typical programming errors or which form highly successful test suites. The success of test suites is determined by the rate of killing mutants created through mutation operators. Because of the high number of mutants in mutation testing, the calculation cost increases in the testing of finite state machines (FSM). Under the assumption that each mutant is of equal value, random selection can be a practical method of mutant reduction. However, in this study, it was assumed that each mutant did not have an equal value. Starting from this point of view, a new mutant reduction method was proposed by using the centrality criteria in social network analysis. It was assumed that the central regions selected within this frame were the regions from where test cases pass the most. To evaluate the proposed method, besides the feature of detecting all failures related to the model, the widely-used W method was chosen. Random and proposed mutant reduction methods were compared with respect to their success by using test suites. As a result of the evaluations, it was discovered that mutants selected via the proposed reduction technique revealed a higher performance. Furthermore, it was observed that the proposed method reduced the cost of mutation testing."
Criterios basados en abstracciones de comportamiento para testing de conformidad de protocolos,['H Czemerinski'],x (not English),
DASE: Document-assisted symbolic execution for improving automated test generation,['L Zhang'],,"Software testing is crucial for uncovering software defects and ensuring software reliability. Symbolic execution has been utilized for automatic test generation to improve testing effectiveness. However, existing test generation techniques based on symbolic execution fail to take full advantage of programs’ rich amount of documentation specifying their input constraints, which can further enhance the effectiveness of test generation. In this paper we present a general approach, Document-Assisted Symbolic Execution (DASE), to improve automated test generation and bug detection. DASE leverages natural language processing techniques and heuristics to analyze programs’ readily available documentation and extract input constraints. The input constraints are then used as pruning criteria; inputs far from being valid are trimmed off. In this way, DASE guides symbolic execution to focus on those inputs that are semantically more important. We evaluated DASE on 88 programs from 5 mature real-world software suites: GNU Coreutils, GNU findutils, GNU grep, GNU Binutils, and elftoolchain. Compared to symbolic execution without input constraints, DASE increases line coverage, branch coverage, and call coverage by 5.27–22.10%, 5.83–21.25% and 2.81–21.43% respectively. In addition, DASE detected 13 previously unknown bugs, 6 of which have already been confirmed by the developers."
Deep neural network test coverage: How far are we?,"['J Chen', 'M Yan', 'Z Wang', 'Y Kang', 'Z Wu']",,"DNN testing is one of the most effective methods to guarantee the quality of DNN. In DNN testing, many test coverage metrics have been proposed to measure test effectiveness, including structural coverage and non-structural coverage (which are classified according to whether considering which structural elements are covered during testing). Those test coverage metrics are proposed based on the assumption: they are correlated with test effectiveness (i.e., the generation of adversarial test inputs or the error-revealing capability of test inputs in DNN testing studies). However, it is still unknown whether the assumption is tenable. In this work, we conducted the first extensive study to systematically validate the assumption by controlling for the size of test sets. In the study, we studied seven typical test coverage metrics based on 9 pairs of datasets and models with great diversity (including four pairs that have never been used to evaluate these test coverage metrics before). The results demonstrate that the assumption fails for structural coverage in general but holds for non-structural coverage on more than half of subjects, indicating that measuring the difference of DNN behaviors between test inputs and training data is more promising than measuring which structural elements are covered by test inputs for measuring test effectiveness. Even so, the current non-structural coverage metrics still can be improved from several aspects such as unfriendly parameters and unstable performance. That indicates that although a lot of test coverage metrics have been proposed before, there is still a lot of room for improvement of measuring test effectiveness in DNN testing, and our study has pointed out some promising directions."
DeepMutants: Training neural bug detectors with contextual mutations,"['C Richter', 'H Wehrheim']",,"Learning-based bug detectors promise to find bugs in large code bases by exploiting natural hints such as names of variables and functions or comments. Still, existing techniques tend to underperform when presented with realistic bugs. We believe bug detector learning to currently suffer from a lack of realistic defective training examples. In fact, real world bugs are scarce which has driven existing methods to train on artificially created and mostly unrealistic mutants. In this work, we propose a novel contextual mutation operator which incorporates knowledge about the mutation context to dynamically inject natural and more realistic faults into code. Our approach employs a masked language model to produce a context-dependent distribution over feasible token replacements. The evaluation shows that sampling from a language model does not only produce mutants which more accurately represent real bugs but also lead to better performing bug detectors, both on artificial benchmarks and on real world source code."
DeepMutation: a neural mutation tool,"['M Tufano', 'J Kimko', 'S Wang', 'C Watson']",,"Mutation testing can be used to assess the fault-detection capabilities of a given test suite. To this aim, two characteristics of mutation testing frameworks are of paramount importance: (i) they should generate mutants that are representative of real faults; and (ii) they should provide a complete tool chain able to automatically generate, inject, and test the mutants. To address the first point, we recently proposed an approach using a Recurrent Neural Network Encoder-Decoder architecture to learn mutants from ~787k faults mined from real programs. The empirical evaluation of this approach confirmed its ability to generate mutants representative of real faults. In this paper, we address the second point, presenting DEEPMUTATION, a tool wrapping our deep learning model into a fully automated tool chain able to generate, inject, and test mutants learned from real faults. Video: https://sites.google.com/view/learning-mutation/deepmutation."
Deriving state-based test oracles for conformance testing,['JH Andrews'],,"We address the problem of how to instrument code to log events for conformance testing purposes, and how to write test oracles that process log files. We specifically consider oracles written in languages based on the state-machine formalism. We describe two processes for systematically deriving logging code and oracles from requirements. The first is a process that we have used and taught, and the second is a more detailed process that we propose to increase the flexibility and traceability of the first process."
Determining flaky tests from test failures,['L Eloussi'],,"Automated regression testing is widely used in modern software development. Whenever a developer pushes some changes to a repository, tests are run to check whether the changes broke some functionality. When previously passing tests fail, the most recent changes are typically suspected, and developers invest time and effort to debug those changes. Unfortunately, new test failures may not be due to the latest changes but due to non-deterministic tests, popularly called flaky tests, that can pass or fail even without changes to the code under test. Many projects have such flaky tests, which can cause developers to lose confidence in test results. Therefore, developers need techniques that can help them determine whether a test failure is due to their latest changes and warrants their debugging, or whether it is due to a flaky test that should be potentially debugged by someone else. The most widely used technique for determining whether a test failure is due to a flaky test is to rerun the failing test multiple times immediately after it fails: if some rerun does pass, the test is definitely flaky, but if all reruns still fail, the status is unknown. This thesis proposes three improvements to this basic technique: (1) postponing the reruns, (2) rerunning in a new runtime environment (e.g., a new JVM for Java tests), and (3) intersecting the test coverage with the latest changes. The thesis evaluates the cost of (1) and (2) and evaluates the applicability of (3) on 15 projects with a total of 2715 test classes, 10 of which contain previously known flaky tests. The results show that the proposed improvements are highly applicable and would be able to determine that more failures are due to flaky tests for the same or somewhat higher cost as rerunning failing tests immediately after failure."
Developers perception on the severity of test smells: an empirical study,"['D Campos', 'L Rocha', 'I Machado']",,"Unit testing is an essential component of the software development life-cycle. A developer could easily and quickly catch and fix software faults introduced in the source code by creating and running unit tests. Despite their importance, unit tests are subject to bad design or implementation decisions, the so-called test smells. These might decrease software systems quality from various aspects, making it harder to understand, more complex to maintain, and more prone to errors and bugs. Many studies discuss the likely effects of test smells on test code. However, there is a lack of studies that capture developers perceptions of such issues. This study empirically analyzes how developers perceive the severity of test smells in the test code they develop. Severity refers to the degree to how a test smell may negatively impact the test code. We selected six open-source software projects from GitHub and interviewed their developers to understand whether and how the test smells affected the test code. Although most of the interviewed developers considered the test smells as having a low severity to their code, they indicated that test smells might negatively impact the project, particularly in test code maintainability and evolution. Also, detecting and removing test smells from the test code may be positive for the project."
Deviation testing: A test case generation technique for GraphQL APIs,"['DM Vargas', 'AF Blanco', 'AC Vidaurre']",,"GraphQL is a flexible and expressive query language. With the objective to replace the flawed and inefficient REST architectural style, GraphQL has been adopted by numerous online APIs and services. Despite its popularity, testing the implementation of a GraphQL schema is a crucial and still an open problem. We found that classical techniques of test generation may be efficiently applied to GraphQL server. We propose a simple but expressive technique called deviation testing that automatically searches for anomalies in the way a schema is served. We demonstrate the feasibility of our approach using an implementation of GraphQL for Pharo and VisualWorks. Running our technique on the popular Yelp and Apollo GraphQL server uncovered several anomalies in the way the schema is served."
Directed test generation and analysis for web applications,['A Milani Fard'],,"The advent of web technologies has led to the proliferation of modern web applications with enhanced user interaction and client-side execution. JavaScript (the most widely used programming language) is extensively used to build responsive modern web applications. The event-driven and dynamic nature of JavaScript, and its interaction with the Document Object Model (DOM), make it challenging to understand and test effectively. The ultimate goal of this thesis is to improve the quality of web applications through automated testing and maintenance. The work presented in this dissertation has focused on advancing the state-of-the-art in testing and maintaining web applications by proposing a new set of techniques and tools. We proposed (1) a feedback-directed exploration technique and a tool to cover a subset of the state-space of a given web application; the exploration is guided towards achieving higher functionality, navigational, and page structural coverage while reducing the test model size, (2) a technique and a tool to generate UI tests using existing tests; it mines the existing test suite to infer a model of the covered DOM states and event-based transitions including input values and assertions; it then expands the inferred model by exploring alternative paths and generates assertions for the new states; finally it generates a new test suite from the extended model, (3) the first empirical study on JavaScript tests to characterize their prevalence and quality metrics, and to find out root causes for the uncovered (missed) parts of the code under test, (4) a DOM-based JavaScript test fixture generation technique and a tool, which is based on dynamic symbolic execution; it guides the executing through different branches of a function by producing expected DOM instances, (5) a technique and a tool to detect JavaScript code smells using static and dynamic analysis. We evaluated the presented techniques by conducting various empirical studies and comparisons. The evaluation results point to the effectiveness of the proposed techniques in terms of fault detection capability and code coverage for test generation, and in terms of accuracy for code smell detection."
"Distributed systems, discrete-event simulation, test adequacy criteria, fault-based analysis.","['MJ Rutherford', 'A Carzaniga', 'AL Wolf']",x (not found),
Diversity driven adaptive test generation for concurrent data structures,"['L Ma', 'P Wu', 'TY Chen']",,"Context: Testing concurrent data structures remains a notoriously challenging task, due to the nondeterminism of multi-threaded tests and the exponential explosion on the number of thread schedules. Objective: We propose an automated approach to generate a series of concurrent test cases in an adaptive manner, i.e., the next test cases are generated with the guarantee to discover the thread schedules that have not yet been activated by the previous test cases. Method: Two diversity metrics are presented to induce such adaptive test cases from a static and a dynamic perspective, respectively. The static metric enforces the diversity in the program structures of the test cases; while the dynamic one enforces the diversity in their capabilities of exposing untested thread schedules. We implement three adaptive test generation approaches for C/C++ concurrent data structures, based on the state-of-the-art active testing engine Maple. Results: We then report an empirical study with 9 real-world C/C++ concurrent data structures, which demonstrates the efficiency of our test generation approaches in terms of the number of thread schedules discovered, as well as the time and the number of tests required for testing a concurrent data structure. Conclusion: Hence, by using diverse test cases derived from the static and dynamic perspectives, our adaptive test generation approaches can deliver a more efficient coverage of the thread schedules of the concurrent data structure under test."
Diversity-based automated test case generation,['A Shahbazi'],,"Software testing is an expensive task that consumes around half of a project’s effort. To reduce the cost of testing and improve the software quality, test cases can be produced automatically. Random Testing (RT) is a low cost and straightforward automated test generation approach. However, its effectiveness is not satisfactory. To increase the effectiveness of RT, researchers have developed more effective test generation approaches such as Adaptive Random Testing (ART) which improves the testing by increasing the test case coverage of the input domain. This research proposes new test case generation methods that improve the effectiveness of the test cases by increasing the diversity of the test cases. Numerical, string, and tree test case structures are investigated. For numerical test generation, the use of Centroidal Voronoi Tessellations (CVT) is proposed. Accordingly, a test case generation method, namely Random Border CVT (RBCVT), is introduced which can enhance the previous RT methods to improve their coverage of the input space. The generated numerical test cases by the other methods act as the input to the RBCVT algorithm and the output is an improved set of test cases. An extensive simulation study and a mutant based software testing investigation have been performed demonstrating that RBCVT outperforms previous methods. For string test cases, two objective functions are introduced to produce effective test cases. The diversity of the test cases is the first objective, where it can be measured through string distance functions. The second objective is guiding the string length distribution into a Benford distribution which implies shorter strings have, in general, a higher chance of failure detection. When both objectives are enforced via a multi-objective optimization algorithm, superior string test sets are produced. An empirical study is performed with several real-world programs indicating that the generated string test cases outperform test cases generated by other methods. Prior to tree test generation study, a new tree distance function is proposed. Although several distance or similarity functions for trees have been introduced, their failure detection performance is not always satisfactory. This research proposes a new similarity function for trees, namely Extended Subtree (EST), where a new subtree mapping is proposed. EST generalizes the edit base distances by providing new rules for subtree mapping. Further, the new approach seeks to resolve the problems and limitations of previous approaches. Extensive evaluation frameworks are developed to evaluate the performance of the new approach against previous methods. Clustering and classification case studies are performed to provide an evaluation against different tree distance functions. The experimental results demonstrate the superior performance of the proposed distance function. In addition, an empirical runtime analysis demonstrates that the new approach is one of the best tree distance functions in terms of runtime efficiency. Finally, the study on the string test case generation is extended to tree test case generation. An abstract tree model is defined by a user based on a program under the test. Then, tree test cases are produced according to the model where diversity is maximized through an evolutionary optimization technique. Real world programs are used to investigate the performance of generated test cases where superior performance of the introduced method is demonstrated compared to the previous methods. Further, the proposed tree distance function is compared against the previous functions in the tree test case generation context. The proposed tree distance function outperforms other functions in tree test generation."
Do mutation reduction strategies matter?,"['R Gopinath', 'A Alipour', 'I Ahmed', 'C Jensen', 'A Groce']",,"Mutation analysis is a well-known, but computationally intensive, method for measuring test suite quality. While multiple strategies have been proposed to reduce the number of mutants, there is inconclusive evidence for their utility due to the limited number and size of programs used for validation, and a lack of comprehensive comparative studies. Traditional evaluation criteria for mutation reduction also rely on mutation-adequate suites, which are rare in practice. We propose novel criteria for evaluating reduction strategies for non-mutation-adequate test suites, directly linked to the actual use of mutation analysis during development — to ensure that tests check for many different possible faults. We evaluate using both these criteria and the traditional criteria with 201 real-world projects, and show that the popular strategies — operator selection, and stratified sampling (on operators or program elements) — are at best marginally better than random sampling, and are often worse."
DroidMate-2: a platform for Android test generation,"['NP Borges', 'J Hotzkow', 'A Zeller']",,"Android applications (apps) represent an ever increasing portion of the software market. Automated test input generators are the state of the art for testing and security analysis. We introduce DRoIDMATE-2 (DM-2), a platform to easily assist both developers and researchers to customize, develop and test new test generators. DM-2 can be used without app instrumentation or operating system modifications, as a test generator on real devices and emulators for app testing or regression testing. Additionally, it provides sensitive resource monitoring or blocking capabilities through a lightweight app instrumentation, out-of-thebox statement coverage measurement through a fully-fledged app instrumentation and native experiment reproducibility. In our experiments we compared DM-2 against DRoIDBoT, a state-of-the-art test generator by measuring statement coverage. Our results show that DM-2 reached 96% of its peak coverage in less than 2/3 of the time needed by DRoIDBoT, allowing for better and more efficient tests. On short runs (5 minutes) DM-2 outperformed DRoIDBoT by 7% while in longer runs (1 hour) this difference increases to 8%. ACM DL Artifact: https://www.doi.org/10.1145/3264864. For the details see: https://github.com/uds-se/droidmate/wiki/ASE-2018:-Data."
Dynamic data-flow testing,['M Vivanti'],,"Data-flow testing techniques have long been discussed in the literature, yet to date they are still of little practical relevance. The applicability of data-flow testing is limited by the complexity and the imprecision of the approach: writing a test suite that satisfy a data-flow criterion is challenging due to the presence of many test objectives that include infeasible elements in the coverage domain and exclude feasible ones that depend on aliasing and dynamic constructs. To improve the applicability and effectiveness of data-flow testing we need both to augment the precision of the coverage domain by including data-flow elements dependent on aliasing and to exclude infeasible ones that reduce the total coverage. In my PhD research I plan to address these two problems by designing a new data-flow testing approach that combines automatic test generation and dynamic identification of data-flow elements that can identify precise test targets by monitoring the program executions."
Dynamic program analysis for suggesting test improvements to developers,['O Vera-Pérez'],,"Automated testing is at the core of modern software development. Yet developers struggle when it comes to the evaluation of the quality of their test cases and how to improve them. The main goal of this thesis is precisely that, to generate concrete suggestion that developers can follow to improve their test suite. We propose the use of extreme mutation, or extreme transformations as an alternative to discover testing issues. Extreme transformations are a form of mutation testing that remove the entire logic of a method instead of making a small syntactic change in the code. As it traditional counterpart it challenges the test suite with a transformed variant of the program to see if the test cases can detect the change. In this thesis we assess the relevance of the testing issues that extreme transformations can spot. We also propose a dynamic infection-propagation analysis to automatically derive concrete test improvement suggestions from undetected extreme transformations. Our results are validated through the interaction with actual developers. We also report the industrial adoption of parts of our results. developers to improve their tests by detecting more of these transformations. Our results are validated through the interaction with actual developers."
Effective fault localization via mutation analysis: A selective mutation approach,"['M Papadakis', 'Y Le Traon']",,"When programs fail, developers face the problem of identifying the code fragments responsible for this failure. To this end, fault localization techniques try to identify suspicious program places (program statements) by observing the spectrum of the failing and passing test executions. These statements are then pointed out to assist the debugging activity. This paper considers mutation-based fault localization and suggests the use of a sufficient mutant set to locate effectively the faulty statements. Experimentation reveals that mutation-based fault localization is significantly more effective than current state-of-the-art fault localization techniques. Additionally, the results show that the proposed approach is capable of reducing the overheads of mutation analysis. In particular the number of mutants to be considered is reduced to 20% with only a limited loss on the method's effectiveness."
Effective methods to tackle the equivalent mutant problem when testing software with mutation,['M Kintis'],,"Mutation Testing is undoubtedly one of the most effective software testing techniques that has been applied to different software artefacts at different testing levels. Apart from mutation’s versatility, its most important characteristic is its ability to detect real faults. Unfortunately, mutation’s adoption in practice is inhibited, primarily due to the manual effort involved in its application. This effort is attributed to the Equivalent Mutant Problem. The Equivalent Mutant Problem is a well-known impediment to mutation’s practical adoption that affects all phases of its application. To exacerbate the situation, the Equivalent Mutant Problem has been shown to be undecidable in its general form. Thus, no complete, automated solution exists. Although previous research has attempted to address this problem, its circumvention remains largely an open issue. This thesis argues that effective techniques that considerably ameliorate the problem’s adverse effects can be devised. To this end, the thesis introduces and empirically evaluates several such approaches that are based on Mutant Classification, Static Analysis and Code Similarity. First, the thesis proposes a novel mutant classification technique, named Isolating Equivalent Mutants (I-EQM) classifier, whose salient feature is the utilisation of second order mutants to automatically isolate first order equivalent ones. The empirical evaluation of the approach, based on real-world test subjects, suggests that I-EQM outperforms the existing techniques and results in a more effective testing process. Second, the thesis formally defines nine data flow patterns that can automatically detect equivalent and partially equivalent mutants. Their empirical evaluation corroborates this statement, providing evidence of their existence in real-world software and their equivalent mutant detection capabilities. Third, MEDIC (Mutants’ Equivalence Discovery), an automated framework that implements the aforementioned patterns and manages to detect equivalent and partially equivalent mutants in different programming languages, is introduced. The experimental investigation of the tool, based on a large set of manually analysed mutants, reveals that MEDIC can detect efficiently more than half of the considered equivalent mutants and provides evidence of automated stubborn mutant detection. Finally, the thesis proposes the concept of mirrored mutants, that is mutants affecting similar code fragments and, more precisely, analogous code locations within these fragments. It is postulated that mirrored mutants exhibit analogous behaviour with respect to their equivalence. The empirical evaluation of this concept supports this statement and suggests that the number of the equivalent mirrored mutants that have to be manually analysed can be reduced approximately by half."
Effective unit-testing in model-based software development,"['D Kamma', 'P Maruthi']",,"Model-based software development is extensively used in avionics and automotive safety critical control software applications. In model-based software development, highly optimized code is generated automatically from models. Such code is often hard to understand and this can make it difficult to write test cases. Therefore, in model based software development, test cases have to be derived based on the models to achieve coverage of code auto-generated from the models. Further, safety standards in those domains often demand effective unit-testing method to check functional requirements as well as achieve 100% code coverage. In this paper, we first discuss three methods for unit testing in model based software development, namely Modified Condition & Decision Coverage (MCDC), Classification tree and Exploratory methods. We then discuss results of our field study conducted on 3 live projects at Robert Bosch Engineering & Business Solutions Limited to check on the effectiveness of three approaches. Based on the results from our field study, we conclude that MCDC method along with boundary value analysis is most productive to check functional requirements as well as achieve 100% coverage of auto-generated code."
Efficient increasing of the mutation score during model-based test suite generation,"['A Kolchin', 'S Potiyenko', 'T Weigert']",,"The purpose of the method is to increase the sensitivity of an automatically generated test suite to mutations of a model. Unlike existing methods for generating test scenarios that use the mutational approach to assess the resulting test set, the proposed method analyzes the possibility of detecting mutations on the fly, in the process of analyzing the model’s behavior space, by adding of special coverage goals. Two types of mutants manifestation are considered: deviations in the behavior of paths for (weak case) and in the observed output (strong case). A new algorithm is proposed for efficient search of a path with observable effect of a mutation."
Empirical analysis of object-oriented software test suite evolution,"['N Alsolami', 'Q Obeidat']",,"The software system is evolving over the time, thus, the test suite must be repaired according to the changing code. Updating test cases manually is a time-consuming activity, especially for large test suites, which motivate the recent development of automatically repairing test techniques. To develop an effective automatic repair technique that reduces the effort of development and the cost of evolution, the developer should understand how the test suite evolves in practice. This investigation aims to conduct a comprehensive empirical study on eight Java systems with many versions of these systems and their test suites to find out how the test suite is evolving, and to find the relationship between the change in the program and the corresponding evolution in the test suite. This study showed that the test suite size is mostly increased, where the test suite complexity is stabilized. The increase (or decrease) in the code size will mostly increase (or decrease) the test suite size. However, the increasing or decreasing in the code complexity is offset by stabilizing the test suite complexity. Moreover, the percentage of the code coverage tends to be increased more than decreased, but in the mutation coverage, the opposite is true."
Empirical evaluation of mutation‐based test case prioritization techniques,"['D Shin', 'S Yoo', 'M Papadakis']",,"In this paper, we propose a new test case prioritization technique that combines both mutation-based and diversity-aware approaches. The diversity-aware mutation-based technique relies on the notion of mutant distinguishment, which aims to distinguish one mutant's behaviour from another, rather than from the original program. The relative cost and effectiveness of the mutation-based prioritization techniques (i.e., using both the traditional mutant kill and the proposed mutant distinguishment) are empirically investigated with 352 real faults and 553,477 developer-written test cases. The empirical evaluation considers both the traditional and the diversity-aware mutation criteria in various settings: single-objective greedy, hybrid, and multi-objective optimization. The results show that there is no single dominant technique across all the studied faults. To this end, the reason why each one of the mutation-based prioritization criteria performs poorly is discussed, using a graphical model called Mutant Distinguishment Graph that demonstrates the distribution of the fault-detecting test cases with respect to mutant kills and distinguishment."
Empirical research on concurrent software testing: A systematic mapping study,"['SM Melo', 'JC Carver', 'PSL Souza', 'SRS Souza']",,"Background: Concurrent software testing is a costly and difficult task, especially due to the exponential increase in the test sequences caused by non-determinism. Such an issue has motivated researchers to develop testing techniques that select a subset of the input domain that has a high probability of revealing faults. Academics and industrial practitioners rarely use most concurrent software testing techniques because of the lack of data about their applicability. Empirical evidence can provide an important scientific basis for the strengths and weaknesses of each technique to help researchers and practitioners choose concurrent testing techniques appropriate for their environments. Aim: This paper gathers and synthesizes empirical research on concurrent software testing to characterize the field and the types of empirical studies performed. Method: We performed a systematic mapping study to identify and analyze empirical research on concurrent software testing techniques. We provide a detailed analysis of the studies and their design choices. Results: The primary findings are: (1) there is a general lack of empirical validation of concurrent software testing techniques, (2) the type of evaluation method varies with the type of technique, (3) there are some key challenges to empirical study design in concurrent software testing, and (4) there is a dearth of controlled experiments in concurrent software testing. Conclusions: There is little empirical evidence available about some specific concurrent testing techniques like model-based testing and formal testing. Overall, researchers need to perform more empirical work, especially real-world case studies and controlled experiments, to validate properties of concurrent software testing techniques. In addition, researchers need to perform more analyses and synthesis of the existing evidence. This paper is a first step in that direction."
Empirical study of the effects of different similarity measures on test case prioritization,"['R Wang', 'S Jiang', 'D Chen', 'Y Zhang']",,"Similarity-based test case prioritization algorithms have been applied to regression testing. The common characteristic of these algorithms is to reschedule the execution order of test cases according to the distances between pair-wise test cases. The distance information can be calculated by different similarity measures. Since the topologies vary with similarity measures, the distances between pair-wise test cases calculated by different similarity measures are different. Similarity measures could significantly influence the effectiveness of test case prioritization. Therefore, we empirically evaluate the effects of six similarity measures on two similarity-based test case prioritization algorithms. The obtained results are statistically analyzed to recommend the best combination of similarity-based prioritization algorithms and similarity measures. The experimental results, confirmed by a statistical analysis, indicate that Euclidean distance is more efficient in finding defects than other similarity measures. The combination of the global similarity-based prioritization algorithm and Euclidean distance could be a better choice. It generates not only higher fault detection effectiveness but also smaller standard deviation. The goal of this study is to provide practical guides for picking the appropriate combination of similarity-based test case prioritization techniques and similarity measures."
Enabling mutation testing for android apps,"['M Linares-Vásquez', 'G Bavota', 'M Tufano']",,"Mutation testing has been widely used to assess the fault-detection effectiveness of a test suite, as well as to guide test case generation or prioritization. Empirical studies have shown that, while mutants are generally representative of real faults, an effective application of mutation testing requires “traditional” operators designed for programming languages to be augmented with operators specific to an application domain and/or technology. This paper proposes MDroid+, a framework for effective mutation testing of Android apps. First, we systematically devise a taxonomy of 262 types of Android faults grouped in 14 categories by manually analyzing 2,023 so ware artifacts from different sources (e.g., bug reports, commits). Then, we identified a set of 38 mutation operators, and implemented an infrastructure to automatically seed mutations in Android apps with 35 of the identified operators. The taxonomy and the proposed operators have been evaluated in terms of stillborn/trivial mutants generated as compared to well know mutation tools, and their capacity to represent real faults in Android apps"
"Engineering of Software Test-Code: Developing, verifying and maintaining high-quality automated test scripts","['V Garousi', 'M Felderer']",x (no Abstract),
Enriching code coverage with test characteristics,"['V Subramanian', 'S Vysali']",,"Code coverage measures the degree to which source code elements (e.g., statements,branches) are invoked during testing. Despite growing evidence that coverage is aproblematic measurement, it is often used to make decisions about where testing effortshould be invested. For example, using coverage as a guide, tests should be written toinvoke the non-covered program elements. At their core, coverage measurements assumethat invocation of a program element during any test is equally valuable and only provide abinary covered-or-not classification of program elements. Yet in reality, tests have variedcharacteristics and coverage can be enriched by incorporating these test characteristics. Inthis thesis, we expand code coverage classification by adding scope (e.g., unit, function)and reliability (flaky vs. robust) characteristics of the tests to the coverage report. Weperform an empirical study of three large software systems from the OpenStackcommunity, namely, Nova, Neutron, and Cinder.We generate an enriched statement coverage report and glean additional insights. Weobserve that 60.94% and 63.33% of statements are covered by both unit and functional tests in Neutron and Nova, respectively, while only 30% are covered by both types of testsin Cinder. We find that systems are disproportionately impacted by flakily coveredstatements with 5% and 10% of the covered statements in Nova and Neutron being flakilycovered, respectively, while < 1% of Cinder statements are flakily covered. We also findthat incidences of flakily covered statements could not be well explained by solely usingcode characteristics, such as dispersion, ownership, and development activity. In order tounderstand the cost effectiveness of enriching code coverage, we propose GreedyFlake – atest effort prioritization algorithm to maximize return on investment when tackling theproblem of flakily covered program elements. We find that GreedyFlake outperformsbaseline approaches by at least eight percentage points of Area Under the CostEffectiveness Curve"
Evaluating and improving white-box test generation,['D Honfi'],,"Software testing is an inevitable part of software development to ensure the quality of the product. Thorough testing of software, however, might consume an significant amount of time and resources. Therefore, already decades ago, research has begun to reduce this effort by automating the process, while improving the efficiency of testing as well. One of the recommended methods is white-box test generation, which uses only the source code to generate test cases. Although there are several types of techniques using this idea – including symbolic execution, search-based testing, and guided random testing – the complexity of real-world software can make their application burdensome. These techniques usually suffer from issues, when the software under test interacts with its environment, structured objects should be created for good coverage, valid test oracles should be guessed, or the size of the program is too large. Furthermore, the use of such advanced techniques is not trivial for ordinary developers or testers due to their underlying complexity, hence the identification of test generation problems can be a difficult task as well. This work empirically evaluates these challenges and addresses some of them by proposing new techniques and tools for white-box test generation. The goal of Thesis 1 is to provide insights from studying white-box test generators in practice. The thesis presents the designs and the results of two empirical studies conducted with human participants. The first, replicated study addresses the problem of using test generators during development and compares the generated tests’ capabilities to manually written ones in terms of coverage achieved and bugs found. The second study analyzes how participants can classify the generated white-box tests with respect to a given behavior specification: do the generated oracles encode a fault silently, or they represent the real expected behavior. Thesis 2 aims at providing a solution for the environment interaction problem of white-box test generation. We designed a novel approach that automatically transforms the source code to alleviate the interaction between the test generator and the dependencies of the unit under test. The transformed source code invokes generated fake methods inside a parameterized sandbox instead of the real dependencies. The concrete values in the sandbox are provided by the test generator. The technique is implemented in a tool called AutoIsolator that is evaluated in a large-scale experiment with open-source projects. Thesis 3 targets the problem of understanding and problem resolution of a popular white-box test generation technique: symbolic execution. We propose a detailed visualization approach of representing the test generation processes via symbolic execution trees. Each node in the tree has additional metadata definitions attached to it, which helps the users of the test generator to identify, understand, and possibly resolve issues that occurred during the test generation. This technique is implemented in a ready-to-use, open-source tool (SEViz). Our results from the empirical studies identify and strengthen some of the practical challenges of white-box test generation. The two techniques we propose are addressing these challenges by keeping the practical aspects in focus as well. The results and the feedbacks received show the potential in both proposed approaches."
Evaluating fuzz testing,"['G Klees', 'A Ruef', 'B Cooper', 'S Wei', 'M Hicks']",,"Fuzz testing has enjoyed great success at discovering security critical bugs in real software. Recently, researchers have devoted significant effort to devising new fuzzing techniques, strategies, and algorithms. Such new ideas are primarily evaluated experimentally so an important question is: What experimental setup is needed to produce trustworthy results? We surveyed the recent research literature and assessed the experimental evaluations carried out by 32 fuzzing papers. We found problems in every evaluation we considered. We then performed our own extensive experimental evaluation using an existing fuzzer. Our results showed that the general problems we found in existing experimental evaluations can indeed translate to actual wrong or misleading assessments. We conclude with some guidelines that we hope will help improve experimental evaluations of fuzz testing algorithms, making reported results more robust."
Evaluating software testing techniques: a systematic mapping study,['M Mayeda'],,"Software testing techniques are crucial for detecting faults in software and reducing the risk of using it. As such, it is important that we have a good understanding of how to evaluate these techniques for their efficiency, scalability, applicability, and effectiveness at finding faults. This thesis enhances our understanding of testing technique evaluations by providing an overview of the state of the art in research. To accomplish this we utilize a systematic mapping study; structuring the field and identifying research gaps and publication trends. We then present a small case study demonstrating how our mapping study can be used to assist researchers in evaluating their own software testing techniques. We find that a majority of evaluations are empirical evaluations in the form of case studies and experiments, most of these evaluations are of low quality based on proper methodology guidelines, and that relatively few papers in the field discuss how testing techniques should be evaluated."
Evaluation and improvement of automated software test suites,['R Niedermayr'],,"Automated software tests are an important means of quality assurance in software projects and for helping to detect faults in software products early. While various measures and techniques have been proposed to evaluate test suites, code coverage metrics are the most common and are widely used in industry. However, it is questionable whether code coverage metrics are suitable to determine the fault detection capabilities of a test suite. Another powerful and valid technique for assessing test suites is mutation testing, which introduces faults into an application’s code and checks whether the existing test cases can detect them. When determining fault detection capabilities, mutation testing is clearly superior to other measures, but it is computationally very complex and suffers from the problem of equivalent mutants, which distort the results. Due to these problems, mutation testing has rarely been adopted as a test adequacy criterion in practice. The aim of this dissertation was to develop measures and techniques to better determine the effectiveness of a test suite with reasonable computational efforts. We wanted to come up with an approach that outperforms code coverage metrics in terms of validity and is, at the same time, less resource-intensive than currently used mutation testing approaches. To do this, we proposed, implemented and evaluated a light-weight mutation approach to identify pseudo-tested methods; that is, methods that are covered by at least one test case, but none of the test cases can detect the removal of the whole logic from the method. We further developed a machine-learning model to predict pseudo-tested methods based on a newly introduced measure for characterizing the proximity between methods and test cases and further easily computable measures. We also built machine-learning models to identify low-fault-risk methods, which can be excluded from quality-assurance activities to focus on the relevant methods and further speed up pseudo-testedness analyses. The results show that pseudo-tested methods exist in all analyzed study objects and constitute relevant test inadequacies. Prediction models can efficiently identify pseudo-tested methods, which means that such models can be applied as a preceding, less costly step to mutation testing or be used in scenarios where mutation testing is not applicable. Depending on what level of risk is acceptable, approximately one-third of the methods can be classified as having a low fault risk, and these methods can be predicted with a machine-learning model based on code metrics. The devised approaches make it possible to identify pseudo-tested methods by using an applicable, light-weight computation or a prediction based on method and test case metrics. Flaws in test suites uncovered by pseudo-tested methods are easy for developers to interpret and take action on, enabling the developers to improve the effectiveness of their test suite. The identification of methods with a low fault risk helps allocate test suite improvement efforts to the relevant methods. More effective test suites can reveal more faults during the software development phase, which can help improve the overall quality of a software product and reduce failure follow-up costs."
Explorando gamificação no ensino de teste de software,['GM Jesus'],x (not English),
Exploring design decisions for mutation testing,['F Hariri'],,"Software testing is by far the most popular technique used in industry for quality assurance. One key challenge of software testing is how to evaluate the quality of test suites in terms of their bug-finding capability. A test suite with a large number of tests, or that achieves a high statement or branch coverage, does not necessarily have a high bug-finding capability. Mutation testing is widely used in research to evaluate the quality of test suites, and it is often considered the most powerful approach for this purpose. Mutation testing proceeds in two steps. The first step is mutant generation. A mutant is a modified version of the original program obtained by applying a mutation operator. A mutation operator is a program transformation that introduces a small syntactic change to the original program. The second step of mutation testing is to run the test suite and determine which mutants are killed, i.e., which mutants lead to tests having a different output when run on them compared against running on the original program. Mutation testing produces a measure of quality of the test suite called mutation score. The mutation score of a given test suite is the percentage of mutants killed by that test suite out of the total number of generated mutants. In this dissertation, we explore three design decisions related to mutation testing and provide recommendations to researchers in those regards. First, we look into mutation operators. To provide insights about how to improve the test suites, mutation testing requires both high quality and diverse mutation operators that lead to different program behaviors. We propose the use of approximate transformations as mutation operators. Approximate transformations were introduced in the emerging area of approximate computing for changing program semantics to trade the accuracy of results for improved energy efficiency or performance. We compared three approximate transformations with a set of conventional mutation operators from the literature, on nine open-source Java subjects. The results showed that approximate transformations change program behavior differently from conventional mutation operators. Our analysis uncovered code patterns in which approximate mutants survived (i.e., were not killed) and showed the practical value of approximate transformations both for understanding code amenable to approximations and for discovering bad tests. We submitted 11 pull requests to fix bad tests. Seven have already been integrated by the developers. Second, we explore the effect of compiler optimizations on mutation testing. Multiple mutation testing tools were developed that perform mutation at different levels. More recently mutation testing has been performed at the level of compiler intermediate representation (IR), e.g., for the LLVM IR and Java bytecode/IR. Compiler optimizations are automatic program transformations applied at the IR level with the goal of improving a measure of program performance, while preserving program semantics. Applying mutations at the IR level means that mutation testing becomes more susceptible to the effects of compiler optimizations. We investigate a new perspective on mutation testing: evaluating how standard compiler optimizations affect the cost and results of mutation testing performed at the IR level. Our study targets LLVM, a popular compiler infrastructure that supports multiple source and target languages. Our evaluation on 16 Coreutils programs discovers several interesting relations between the numbers of mutants (including the numbers on equivalent and duplicated mutants) and mutation scores on unoptimized and optimized programs. Third, we perform an empirical study to compare mutation testing at the source (SRC) and IR levels. Applying mutation at different levels offers different advantages and disadvantages, and the relation between mutants at the different levels is not clear. In our study, we compare mutation testing at the SRC and IR levels, specifically in the C programming language and the LLVM compiler IR. To make the comparison fair, we develop two mutation tools that implement conceptually the same operators at both levels. We also employ automated techniques to account for equivalent and duplicated mutants, and to determine hard-tokill mutants. We carry out our study on 16 programs from the Coreutils library, using a total of 948 tests. Our results show interesting characteristics that can help researchers better understand the relationship between mutation testing at both levels. Overall, we find mutation testing to be better at the SRC level than at the IR level: the SRC level produces much fewer (non-equivalent) mutants and is thus less expensive, but the SRC level still generates a similar number of hard-to-kill mutants."
Fast and accurate incremental feedback for students' software tests using selective mutation analysis,"['AM Kazerouni', 'JC Davis', 'A Basak', 'CA Shaffer']",,"As incorporating software testing into programming assignments becomes routine, educators have begun to assess not only the correctness of students’ software, but also the adequacy of their tests. In practice, educators rely on code coverage measures, though its shortcomings are widely known. Mutation analysis is a stronger measure of test adequacy, but it is too costly to be applied beyond the small programs developed in introductory programming courses. We demonstrate how to adapt mutation analysis to provide rapid automated feedback on software tests for complex projects in large programming courses. We study a dataset of 1389 student software projects ranging from trivial to complex. We begin by showing that although the state-of-the-art in mutation analysis is practical for providing rapid feedback on projects in introductory courses, it is prohibitively expensive for the more complex projects in subsequent courses. To reduce this cost, we use a statistical procedure to select a subset of mutation operators that maintains accuracy while minimizing cost. We show that with only 2 operators, costs can be reduced by a factor of 2–3 with negligible loss in accuracy. Finally, we evaluate our approach on open-source software and report that our findings may generalize beyond our educational context."
Feedback-based random test generator for TSTL,['K Kaneoka'],,"Software testing is the process of evaluating the accuracy and performance of software, and automated software testing allows programmers to develop software more efficiently by decreasing testing costs. We compared two advanced random test generators, a Feedback-Directed Random Test Generator (FDR) and a Feedback-Controlled Random Test Generator (FCR), for an automated software testing tool in Python 2.x, the Template Scripting Testing Language (TSTL). An FDR generates test inputs incrementally. Feedback from previous trials is used to generate new inputs. As each test input is executed, the software properties are assessed to determine if there is any value. Because of this process of gradually generating new tests, the FDR avoids redundant and illegal test inputs commonly produced by traditional random test generators. An FCR employs a different feedback technique. It controls the feedback to produce varied test inputs using multiple input containers. In our experiments, we compared the performance of our test generators with TSTL’s generator in terms of coverage, time-efficiency, and error-detection capability."
File Systems are Hard to Test—Learning from Xfstests,"['N Aota', 'K Kono']",,"Modern file systems, such as ext4, btrfs, and XFS, are evolving and enable the introduction of new features to meet ever-changing demands and improve reliability. File system developers are struggling to eliminate all software bugs, but the operating system community points out that file systems are a hotbed of critical software bugs. This paper analyzes the code coverage of xfstests, a widely used suite of file system tests, on three major file systems (ext4, btrfs, and XFS). The coverage is 72.34%, and the uncovered code runs into 23,232 lines of code. To understand why the code coverage is low, the uncovered code is manually examined line by line. We identified three major causes, peculiar to file systems, that hinder higher coverage. First, covering all the features is difficult because each file system provides a wide variety of file-system specific features, and some features can be tested only on special storage devices. Second, covering all the execution paths is difficult because they depend on file system configurations and internal on-disk states. Finally, the code for maintaining backward-compatibility is executed only when a file system encounters old formats. Our findings will help file system developers improve the coverage of test suites and provide insights into fostering the development of new methodologies for testing file systems."
Fragment analysis and test case generation using F-measure for adaptive random testing and partitioned block based adaptive random testing,"['D Indhumathi', 'S Sarala']",,"Test case generation is a path to identify the solution in software testing. Adaptive random testing is an enhancement of random testing to improve the quality of fault-revealing. The research focuses on software adaptive random testing based on Matrix called Partitioned Block based Adaptive Random Testing. It compares the performance of PBART with the existing Adaptive random testing using random samples of test cases which are drawn from blocks of distinct partitions. Partition testing defines as a block of test cases partitioned into set of all test cases. Thereby it has prompted to investigate the performance of random testing that can be improved by taking the patterns of failure-causing inputs which utilizes the prior knowledge and the information of the test cases. The proposed algorithm PB –ART performs the testing of program structure and load the source code to matrix with scenarios, method flows and data values. In numerical experiments, the approach examines effectiveness of PB-ART with ordinary adaptive random testing. There exist three measures for evaluating the effectiveness of a testing technique namely P-measure, E-measure and F-measure. Moreover F-measure is intuitively more appealing to testers and more realistic and informative from a practical point of view. Therefore, F-measure is chosen for measuring testing techniques in this research work."
From Daikon to Agitator: lessons and challenges in building a commercial tool for developer testing,"['M Boshernitsan', 'R Doong', 'A Savoia']",,"Developer testing is of one of the most effective strategies for improving the quality of software, reducing its cost, and accelerating its development. Despite its widely recognized benefits, developer testing is practiced by only a minority of developers. The slow adoption of developer testing is primarily due to the lack of tools that automate some of the more tedious and time-consuming aspects of this practice. Motivated by the need for a solution, and helped and inspired by the research in software test automation, we created a developer testing tool based on software agitation. Software agitation is a testing technique that combines the results of research in test-input generation and dynamic invariant detection. We implemented software agitation in a commercial testing tool called Agitator. This paper gives a high-level overview of software agitation and its implementation in Agitator, focusing on the lessons and challenges of leveraging and applying the results of research to the implementation of a commercial product."
Functional and Security testing of a Mobile Application,"['J Sjöstrand', 'S Westberg']",,"A mobile application has been developed to be used for assistance in crisis scenarios. To assure the application is dependable enough to be used in such scenarios, the application was put under test. This thesis investigates different approaches to functional testing and security testing. Five common methods of generating test cases for functional testing have been identified and four were applied on the application. The coverage achieved for each method was measured and compared. For this specific application under test, test cases from a method called decision table-testing scored the highest code coverage. 9 bugs related to functionality were identified. Fuzz testing is a simple security testing technique for efficiently finding security flaws, and was applied for security testing of our application. During the fuzz test, system security properties were breached. An unauthorized user could read and alter asset data, and it also affected the system's availability. Our overall conclusion was that with more time, creating functional tests for smaller components of the application might have been more effective in finding faults and achieving coverage."
Gamification in software testing: A characterization study,"['GM de Jesus', 'FC Ferrari', 'D de Paula Porto']",,"Context: Testing is a fundamental activity in the software development cycle. Revealing software faults is its main objective. Despite that, testing is considered unpleasant, dull and tedious. As a result, there is a lack of expertise among professionals while many projects fail. Gamification is a promising way to address testing issues; it is a new trend being used mostly to increase motivation, engagement and performance with the use of game elements in non-game contexts. Objective: To describe results of a study that aimed to characterize how gamification has been explored to support software testing. Method: The studies that compose our baseline for analysis and discussion were obtained through a systematic mapping carried out following a research protocol. To retrieve relevant literature, we applied automatic search and backward snowballing. At the end, we selected 15 studies that we analyzed and classified according to six perspectives: application context, used gamifcation elements, gamification goals, testing techniques, testing levels, and testing process phases. Results: The most used gamification elements are points, leader boards, and levels, and unit testing and functional testing are the level and technique most addressed in the studies, respectively. Conclusion: Gamification is a rising research topic, especially in the software testing field. The increasing interest for gamification has the potential do lead to positive outcomes. The map presented in this paper can be a useful resource for the identification of gaps and for triggering new research initiatives."
Gamifying a software testing course with code defenders,"['G Fraser', 'A Gambi', 'M Kreis', 'JM Rojas']",,"Software testing is an essential skill for software developers, but it is challenging to get students engaged in this activity. The Code Defenders game addresses this problem by letting students compete over code under test by either introducing faults ('attacking') or by writing tests ('defending') to reveal these faults. In this paper, we describe how we integrated Code Defenders as a semester-long activity of an undergraduate and graduate level university course on software testing. We complemented the regular course sessions with weekly Code Defenders sessions, addressing challenges such as selecting suitable code to test, managing games, and assessing performance. Our experience and our data show that the integration of Code Defenders was well-received by students and led them to practice testing thoroughly. Positive learning effects are evident as student performance improved steadily throughout the semester."
Generating effective test suites for reactive systems using specification mining,['PR Bokil'],,"Failures in reactive embedded systems are often unacceptable. Effective testing of embedded systems to detect such unacceptable failures is a difficult task. We present an automated black box test suite generation technique for embedded systems. The technique is based on dynamic mining of specifications, in the form of a finite state machine (FSM), from initial runs. The set of test cases thus produced may contain several redundant test cases. Many of the redundant test cases are then eliminated by an aggressive greedy test suite reduction algorithm to yield the final test suite. The tests generated by our technique were evaluated for their effectiveness on five case studies from the embedded domain. The evaluation of the results indicate that a test suite generated by our technique is promising in terms of effectiveness and scales easily. Further, the test suite reduction algorithm may sometimes remove non-redundant test cases too. Therefore, in our experimentation, we have also evaluated the change in the effectiveness of test suites due to this reduction. In this thesis, we describe the test suite generation and reduction technique in detail and present the results of the case studies."
Generic method for statistical testing of parallel programs based on task trees,"['M Popovic', 'I Kupresanin']",,"This paper deals with a particular class of parallel programs, which are based on task trees. The main objective of this paper was to adapt the generic method for statistical testing of sequential programs (GMST-SP) for this class of parallel programs, such that adapted method (GMST) can treat a family of task trees rather than just a single task tree, and that it can respect various evolutions of individual task trees. In this paper, we compare GMST with the adapted exhaustive testing method (ET) and with the previously adapted statistical usage testing method (SUT), based on experimentally measured testing effort and path coverage. GMST and SUT both have better deep path coverage than ET. SUT requires less testing effort than GMST and ET, but its deep path coverage decreases with the number of tasks. Finally, GMST has advantage over SUT because it provides constant mean level of deep path coverage, which can be regulated by the required testing quality."
Grammar-driven generation of domain-specific language testing tools using aspects,['H Wu'],,"Domain-specific languages (DSLs) assist a software developer (or end-user) in writing a program using idioms that are similar to the abstractions found in a specific problem domain. Testing tool support for DSLs is lacking when compared to the capabilities provided for standard general-purpose languages (GPLs), such as Java and C++. For example, support for debugging and unit testing a program written in a DSL is often non-existent. The lack of a debugger and unit test engine at the proper abstraction level limits an end-user‟s ability to discover and locate faults in a DSL program. This dissertation describes a grammar-driven technique to build a debugging and unit testing tool generation framework by adaptations to existing DSL grammars. This approach leverages existing GPL testing tools to indirectly exercise the end-user‟s debug and test intentions at the DSL level. The adaptations to DSL grammars represent the hooks needed to interface with a supporting infrastructure constructed for an Integrated Development Environment (IDE) that assists in debugging and unit testing a program written in a DSL. The contribution represents a coordinated approach to bring essential software tools (e.g., debuggers and test engines) to different types of DSLs (e.g., imperative, declarative, and hybrid). This approach hides from the end-users the accidental complexities associated with expanding the focus of a language environment to include testing tools. During the testing tool generation process, crosscutting concerns were observed in representations of DSL grammars. To address these particular crosscutting concerns, an investigation into the principles of aspect-oriented programming applied to grammars has been conducted. A domain-specific aspect language, called AspectG, has been designed and implemented, which is focused within the domain of language specification. This dissertation outlines the challenges and issues that exist when designing aspect languages that assist in modularizing crosscutting concerns in grammars. The research described in the dissertation addresses a long-term goal of empowering end-users with development tools for particular DSL problem domains at the proper level of abstraction without depending on a specific GPL."
Higher order mutation testing: A Systematic,"['A Ghiduk', 'M Girgis']",,"Mutation testing is the process whereby a fault is deliberately inserted into a software system, in order to assess the quality of test data, in terms of its ability to find this fault. Mutation testing is also used as a way to drive the test data development process. Traditionally, faults were inserted one by one into a software system, but more recently there has been an upsurge of interest by the area of higher-order mutation, in which multiple faults are inserted into the system at once. Originally, this was thought to be too expensive, as there was already a concern that the size of the pool of mutants for traditional mutation was already too large to handle. However, following a seminal publication in 2008, it was realized that the space of higher-order mutants (HOMs) could be searched for useful mutants that drive testing harder, and to reduce the overall test effort, by clever combination of first-order mutants. As a result, many authors examined the way in which HOM testing could find subtle hard to kill faults, capture partial fault masking, reduce equivalent mutants problem, reduce test effort while increasing effectiveness, and capture more realistic faults than those captured by simple insertion of first-order mutants. Because of the upsurge of interest in the previous issues, this paper presents the first Systematic Literature Review research specifically targeted at a higher-order mutation. This Systematic Literature Review analyzes the results of more than one hundred sixty research articles in this area. The current paper presents qualitative results and bibliometric analysis for the surveyed articles. In addition, it augments these results with scientific findings and quantitative results from the primary literature. As a result of this work, this SLR presents an outline for many future work."
How test suites impact fault localisation starting from the size,"['Y Lei', 'C Sun', 'X Mao', 'Z Su']",,"Although a test suite is indispensable for conducting effective fault localisation, not much work has been done to study how the test suite impacts fault localisation. This study presents a systematic study for a deeper understanding of their relation. Specifically, the authors' study reveals an interesting fact that there is no strong correlation between localisation effectiveness and the size of the test suite. Furthermore, they show that, in a test suite, (i) the passing test cases that do not execute the faulty statements and the failing test cases have a positive effect on the fault localisation effectiveness, while (ii) the passing test cases that exercise the faulty statements have a negative impact on localisation performance. Their result is drawn from a large-scale empirical analysis on the localisation effectiveness with respect to randomly sampled test suites. This study presents the details of the study and their follow-up investigation on the findings. Their work provides a new perspective on fault localisation and suggests fresh directions of research on an extensively studied topic."
How to kill them all: an exploratory study on the impact of code observability on mutation testing,"['Q Zhu', 'A Zaidman', 'A Panichella']",,"Mutation testing is well-known for its efficacy in assessing test quality, and starting to be applied in the industry. However, what should a developer do when confronted with a low mutation score? Should the test suite be plainly reinforced to increase the mutation score, or should the production code be improved as well, to make the creation of better tests possible? In this paper, we aim to provide a new perspective to developers that enables them to understand and reason about the mutation score in the light of testability and observability. First, we investigate whether testability and observability metrics are correlated with the mutation score on six open-source Java projects. We observe a correlation between observability metrics and the mutation score, e.g., test directness, which measures the extent to which the production code is tested directly, seems to be an essential factor. Based on our insights from the correlation study, we propose a number of ”mutation score anti-patterns”, enabling software engineers to refactor their existing code or add tests to improve the mutation score. In doing so, we observe that relatively simple refactoring operations enable an improvement or increase in the mutation score."
Identifying testing requirements for modified software,['T Apiwattanapong'],,"Throughout its lifetime, software must be changed for many reasons, such as bug fixing, performance tuning, and code restructuring. Testing modified software is the main activity performed to gain confidence that changes behave as they are intended and do not have adverse effects on the rest of the software. A fundamental problem of testing evolving software is determining whether test suites adequately exercise changes and, if not, providing suitable guidance for generating new test inputs that target the modified behavior. Existing techniques evaluate the adequacy of test suites based only on control- and data-flow testing criteria. They do not consider the effects of changes on program states and, thus, are not sufficiently strict to guarantee that the modified behavior is exercised. Also, because of the lack of this guarantee, these techniques can provide only limited guidance for generating new test inputs. This research has developed techniques that will assist testers in testing evolving software and provide confidence in the quality of modified versions. In particular, this research has developed a technique to identify testing requirements that ensure that the test cases satisfying them will result in different program states at preselected parts of the software. This research has also developed supporting techniques for identifying testing requirements. Such techniques include (1) a differencing technique, which computes differences and correspondences between two software versions and (2) two dynamic-impact-analysis techniques, which identify parts of software that are likely affected by changes with respect to a set of executions."
Impact of mutation operators on the ratio of equivalent mutants,"['I Marsit', 'MN Omri', 'JM Loh', 'A Mili']",,"Software mutation is a widely used technique of software testing that consists in generating variants of a base program by applying standard modifications to its source code. One of the main obstacles in the use of software mutations is the existence of equivalent mutants, i.e. mutants whose behavior is indistinguishable from the base program, even though their source code is distinct. Despite several decades of research, the identification of equivalent mutants remains an open problem. Rather than attempting to identify individual mutants that are equivalent to the base, we argue that it is often sufficient to estimate the number of equivalent mutants; also, we argue that the number of equivalent mutants depends on two factors that must be considered in the estimation effort, namely the base program and the mutation operators that are used; in this paper, we explore the impact of mutation operators on the number of equivalent mutants."
Impacts de l'AOP sur les tests dans un environnement Agile: utilisation de Mocks pour les tests unitaires d'aspects,['FA Bourbonnais-Bigras'],x (not English),
Improving generation of object-oriented test suites by avoiding redundant tests,"['T Xie', 'D Marinov', 'D Notkin']",,"Object-oriented tests consist of sequences of method invocations. Behavior of an invocation depends on the state of the receiver object and method arguments at the beginning of the invocation. Existing tools for automatic generation of object-oriented test suites, such as Jtest and JCrasher for Java, typically ignore object states. These tools generate redundant tests that exercise the same method behavior, which increases the testing time without increasing the ability to detect faults. We propose a formal framework for detecting redundant tests and present five fully automatic techniques within this framework. Based on these techniques, we have developed a test-minimization tool that removes redundant tests from test suites and a test-generation tool that iteratively augments test suites with non-redundant tests. We evaluate our tools on eight subjects taken from a variety of sources. The experimental results show that our test minimization can remove over 90% of the tests generated by Jtest for most subjects and 30% of the tests generated by JCrasher for half of the subjects, without decreasing the quality of test suites. The results also show that our test generation can effectively generate new tests that increase the quality of test suites generated by Jtest and JCrasher"
Improving in-house testing using field execution data,['Q Wang'],,"Software testing is today the most widely used approach for assessing and improving software quality. Despite its popularity, however, software testing has a number of inherent limitations. First, due to resource limitations, in-house tests necessarily exercise only a tiny fraction of all the possible behaviors of a software system. Second, testers typically select this fraction of behaviors to be tested based either on some (more or less rigorous) selection criteria or on their assumptions, intuition, and experience. As a result, in-house tests are typically not representative of the software behavior exercised by real users, which ultimately results in the software behaving incorrectly and failing in the field, after it has been released. The overarching goal of my dissertation is to address this problem and improve the effectiveness of in-house testing. To this end, I proposed a set of techniques for measuring and bridging the gap between in-house tests and field executions. My first technique allows for quantifying and analyzing the differences between behaviors exercised in-house and in the field. My second approach leverages the differences identified by my first technique to generate, using a guided symbolic analysis, test inputs that mimic field behaviors and can be added to existing in-house test suites. Finally, my third approach leverages the executions observed in the field to improve symbolic input generation and make test generation more effective. The evaluation shows that my techniques can effectively generate test inputs using field execution data and make in-house testing more representative of field executions."
Improving mutation testing with dominator mutants,['RG Kurtz Jr'],,"In a world increasingly driven by software, software testing is an increasingly important topic. Mutation testing is a software testing technique that has been shown to be highly effective in identifying software defects. In mutation testing, engineers or researchers use an automated tool to produce a large number of variants of the software under test (called mutants), where each mutant contains a slight difference from the original software. They can then develop tests that show a difference in behavior between mutants and the original version; this is known as killing the mutants. The proportion of mutants killed is the mutation score, and is often used as an indicator of the completeness of the test set. The fundamental contribution of this research is to characterize and address the nature of mutant redundancy. First, I characterize the complex redundancy relationship between mutants using subsumption, where one mutant subsumes another if every test that kills the first mutant also kills the second. I represent this relationship using the mutant subsumption graph. Second, I investigate methods to automatically develop this subsumption relationship. Third, I explore the effects of equivalent and redundant mutants on testing. Fourth, I compare common existing methods of mutant reduction and show that, consistent with prior research, none significantly outperform random mutant selection. Fifth, I explore how to reduce the expense of mutation testing by biasing mutant generation toward the high-value mutants that approximate dominator mutants by considering not only the mutation operator but also the context of the code where the mutation is made. This use of program context to determine the usefulness of a mutant is a key contribution of my work. Sixth, I apply machine learning techniques to automate the identification of such high-value mutants. The result is the first mutant selection strategy to significantly outperform random mutant selection, with an increase in efficiency of nearly 20%."
Improving regression testing efficiency and reliability via test-suite transformations,['AW Shi'],,"As software becomes more important and ubiquitous, high quality software also becomes crucial. Developers constantly make changes to improve software, and they rely on regression testing—the process of running tests after every change—to ensure that changes do not break existing functionality. Regression testing is widely used both in industry and in open source, but it suffers from two main challenges. (1) Regression testing is costly. Developers run a large number of tests in the test suite after every change, and changes happen very frequently. The cost is both in the time developers spend waiting for the tests to finish running so that developers know whether the changes break existing functionality, and in the monetary cost of running the tests on machines. (2) Regression test suites contain flaky tests, which nondeterministically pass or fail when run on the same version of code, regardless of any changes. Flaky test failures can mislead developers into believing that their changes break existing functionality, even though those tests can fail without any changes. Developers will therefore waste time trying to debug non existent faults in their changes. This dissertation proposes three lines of work that address these challenges of regression testing through test-suite transformations that modify test suites to make them more efficient or more reliable. Specifically, two lines of work explore how to reduce the cost of regression testing and one line of work explores how to fix existing flaky tests. First, this dissertation investigates the effectiveness of test-suite reduction (TSR), a traditional test-suite transformation that removes tests deemed redundant with respect to other tests in the test suite based on heuristics. TSR outputs a smaller, reduced test suite to be run in the future. However, TSR risks removing tests that can potentially detect faults in future changes. While TSR was proposed over two decades ago, it was always evaluated using program versions with seeded faults. Such evaluations do not precisely predict the effectiveness of the reduced test suite on the future changes. This dissertation evaluates TSR in a real-world setting using real software evolution with real test failures. The results show that TSR techniques proposed in the past are not as effective as suggested by traditional TSR metrics, and those same metrics do not predict how effective a reduced test suite is in the future. Researchers need to either propose new TSR techniques that produce more effective reduced test suites or better metrics for predicting the effectiveness of reduced test suites. Second, this dissertation proposes a new transformation to improve regression testing cost when using a modern build system by optimizing the placement of tests, implemented in a technique called TestOptimizer. Modern build systems treat a software project as a group of inter-dependent modules, including test modules that contain only tests. As such, when developers make a change, the build system can use a developer-specified dependency graph among modules to determine which test modules are affected by any changed modules and to run only tests in the affected test modules. However, wasteful test executions are a problem when using build systems this way. Suboptimal placements of tests, where developers may place some tests in a module that has more dependencies than the test actually needs, lead to running more tests than necessary after a change. TestOptimizer analyzes a project and proposes moving tests to reduce the number of test executions that are triggered over time due to developer changes. Evaluation of TestOptimizer on five large proprietary projects at Microsoft shows that the suggested test movements can reduce 21.7 million test executions (17.1%) across all evaluation projects. Developers accepted and intend to implement 84.4% of the reported suggestions. Third, to make regression testing more reliable, this dissertation proposes iFixFlakies, a framework for fixing a prominent kind of flaky tests: order dependent tests. Order-dependent tests pass or fail depending on the order in which the tests are run. Intuitively, order-dependent tests fail either because they need another test to set up the state for them to pass, or because some other test pollutes the state before they are run, and the polluted state makes them fail. The key insight behind iFixFlakies is that test suites often already have tests, which we call helpers, that contain the logic for setting/resetting the state needed for order-dependent tests to pass. iFixFlakies searches a test suite for these helpers and then recommends patches for order-dependent tests using code from the helpers. Evaluation of iFixFlakies on 137 truly order-dependent tests from a public dataset shows that 81 of them have helpers, and iFixFlakies can fix all 81. Furthermore, among our GitHub pull requests for 78 of these order dependent tests (3 of 81 had been already fixed), developers accepted 38; the remaining ones are still pending, and none are rejected so far."
Improving software quality for regular expression matching tools using automated combinatorial testing,['FA Aldebeyan'],,"Regular expression matching tools (grep) match regular expressions to lines of text. However, because of the complexity that regular expressions can reach, it is challenging to apply state of the art automated testing frameworks to grep tools. Combinatorial testing has shown to be an effective testing methodology, especially for systems with large input spaces. In this dissertation, we investigate the approach of a fully automated combinatorial testing system for regular expression matching tools CoRE (Combinatorial testing for Regular Expressions). CoRE automatically generates test cases using combinatorial testing and measures correctness using differential testing. CoRE outperformed AFL and AFLFast in terms of code coverage testing icGrep, GNU grep and PCRE grep."
Improving the effectiveness of testing pervasive software via,"['H Wang', 'WK Chan', 'TH Tse']",,"Context-aware pervasive software is responsive to various contexts and their changes. A faulty implementation of the context-aware features may lead to unpredictable behavior with adverse effects. In software testing, one of the most important research issues is to determine the sufficiency of a test suite to verify the software under test. Existing adequacy criteria for testing traditional software, however, have not explored the dimension of serial test inputs and have not considered context changes when constructing test suites. In this article, we define the concept of context diversity to capture the extent of context changes in serial inputs and propose three strategies to study how context diversity may improve the effectiveness of the data-flow testing criteria. Our case study shows that the strategy that uses test cases with higher context diversity can significantly improve the effectiveness of existing data-flow testing criteria for context-aware pervasive software. In addition, test suites with higher context diversity are found to execute significantly longer paths, which may provide a clue that reveals why context diversity can contribute to the improvement of effectiveness of test suites."
Improving the quality of automotive test case specifications,['K Juhnke'],,"Context. Test case specifications are a central element of a structured automotive test process. They contain natural language test cases that are used to perform manual tests in prototype vehicles (entire vehicle test) or as a basis for implementing test scripts (system integration test). Problem. Usually, these test case specifications are written by several test designers and executed by different testers. The different actors involved, who write and interpret test cases differently, and the fact that such test cases are predominantly written in natural language, impairs the quality of test case specifications. Thus, quality deficiencies, such as ambiguous, incomplete, or inconsistent test cases, have a negative impact on the cost and time required for testing and on the probability of detecting defects. Goal. The aim of this thesis is to identify challenges that negatively influence the quality of test case specifications and to define and evaluate quality assurance methods that counter them. Method. This thesis is based on the methodological approach of Design Science Research. First, challenges which have an influence on the quality of test case specifications are systematically identified in an exploratory case study and assessed by practitioners in a descriptive survey in terms of frequency and criticality. Second, quality characteristics for automotive test case specifications are determined based on the identified challenges, related work on test case quality, and expert workshops to develop a quality model and review checklists to be used for analytical quality assurance. Furthermore, a constructive quality assurance method called Test Case Specification-Oriented Domain Analysis Method is developed, which focuses on the derivation of system-specific templates for the specification of automotive test cases. Third, the review checklists are evaluated by test designers as well as testers and discussed in an expert workshop. In addition, the applicability of the developed domain analysis method for deriving system-specific templates is evaluated and a controlled experiment is conducted to compare the conventional natural language approach with the template-based approach for specifying test cases. Results. This thesis presents a taxonomy of nine main categories of challenges concerning automotive test case specifications. To improve their quality, this thesis presents on the one hand a quality model, which forms the basis for the developed perspective-based review checklists. On the other hand, the developed Test Case Specification-Oriented Domain Analysis Method supports the derivation of system-specific templates based on existing test case specifications. Additionally, it is shown that the template-based approach leads to fewer defects in test case specifications. Finally, it is presented how the developed review checklists and a tool support for the derivation and use of system-specific templates were integrated into an existing automotive tool chain. Conclusion. In summary, this thesis identifies challenges with test case specifications in the automotive domain and presents two approaches to improve the quality of automotive test case specifications."
Improving the testing of Profit Software's insurance policy database system,['K Nordman'],,"Profit Software's Profit Life and Pension (PLP) is an investment insurance management system. This means that PLP handles investment insurances from the moment they are sold to when they eventually expire. For a system that handles money, it is important that it can be trusted. Therefore, testing is a required part of PLP's development. This thesis is an investigation into PLP's testing strategy. In this thesis we analyse PLP's current testing strategy to find flaws and impediments. We then offer improvement suggestions to the identified problem areas as well as suggest additions which we found could be beneficial."
Increasing system test coverage in production automation systems,"['S Ulewicz', 'B Vogel-Heuser']",,"An approach is introduced, which supports a testing technician in the identification of possibly untested behavior of control software of fully integrated automated production systems (aPS). Based on an approach for guided semi-automatic system testing, execution traces are recorded during testing, allowing for a subsequent coverage assessment. As the behavior of an aPS is highly dependent on the software, omitted system behavior can be identified and assessed for criticality. Through close cooperation with industry, this approach represents the first coverage assessment approach for system testing in production automation to be applied on real industrial objects and evaluated by industrial experts."
Intelligent evaluation of test suites for developing efficient and reliable software,"['M Mohammadian', 'Z Javed']",,"Test suites play an important role in developing reliable software applications. Generally, the behaviour of software applications is verified by executing test suites to find defects. The quality of a test suite needs to be evaluated and enriched (if needed) especially for testing critical systems, such as plane-navigation system. This paper presents a novel method for comparing concrete and executable test suites using equivalence classes. This comparison identifies gaps in test suites with respect to each other. These gaps indicate potential weaknesses in the test suites. Furthermore, this method provides a mechanism to enrich the test suites using these gaps. In this method, we devise equivalence classes, and associate each test case to an equivalence class. We, then, simulate the comparison of test suites by comparing sets of equivalence classes. The method compares test suites in a platform independent manner. The test suites, which are compared, are smaller than the original test suites because the redundant test cases are removed from the test suites, which makes it efficient. We exercise our method over three case studies to demonstrate its viability and effectiveness. The first case study illustrates the application of the method and evaluates its effectiveness using a mutation analysis. The second case study evaluates its effectiveness using mutation and coverage analyses. The final case study evaluates it on a real case study, which is Lucene search engine."
Introduction du test dans la modélisation par aspects,"['J Klein', 'B Baudry', 'O Barais', 'A Jackson']",x (not English),
Introduction to software testing,"['P Ammann', 'J Offutt']",x (Book),
Investigate the matrix: leveraging variability to specialize software and test suites,['P Temple'],,"Nowadays, software have to be efficient, fast to execute, etc. They can be configured to adapt to specific needs. Each configuration leads to a different system and usually it is hard to generate them all. Thus, the exhaustive evaluation of their performance is impossible. Furthermore, several executions of systems, under different conditions, are needed to properly evaluate performances. Two dimensions emerge from this description of performance testing: the selection of system configurations allowing to generate associated systems that meet expressed needs and the selection of test cases allowing to observe performances of systems under different conditions. We propose to represent those two dimensions as a (performance) matrix: one dimension represents selected systems that can be observed while the other dimension represents the set of test cases that will be executed on each of these systems. Each cell is the execution of a program variant regarding a test. The contributions of this thesis are as follows : First, we leverage Machine Learning techniques in order to specialize a Software Product Line (in this case a video generator) helping in selecting a configuration that is likely to meet requirements. End users must be able to express their requirements such that it results in a binary decision problem (i.e., configurations that are acceptable and those that are not). Machine Learning techniques are then used to retrieve partial configurations that specialize a Software Product Line to guide end users and reduce the configuration space. In the end, this work aims at diminishing the first dimension of the matrix that deals with systems and programs. Second, we propose a new method assessing the ability of test suites to reveal significant performance differences of a set of configurations tackling the same task. This method can be used to assess whether a new test case is worth adding to a test suite or to select an optimal test set with respect to a property of interest. In the end, it might help structuring the execution of tests. For instance, it can create an order of execution resulting in using less test cases that are presented in the second dimension of the matrix. We evaluated our approach on several systems from different domains such as OpenCV or Haxe."
L3. 4: Etude de réduction de suites de tests,"['T Triki', 'L du-Bousquet', 'Y Ledru']",x (not English),
Learning from super-mutants: searching post-apocalyptic software ecosystems for novel semantics-preserving transforms,"['J Landsborough', 'S Harding', 'S Fugate']",,"In light of recent advances in genetic-algorithm-driven automated program modification, our team has been actively exploring the art, engineering, and discovery of novel semantics-preserving transforms. While modern compilers represent some of the best ideas we have for automated program modification, current approaches represent only a small subset of the types of transforms which can be achieved. In the wilderness of post-apocalyptic software ecosystems of genetically-modified and mutant programs, there exist a broad array of potentially useful software mutations, including semantics-preserving transforms that may play an important role in future software design, development, and most importantly, evolution."
Lightweight lexical test prioritization for immediate feedback,"['T Mattis', 'R Hirschfeld']",,"The practice of unit testing enables programmers to obtain automated feedback on whether a currently edited program is consistent with the expectations specified in test cases. Feedback is most valuable when it happens immediately, as defects can be corrected instantly before they become harder to fix. With growing and longer running test suites, however, feedback is obtained less frequently and lags behind program changes. The objective of test prioritization is to rank tests so that defects, if present, are found as early as possible or with the least costs. While there are numerous static approaches that output a ranking of tests solely based on the current version of a program, we focus on change-based test prioritization, which recommends tests that likely fail in response to the most recent program change. The canonical approach relies on coverage data and prioritizes tests that cover the changed region, but obtaining and updating coverage data is costly. More recently, information retrieval techniques that exploit overlapping vocabulary between change and tests have proven to be powerful, yet lightweight. In this work, we demonstrate the capabilities of information retrieval for prioritizing tests in dynamic programming languages using Python as example. We discuss and measure previously understudied variation points, including how contextual information around a program change can be used, and design alternatives to the widespread \emph{TF-IDF} retrieval model tailored to retrieving failing tests. To obtain program changes with associated test failures, we designed a tool that generates a large set of faulty changes from version history along with their test results. Using this data set, we compared existing and new lexical prioritization strategies using four open-source Python projects, showing large improvements over untreated and random test orders and results consistent with related work in statically typed languages. We conclude that lightweight IR-based prioritization strategies are effective tools to predict failing tests in the absence of coverage data or when static analysis is intractable like in dynamic languages. This knowledge can benefit both individual programmers that rely on fast feedback, as well as operators of continuous integration infrastructure, where resources can be freed sooner by detecting defects earlier in the build cycle."
MC/DC coverage measurement of C programs,['EA Gerlits'],,"MC/DC is a test coverage criterion which is usually applied in testing safety critical software including embedded software and especially dealing with avionics software. In this article, we discuss some practical issues connected with test coverage measurement for MC/DC written in C programming language and come up with the solutions to them. Chosen solutions influence on the quality of testing. The given article includes the part of our research wherein we perform testing of MC/DC coverage analysis tools for C/C++."
MS-guided many-objective evolutionary optimisation for test suite minimisation,"['W Zheng', 'X Wu', 'S Cao', 'J Lin']",,"Test suite minimisation is a process that seeks to identify and then eliminate the obsolete orredundant test cases from the test suite. It is a trade-off between cost andother value criteria and is appropriate to be described as a many-objectiveoptimisation problem. This study introduces a mutation score (MS)-guidedmany-objective optimisation approach, which prioritises the fault detectionability of test cases and takes MS, cost and three standard code coveragecriteria as objectives for the test suite minimisation process. They use sixclassical evolutionary many-objective optimisation algorithms to identifyefficient test suite, and select three small programs from the Software-ArtefactInfrastructure Repository (SIR) and two larger program space and gzip forexperimental evaluation as well as statistical analysis. The experiment resultsof the three small programs show non-dominated sorting genetic algorithm II(NSGA-II) with tuning was the most effective approach. However, MOEA/D-PBI andMOEA/D-WS outperform NSGA-II in the cases of two large programs. On the otherhand, the test cost of the optimal test suite obtained by their proposedMS-guided many-objective optimisation approach is much lower than the onewithout it in most situation for both small programs and large programs."
Machine learning applied to software testing: A systematic mapping study,"['VHS Durelli', 'RS Durelli', 'SS Borges']",,"Software testing involves probing into the behavior of software systems to uncover faults. Most testing activities are complex and costly, so a practical strategy that has been adopted to circumvent these issues is to automate software testing. There has been a growing interest in applying machine learning (ML) to automate various software engineering activities, including testing-related ones. In this paper, we set out to review the state-of-the art of how ML has been explored to automate and streamline software testing and provide an overview of the research at the intersection of these two fields by conducting a systematic mapping study. We selected 48 primary studies. These selected studies were then categorized according to study type, testing activity, and ML algorithm employed to automate the testing activity. The results highlight the most widely used ML algorithms and identify several avenues for future research. We found that ML algorithms have been used mainly for test-case generation, refinement, and evaluation. Also, ML has been used to evaluate test oracle construction and to predict the cost of testing-related activities. The results of this paper outline the ML algorithms that are most commonly used to automate software-testing activities, helping researchers to understand the current state of research concerning ML applied to software testing. We also found that there is a need for better empirical studies examining how ML algorithms have been used to automate software-testing activities."
Mapeamento e aplicação de testes estatísticos em engenharia de software,['MNP Detoni'],x (not English),
Maple: A coverage-driven testing tool for multithreaded programs,"['J Yu', 'S Narayanasamy', 'C Pereira']",,"Testing multithreaded programs is a hard problem, because it is challenging to expose those rare interleavings that can trigger a concurrency bug. We propose a new thread interleaving coverage-driven testing tool called Maple that seeks to expose untested thread interleavings as much as possible. It memoizes tested interleavings and actively seeks to expose untested interleavings for a given test input to increase interleaving coverage. We discuss several solutions to realize the above goal. First, we discuss a coverage metric based on a set of interleaving idioms. Second, we discuss an online technique to predict untested interleavings that can potentially be exposed for a given test input. Finally, the predicted untested interleavings are exposed by actively controlling the thread schedule while executing for the test input. We discuss our experiences in using the tool to expose several known and unknown bugs in real-world applications such as Apache and MySQL."
Mdroid+: A mutation testing framework for android,"['K Moran', 'M Tufano', 'C Bernal-Cárdenas']",,"Mutation testing has shown great promise in assessing the effectiveness of test suites while exhibiting additional applications to test-case generation, selection, and prioritization. Traditional mutation testing typically utilizes a set of simple language specific source code transformations, called operators, to introduce faults. However, empirical studies have shown that for mutation testing to be most effective, these simple operators must be augmented with operators specific to the domain of the software under test. One challenging software domain for the application of mutation testing is that of mobile apps. While mobile devices and accompanying apps have become a mainstay of modern computing, the frameworks and patterns utilized in their development make testing and verification particularly difficult. As a step toward helping to measure and ensure the effectiveness of mobile testing practices, we introduce MDroid+, an automated framework for mutation testing of Android apps. MDroid+ includes 38 mutation operators from ten empirically derived types of Android faults and has been applied to generate over 8,000 mutants for more than 50 apps."
Measuring effectiveness of sample-based product-line testing,"['S Ruland', 'L Luthmann', 'J Bürdek', 'S Lity']",,"Recent research on quality assurance (QA) of configurable software systems (e.g., software product lines) proposes different analysis strategies to cope with the inherent complexity caused by the well-known combinatorial-explosion problem. Those strategies aim at improving efficiency of QA techniques like software testing as compared to brute-force configuration-by-configuration analysis. Sampling constitutes one of the most established strategies, defining criteria for selecting a drastically reduced, yet sufficiently diverse subset of software configurations considered during QA. However, finding generally accepted measures for assessing the impact of sample-based analysis on the effectiveness of QA techniques is still an open issue. We address this problem by lifting concepts from single-software mutation testing to configurable software. Our framework incorporates a rich collection of mutation operators for product lines implemented in C to measure mutation scores of samples, including a novel family-based technique for product-line mutation detection. Our experimental results gained from applying our tool implementation to a collection of subject systems confirms the widely-accepted assumption that pairwise sampling constitutes the most reasonable efficiency/effectiveness trade-off for sample-based product-line testing."
Measuring the multiple-condition coverage with test suites for AspectJ programs,['A Zanderink'],x (not found),
Memory mutation testing,"['F Wu', 'J Nanavati', 'M Harman', 'Y Jia', 'J Krinke']",,"Context: Three decades of mutation testing development have given software testers a rich set of mutation operators, yet relatively few operators can target memory faults (as we demonstrate in this paper). Objective: To address this shortcoming, we introduce Memory Mutation Testing, proposing 9 Memory Mutation Operators each of which targets common forms of memory fault. We compare Memory Mutation Operators with traditional Mutation Operators, while handling equivalent and duplicate mutants. Method: We extend our previous workshop paper, which introduced Memory Mutation Testing, with a more extensive and precise analysis of 18 open source programs, including 2 large real-world programs, all of which come with well-designed unit test suites. Specifically, our empirical study makes use of recent results on Trivial Compiler Equivalence (TCE) to identify both equivalent and duplicate mutants. Though the literature on mutation testing has previously deployed various techniques to cater for equivalent mutants, no previous study has catered for duplicate mutants. Results: Catering for such extraneous mutants improves the precision with which claims about mutation scores can be interpreted. We also report the results of a new empirical study that compares Memory Mutation Testing with traditional Mutation Testing, providing evidence to support the claim that traditional mutation testing inadequately captures memory faults; 2% of the memory mutants are TCE-duplicates of traditional mutants and average test suite effectiveness drops by 44% when the target shifts from traditional mutants to memory mutants. Conclusions: Introducing Memory Mutation Operators will cost only a small portion of the overall testing effort, yet generate higher quality mutants compared with traditional operators. Moreover, TCE technique does not only help with reducing testing effort, but also improves the precision of assessment on test quality, therefore should be considered in other Mutation Testing studies."
Model transformation impact on test artifacts: An empirical study,"['A Eriksson', 'B Lindström', 'SF Andler', 'J Offutt']",,"Development environments that support Model-Driven Development often focus on model-level functional testing, enabling verification of design models against their specifications. However, developers of safety-critical software systems are also required to show that tests cover the structure of the implementation. Unfortunately, the implementation structure can diverge from the model depending on choices such as the model compiler or target language. Therefore, structural coverage at the model level may not guarantee coverage of the implementation. We present results from an industrial experiment that demonstrates the model-compiler effect on test artifacts in xtUML models when these models are transformed into C++. Test artifacts, i.e., predicates and clauses, are used to satisfy the structural code coverage criterion, in this case MCDC, which is required by the US Federal Aviation Administration. The results of the experiment show not only that the implementation contains more test artifacts than the model, but also that the test artifacts can be deterministically enumerated during translation. The analysis identifies two major sources for these additional test artifacts."
Most higher mutants are useless for method-level mutation operators using weak mutation.,['BB SOUZA'],,"Mutation analysis is a popular but costly approach to assess the quality of test suites. One of the attempts to reduce the costs associated to mutation analysis is to identify subsuming higher order mutants (HOMs), i.e., mutants that are harder to kill than the first order mutants (FOMs) from which they are constructed. However, it is not known how many HOMs subsume FOMs. In this paper, we use our previous approach, which discovers redundancy in mutations by proving subsumption relations among method-level mutation operators using weak mutation testing, to encode and prove subsumption relations among FOMs and HOMs. We encode a theory of subsumption relations in the Z3 theorem prover for 27 mutation targets (mutations of an expression or statement). We encode 233 FOMS and 438 HOMs and automatically prove a number of subsumption relations using Z3. Our results indicate that 91% of all mutants could be discarded on average. Moreover, 97.5% of all HOMs could be discarded and HOMs compose only 16.67% of the subsuming mutants sets on average."
MuDroid: Mutation testing for Android apps,['Y Wei'],,"With the raising of smartphones, mobile apps become an new emerging paradigm in software development. With 3.4 billion smartphone subscription, the quality of mobile apps become a crucial problem which lead to the need of novel and high quality testing approaches for app developers. Existing testing approaches, such as code coverage based, do not provide an effective way to assess the fault detectability of mobile app tests. The fault-based mutation testing techniques offer a better guideline in improving the fault detection ability. This project aims to design and implement an automated mutation testing system for Android apps at integration level. With this system, Android developers and testers could gauge the quality of their test suites by understanding their fault detection ability. Furthermore, it can provide a guideline for testers to improve their testing as well as improving their implementation. This thesis proposes three novel Android mutation testing techniques and describe the the implementation of MuDroid, an automated mutation testing system for Android apps. We designed six selective operators which generated 3,649 mutants on four real-world Android apps in the empirical study. The innovative screenshot-based killing approach we proposed could kill 40% more mutants on average than traditional crash-based killing approaches. The results also shown that our best cost reduction strategy could reduce on average 80% mutants with only a 7.3% error in average."
Multi-objective integer programming approaches for solving the multi-criteria test-suite minimization problem: Towards sound and complete solutions of a particular …,"['Y Xue', 'YF Li']",,"Test-suite minimization is one key technique for optimizing the software testing process. Due to the need to balance multiple factors, multi-criteria test-suite minimization (MCTSM) becomes a popular research topic in the recent decade. The MCTSM problem is typically modeled as integer linear programming (ILP) problem and solved with weighted-sum single objective approach. However, there is no existing approach that can generate sound (i.e., being Pareto-optimal) and complete (i.e., covering the entire Pareto front) Pareto-optimal solution set, to the knowledge of the authors. In this work, we first prove that the ILP formulation can accurately model the MCTSM problem and then propose the multi-objective integer programming (MOIP) approaches to solve it. We apply our MOIP approaches on three specific MCTSM problems and compare the results with those of the cutting-edge methods, namely, NonlinearFormulation_LinearSolver (NF_LS) and two Multi-Objective Evolutionary Algorithms (MOEAs). The results show that our MOIP approaches can always find sound and complete solutions on five subject programs, using similar or significantly less time than NF_LS and two MOEAs do. The current experimental results are quite promising, and our approaches have the potential to be applied for other similar search-based software engineering problems."
Multi-objective search-based mobile testing,['K Mao'],,"Despite the tremendous popularity of mobile applications, mobile testing still relies heavily on manual testing. This thesis presents mobile test automation approaches based on multi-objective search. We introduce three approaches: Sapienz (for native Android app testing), Octopuz (for hybrid/web JavaScript app testing) and Polariz (for using crowdsourcing to support search-based mobile testing). These three approaches represent the primary scientific and technical contributions of the thesis. Since crowdsourcing is, itself, an emerging research area, and less well understood than search-based software engineering, the thesis also provides the first comprehensive survey on the use of crowdsourcing in software testing (in particular) and in software engineering (more generally). This survey represents a secondary contribution. Sapienz is an approach to Android testing that uses multi-objective search-based testing to automatically explore and optimise test sequences, minimising their length, while simultaneously maximising their coverage and fault revelation. The results of empirical studies demonstrate that Sapienz significantly outperforms both the state-of-the-art technique Dynodroid and the widely-used tool, Android Monkey, on all three objectives. When applied to the top 1,000 Google Play apps, Sapienz found 558 unique, previously unknown crashes. Octopuz reuses the Sapienz multi-objective search approach for automated JavaScript testing, aiming to investigate whether it replicates the Sapienz’ success on JavaScript testing. Experimental results on 10 real-world JavaScript apps provide evidence that Octopuz significantly outperforms the state of the art (and current state of practice) in automated JavaScript testing. Polariz is an approach that combines human (crowd) intelligence with machine (computational search) intelligence for mobile testing. It uses a platform that enables crowdsourced mobile testing from any source of app, via any terminal client, and by any crowd of workers. It generates replicable test scripts based on manual test traces produced by the crowd workforce, and automatically extracts from these test traces, motif events that can be used to improve search-based mobile testing approaches such as Sapienz."
Mutation testing approach to negative testing,['J Strug'],,"Negative testing deals with an important problem of assessing a system ability to handle unexpected situations. Such situations, if unhandled, may lead to system failures that in some cases can have catastrophic consequences. This paper presents a mutation testing-based approach for generation of test cases supporting negative testing. Application of this approach can provide, in a systematic and human-unbiased way, test cases effectively testing wide range of unexpected situations. Thus, it can contribute to improvement of a tested system. The paper formally defines mutation operators used to control the generation process, describes a generic framework for the generation and execution of the test cases, and explains how to interpret results."
Mutation testing for aspect-oriented programs,"['FC Ferrari', 'JC Maldonado']",,"Mutation testing has been shown to be one of the strongest testing criteria for the evaluation of both programs and test suites. Comprehensive sets of mutants require strong test sets to achieve acceptable testing coverage. Moreover, mutation operators are valuable for the evaluation of other testing approaches. Although its importance has been highlighted for aspect-oriented (AO) programs, there is still a need for a suitable set of mutation operators for AO languages. The quality of the mutation testing itself relies on the quality of such operators. This paper presents the design of a set of mutation operators for AspectJ-based programs. These operators model instances of fault types identified in an extensive survey. The fault types and respective operators are grouped according to the related language features. We also discuss the generalisation of the fault types to AO approaches other than AspectJ and the coverage that may be achieved with the application of the proposed operators. In addition, a cost analysis based on two case studies involving real-world applications has provided us feedback on the most expensive operators, which will support the definition of further testing strategies."
Mutation testing for ethereum smart contract,"['H Wu', 'X Wang', 'J Xu', 'W Zou', 'L Zhang']",,"Smart contract is a special program that manages digital assets on blockchain. It is difficult to recover the loss if users make transactions through buggy smart contracts, which cannot be directly fixed. Hence, it is important to ensure the correctness of smart contracts before deploying them. This paper proposes a systematic framework to mutation testing for smart contracts on Ethereum, which is currently the most popular open blockchain for deploying and running smart contracts. Fifteen novel mutation operators have been designed for Ethereum Smart Contracts (ESC), in terms of keyword, global variable/function, variable unit, and error handling. An empirical study on 26 smart contracts in four Ethereum DApps has been conducted to evaluate the effectiveness of mutation testing. The experimental results show that our approach can outperform the coverage-based approach on defect detection rate (96.01% vs. 55.68%). The ESC mutation operators are effective to reveal real defects and we found 117 out of 729 real bug reports are related to our operators. These show the great potential of using mutation testing for quality assurance of ESC."
Mutation testing of functional programming languages,"['D Le', 'MA Alipour', 'R Gopinath', 'A Groce']",,"Mutation testing has been widely studied in imperative programming languages. The rising popularity of functional languages and the adoption of functional idioms in traditional languages (e.g. lambda expressions) requires a new set of studies for evaluating the effectiveness of mutation testing in a functional context. In this paper, we report our ongoing effort in applying mutation testing in functional programming languages. We describe new mutation operators for functional constructs and explain why functional languages might facilitate understanding of mutation testing results. We also introduce MuCheck, our mutation testing tool for Haskell programs."
Mutation testing of smart contracts at scale,"['P Hartel', 'R Schumi']",,"It is crucial that smart contracts are tested thoroughly due to their immutable nature. Even small bugs in smart contracts can lead to huge monetary losses. However, testing is not enough; it is also important to ensure the quality and completeness of the tests. There are already several approaches that tackle this challenge with mutation testing, but their effectiveness is questionable since they only considered small contract samples. Hence, we evaluate the quality of smart contract mutation testing at scale. We choose the most promising of the existing (smart contract specific) mutation operators, analyse their effectiveness in terms of killability and highlight severe vulnerabilities that can be injected with the mutations. Moreover, we improve the existing mutation methods by introducing a novel killing condition that is able to detect a deviation in the gas consumption, i.e., in the monetary value that is required to perform transactions."
Mutation testing: from theory to practice,['A Parsai'],,"The cost of software faults has increased from 59 billion USD in 2002 to 1.7 trillion USD in 2017. To alleviate this cost, the consensus among software engineers is to test as early and as often as possible. This, however, is not adopted by many software development teams. Most often, there are limited resources available for testing compared to the development of a product. Therefore, new techniques and methods are needed to improve testing quality in practice. Currently, most software companies rely on simple coverage metrics to assess the quality of their tests. Yet, the academic literature proposes the use of mutation testing to assess and improve the quality of software tests. Despite the promising results of mutation testing, it is not yet widely adopted in industry. We attribute this to three main problems: the performance overhead, lack of domain knowledge in tool providers, and lack of tool support. In this thesis, we address these three problems. Our results show that it is feasible to adapt the process of mutation testing based on industrial needs."
Novel approach for whole test suite generation using metamorphic relations,"['R Bandaru', 'JA Mayan']",,"Background: The software or an individual program will not get crash by the minute bugs in the code and always manual method for testing the code was not feasible, most of the cases the tester will adds the test oracles to the test cases using the manual method but it is not optimal solution for the large programs and software's and this method can targets only covering the one goal at a time. There is a problem with this coverage goals due to these goals are not independent. Methodology: To get out from these problems we propose a unique approach, in this approach we are generating the test cases automatically and developed an integrated method for program correctness, testing and debugging. Findings: We developed an unique approach in order to solve the oracle problem by using the metamorphic testing this approach also address the automatic debugging this testing uses the synergy algorithm, it does not attempt to traverse the execution tree , instead it attempts to cover all abstract states. Applications/Improvement: With metamorphic relations the system is ideal for medium and large scale applications and this approach also uses the fuzzy logic to provide the result whether the test case pass or fail."
On strong mutation and the theory of subsuming logic‐based mutants,"['B Lindström', 'A Márki']",,"Redundant mutants might cause problems when benchmarking since testing techniques can get high scores without detecting any nonredundant mutants. However, removing nonredundant mutants might cause similar problems. Subsumed mutants are per definition also redundant since no additional tests are required to detect them once all other mutants are detected. We focus on relational operator replacement (ROR) and conditional operator replacement mutants. Subsumption relations between ROR mutants are defined by fault hierarchies. The fault hierarchies are proven for weak mutation but have since they were published been used with strong mutation. We prove that ROR fault hierarchies do not hold for strong mutation and show why. We also show that the probability for a random test to experience the problem can be more than 30% and that 50% of the mutants might be affected in a real software system. Finally, we show that there is a similar problem with the theory on sufficient conditional operator replacement."
On the construction of context-aware test suites,"['H Wang', 'WK Chan', 'TH Tse']",,"Context-aware programs are responsive to various contexts and their changes. A faulty implementation of the context-awareness may lead to misbehavior. Existing techniques do not consider the amount of context changes related to program execution, so that they do not achieve their full potential in exposing faults in context-aware programs. In this paper, we propose to annotate every test case with the amount of its intrinsic context changes, and recommend several strategies that select test cases according to the amounts of context changes whenever an underlying test suite construction procedure provides a choice in test case selection. An experiment shows that the proposal significantly improves the median fault detection rates of the latest techniques for testing context-aware programs."
On the limits of mutation analysis,['R Gopinath'],,"Mutation analysis is the gold standard for evaluating test-suite adequacy. It involves exhaustive seeding of all small faults in a program and evaluating the effectiveness of test suites in detecting these faults. Mutation analysis subsumes numerous structural coverage criteria, approximates fault detection capability of test suites, and the faults produced by mutation have been shown to be similar to the real faults. This dissertation looks at the effectiveness of mutation analysis in terms of its ability to evaluate the quality of test suites, and how well the mutants generated emulate real faults. The effectiveness of mutation analysis hinges on its two fundamental hypotheses: The competent programmer hypothesis, and the coupling effect. The competent programmer hypothesis provides the model for the kinds of faults that mutation operators emulate, and the coupling effect provides guarantees on the ratio of faults prevented by a test suite that detects all simple faults to the complete set of possible faults. These foundational hypotheses determine the limits of mutation analysis in terms of the faults that can be prevented by a mutation adequate test suite. Hence, it is important to understand what factors affect these assumptions, what kinds of faults escape mutation analysis, and what impact interference between faults (coupling and masking) have. A secondary concern is the computational footprint of mutation analysis. Mutation analysis requires the evaluation of numerous mutants, each of which potentially requires complete test runs to evaluate. Numerous heuristic methods exist to reduce the number of mutants that need to be evaluated. However, we do not know the effect of these heuristics on the quality of mutants thus selected. Similarly, whether the possible improvement in representation using these heuristics are subject to any limits have also not been studied in detail. Our research investigates these fundamental questions in mutation analysis both empirically and theoretically. We show that while a majority of faults are indeed small, and hence within a finite neighborhood of the correct version, their size is larger than typical mutation operators. We show that strong interactions between simple faults can produce complex faults that are semantically unrelated to the component faults, and hence escape first order mutation analysis. We further validate the coupling effect for a large number of real-world faults, provide theoretical support for fault coupling, and evaluate its theoretical and empirical limits. Finally, we investigate the limits of heuristic mutation reduction strategies in comparison with random sampling in representativeness and find that they provide at most limited improvement. These investigations underscore the importance of research into new mutation operators and show that the potential benefit far outweighs the perceived drawbacks in terms of computational cost."
On the preliminary adaptive random testing of aspect-oriented programs,"['RM Parizi', 'AAA Ghani']",,"Adaptive random testing (ART) is a new family of random-based test data generation and selection strategies that enhances the effectiveness of tests over the classical random testing (RT). ART has been widely investigated and studied in numerous research papers over the recent years. These studies have included proposing various techniques for implementing and improving the intuition behind ART (evenly spread of test cases over the input domain, measured by some distance measures) generally for procedural programs with numerical input domain and most recently object-oriented programs. However, there is currently no work available in the literature that discusses the applicability of ART to aspect-oriented programming (AOP), as it is gaining popularity in software development. Inspired by this, this paper aims to investigate the possible ways that ART can be applied to AOP. This investigation focuses on a multi-perspective analysis of the current ART-based techniques. In this respect, we identified three related perspectives based on the current state of art in the area of ART. Each perspective was analyzed in terms of its applicability and possibility for aspect-oriented programs, particularly its constituent distance measure. As a result, our study gives rise to some interesting points and outlines a number of potential research directions in applying ART to AOP. This can pave the way for efficient development on applying of ART to AOP and finally AOP success. "
On the test-driven development of emerging modularization mechanisms,['RB Setty'],,"Emerging modularization techniques such as aspects and their precursors such as events in implicit invocation languages aim to provide a software engineer with better facilities to separate conceptual concerns in software systems. To facilitate adoption of these techniques in real world software projects, seamless integration into well-accepted practices such as a test-driven development process is essential. To that end, the main contribution of this thesis is an analysis (both pragmatic and theoretical) of the impact of a class of such techniques on the efficiency of a test-driven development process, which involves frequently compiling and testing programs in a process commonly known as the edit-compile-test cycle. I study two variants: the popular model of aspects as in the AspectJ-like languages, and a recently suggested alternative based on quantified, typed events embodied in the Ptolemy language. I present a case study analyzing two variants of the aspect-based model on two open source projects and a theoretical analysis of the quantified, typed event-based model. My results show that a seamless adoption of the aspect-based model requires careful balancing of competing parameters to ensure efficiency of a test-driven development process, whereas a quantified, typed event-based model naturally supports separate compilation thus decreasing the time spent in the edit-compile-test cycle."
Optimizing test prioritization via test distribution analysis,"['J Chen', 'Y Lou', 'L Zhang', 'J Zhou', 'X Wang']",,"Test prioritization aims to detect regression faults faster via reordering test executions, and a large number of test prioritization techniques have been proposed accordingly. However, test prioritization effectiveness is usually measured in terms of the average percentage of faults detected concerned with the number of test executions, rather than the actual regression testing time, making it unclear which technique is optimal in actual regression testing time. To answer this question, this paper first conducts an empirical study to investigate the actual regression testing time of various prioritization techniques. The results reveal a number of practical guidelines. In particular, no prioritization technique can always perform optimal in practice. To achieve the optimal prioritization effectiveness for any given project in practice, based on the findings of this study, we design learning-based Predictive Test Prioritization (PTP). PTP predicts the optimal prioritization technique for a given project based on the test distribution analysis (i.e., the distribution of test coverage, testing time, and coverage per unit time). The results show that PTP correctly predicts the optimal prioritization technique for 46 out of 50 open-source projects from GitHub, outperforming state-of-the-art techniques significantly in regression testing time, e.g., 43.16% to 94.92% improvement in detecting the first regression fault. Furthermore, PTP has been successfully integrated into the practical testing infrastructure of Baidu (a search service provider with over 600M monthly active users), and received positive feedbacks from the testing team of this company, e.g., saving beyond 2X testing costs with negligible overheads."
Path based test suite augmentation using artificial bee colony algorithm,"['D Suri', 'P Kaur']",,"Regression testing is the activity of retesting a program that ensures that no new bugs are generated into the previously tested code. This activity involves selecting a few test cases from the test suite that exercise these changes. Suppose there is a program P and P’ is it’s modified version. The regression test suite so selected should be capable enough to bring out the differences between the original program (P) and the modified program (P’) that would help the developer discover errors caused by changes. Prime importance has been laid in identifying the regression test suites and ordering them. However less focus is given to the effectiveness of regression test suite in response to changes. Moreover whether the existing test suite is sufficient for handling the changes also need to be checked. If they are not adequate then providing guidance for creating the new test cases that would be targeting the changed behaviour of the program. This problem is called as test suite augmentation. . The main aim of this paper is to explain the concept of test suite augmentation problem and applying artificial bee colony algorithm to find the affected portions in a program and checking adequacy of the existing test suite to handle those affected portions. If the existing test suite is inefficient to handle changes then manually generating the test cases to cover those requirements. The main focus of the technique is to achieve maximum path coverage."
Possibility of cost reduction by mutant clustering according to the clustering scope,"['M Yu', 'YS Ma']",,"Mutation testing offers developers a good way to improve the quality of a test set. However, the high cost of executing a large number of mutants remains an issue. This paper examines the possibility of reducing the cost of statement-level mutant clustering by comparing the number of mutant executions with those of expression-level and block-level mutant clustering. The goal is to investigate to what extent the clustering scope should be extended. The experimental results using nine real-world programs show that statement-level clustering can reduce the mutant executions that are required by expression-level clustering by 10.51% on average. Block-level clustering exhibits an unexpected result; the number of mutant executions with block-level clustering is only 1.06% times less than that with statement-level clustering. That is, statement-level clustering is more cost-effective than block-level clustering when considering their clustering overheads. A compound expression plays a major role in providing a cost-reduction effect in statement-level clustering. With a compound expression, the number of candidate mutants to be clustered in a statement scope increases, and state change can be comprehensively examined, thereby increasing the possibility of cost reduction."
Practical mutation testing at scale,"['G Petrovic', 'M Ivankovic', 'G Fraser']",,"Mutation analysis assesses a test suite's adequacy by measuring its ability to detect small artificial faults, systematically seeded into the tested program. Mutation analysis is considered one of the strongest test-adequacy criteria. Mutation testing builds on top of mutation analysis and is a testing technique that uses mutants as test goals to create or improve a test suite. Mutation testing has long been considered intractable because the sheer number of mutants that can be created represents an insurmountable problem -- both in terms of human and computational effort. This has hindered the adoption of mutation testing as an industry standard. For example, Google has a codebase of two billion lines of code and more than 500,000,000 tests are executed on a daily basis. The traditional approach to mutation testing does not scale to such an environment. To address these challenges, this paper presents a scalable approach to mutation testing based on the following main ideas: (1) Mutation testing is done incrementally, mutating only changed code during code review, rather than the entire code base; (2) Mutants are filtered, removing mutants that are likely to be irrelevant to developers, and limiting the number of mutants per line and per code review process; (3) Mutants are selected based on the historical performance of mutation operators, further eliminating irrelevant mutants and improving mutant quality. Evaluation in a code-review-based setting with more than 24,000 developers on more than 1,000 projects shows that the proposed approach produces orders of magnitude fewer mutants and that context-based mutant filtering and selection improve mutant quality and actionability. Overall, the proposed approach represents a mutation testing framework that seamlessly integrates into the software development workflow and is applicable up to large-scale industrial settings."
Predictive analytics for software testing: Keynote paper,['F Sarro'],,"This keynote discusses the use of Predictive Analytics for Software Engineering, and in particular for Software Defect Prediction and Software Testing, by presenting the latest results achieved in these fields leveraging Artificial Intelligence, Search-based and Machine Learning methods, and by giving some directions for future work."
Profile analysis techniques for observation-based software testing,['DZL Cesin'],,"Observation-based testing is a software-testing paradigm based on the idea of observing the behavior of the program when executed under a variety of test cases. The runtime behavior of a program can be summarized in profiles, which can then be analyzed for a variety of purposes useful for the tester. This dissertation presents techniques for test suite visualization, test case selection and test case prioritization based on profile data and includes extensive experiments on large, real-world applications to compare these techniques with ones from the literature. Test suite visualization is the application of multivariate visualization techniques to profile data in order to visually study the composition of the test suite and its interaction with the program. Two techniques are examined for this purpose, Correspondence Analysis and Multidimensional Scaling, and a novel algorithm for the latter is presented and studied. Example applications of test suite visualization are provided. Test case selection is the problem of selecting a small set of tests from a large test suite such that the most defects are revealed when this subset is executed. Test case prioritization is the problem of finding an optimal scheduling of the tests in a test suite so that the number of defects found earlier during testing is maximized. Other researchers have tried to address these problems using profile information, by looking at the amount of code executed by a subset of tests. Dickinson proposed some methods for test-case selection that consider the distribution of the profiles in the profile space by using cluster analysis on the profiles. This work was later extended in conjunction with the author. These methods will be presented in this work, together with novel methods for test case prioritization. Experimental validations and comparisons of all of these methods will be presented, including comparison criteria that were missing from earlier work. The results suggest that profile analysis is a useful tool for software testers, and that studying the distribution of tests in a profile space can be more beneficial than concentrating on code coverage."
"Programs, tests, and oracles: the foundations of testing revisited","['M Staats', 'MW Whalen']",,"In previous decades, researchers have explored the formal foundations of program testing. By exploring the foundations of testing largely separate from any specific method of testing, these researchers provided a general discussion of the testing process, including the goals, the underlying problems, and the limitations of testing. Unfortunately, a common, rigorous foundation has not been widely adopted in empirical software testing research, making it difficult to generalize and compare empirical research. We continue this foundational work, providing a framework intended to serve as a guide for future discussions and empirical studies concerning software testing. Specifically, we extend Gourlay's functional description of testing with the notion of a test oracle, an aspect of testing largely overlooked in previous foundational work and only lightly explored in general. We argue additional work exploring the interrelationship between programs, tests, and oracles should be performed, and use our extension to clarify concepts presented in previous work, present new concepts related to test oracles, and demonstrate that oracle selection must be considered when discussing the efficacy of a testing process."
Reconsidering automated feedback: A test-driven approach,"['K Buffardi', 'SH Edwards']",,"Writing meaningful software tests requires students to think critically about a problem and consider a variety of cases that might break the solution code. Consequently, to overcome bugs in their code, it would be beneficial for students to reflect over their work and write robust tests rather than relying on trial-and-error techniques. Automated grading systems provide students with prompt feedback on their programming assignments and may help them identify where their interpretation of requirements do not match the instructor's expectations. However, when automated grading systems help students identify bugs in their code, the systems may inadvertently discourage students from thinking critically and testing thoroughly and instead encourage dependence on the instructor's tests. In this paper, we explain a framework for identifying whether a student has adequately tested a specific feature of their code that is failing an instructor's tests. Using an implementation of the framework, we analyzed an automated grading system's feedback for programming assignments and found that it often provided hints that may discourage reflective testing."
Redefining and evaluating coverage criteria based on the testing scope,['B Miranda'],,"Test coverage information can help testers in deciding when to stop testing and in augmenting their test suites when the measured coverage is not deemed sufficient. Since the notion of a test criterion was introduced in the 70’s, research on coverage testing has been very active with much effort dedicated to the definition of new, more cost-effective, coverage criteria or to the adaptation of existing ones to a different domain. All these studies share the premise that after defining the entity to be covered (e.g., branches), one cannot consider a program to be adequately tested if some of its entities have never been exercised by any input data. However, it is not the case that all entities are of interest in every context. This is particularly true for several paradigms that emerged in the last decade (e.g., component-based development, service-oriented architecture). In such cases, traditional coverage metrics might not always provide meaningful information. In this thesis we address such situation and we redefine coverage criteria so to focus on the program parts that are relevant to the testing scope. We instantiate this general notion of scope-based coverage by introducing three coverage criteria and we demonstrate how they could be applied to different testing contexts. When applied to the context of software reuse, our approach proved to be useful for supporting test case prioritization, selection and minimization. Our studies showed that for prioritization we can improve the average rate of faults detected. For test case selection and minimization, we can considerably reduce the test suite size with small to no extra impact on fault detection effectiveness. When the source code is not available, such as in the service-oriented architecture paradigm, we propose an approach that customizes coverage, measured on invocations at service interface, based on data from similar users. We applied this approach to a real world application and, in our study, we were able to predict the entities that would be of interest for a given user with high precision. Finally, we introduce the first of its kind coverage criterion for operational profile based testing that exploits program spectra obtained from usage traces. Our study showed that it is better correlated than traditional coverage with the probability that the next test input will fail, which implies that our approach can provide a better stopping rule. Promising results were also observed for test case selection. Our redefinition of coverage criteria approaches the topic of coverage testing from a completely different angle. Such a novel perspective paves the way for new avenues of research towards improving the cost-effectiveness of testing, yet all to be explored."
Regression test case prioritization by code combinations coverage,"['R Huang', 'Q Zhang', 'D Towey', 'W Sun', 'J Chen']",,"Regression test case prioritization (RTCP) aims to improve the rate of fault detection by executing more important test cases as early as possible. Various RTCP techniques have been proposed based on different coverage criteria. Among them, a majority of techniques leverage code coverage information to guide the prioritization process, with code units being considered individually, and in isolation. In this paper, we propose a new coverage criterion, code combinations coverage, that combines the concepts of code coverage and combination coverage. We apply this coverage criterion to RTCP, as a new prioritization technique, code combinations coverage based prioritization (CCCP). We report on empirical studies conducted to compare the testing effectiveness and efficiency of CCCP with four popular RTCP techniques: total, additional, adaptive random, and search-based test prioritization. The experimental results show that even when the lowest combination strength is assigned, overall, the CCCP fault detection rates are greater than those of the other four prioritization techniques. The CCCP prioritization costs are also found to be comparable to the additional test prioritization technique. Moreover, our results also show that when the combination strength is increased, CCCP provides higher fault detection rates than the state-of-the-art, regardless of the levels of code coverage."
Regression testing in software product line engineering,"['P Runeson', 'E Engström']",,"Software product line engineering is an approach to cost-efficiently derive tailored products to markets and customers, utilizing common components and services in a planned manner. Product lines have been applied to other engineering fields for decades, while being quite recently introduced in software engineering. For software product lines, productivity gains are mostly related to the development process. Especially, software product line testing faces challenges in the vast number of versions and variants of software products to be tested, originating from a software product line, and consequently the risk for redundant testing. The testing challenges resemble those of regression testing in one-off software development, although adding the complexity of parallel variants. Ongoing research provide some support for software product line test selection, although they are too small-scale and require more formalism than generally available in practice. We propose a visualization approach to help test managers improve communication about testing in order to utilize test resources efficiently."
"Regression testing minimization, selection and prioritization: a survey","['S Yoo', 'M Harman']",,"Regression testing is a testing activity that is performed to provide confidence that changes do not harm the existing behaviour of the software. Test suites tend to grow in size as software evolves, often making it too costly to execute entire test suites. A number of different approaches have been studied to maximize the value of the accrued test suite: minimization, selection and prioritization. Test suite minimization seeks to eliminate redundant test cases in order to reduce the number of tests to run. Test case selection seeks to identify the test cases that are relevant to some set of recent changes. Test case prioritization seeks to order test cases in such a way that early fault detection is maximized. This paper surveys each area of minimization, selection and prioritization technique and discusses open problems and potential directions for future research."
Relation-based test case prioritization for regression testing,"['J Chi', 'Y Qu', 'Q Zheng', 'Z Yang', 'W Jin', 'D Cui']",,"Test case prioritization (TCP), which aims at detecting faults as early as possible is broadly used in program regression testing. Most existing TCP techniques exploit coverage information with the hypothesis that higher coverage has more chance to catch bugs. Static structure information such as function and statement are frequently employed as coverage granularity. However, the former consumes less costs but presents lower capability to detect faults, the latter typically incurs more overhead. In this paper, dynamic function call sequences are argued that can guide TCP effectively. Same set of functions/statements can exhibit very different execution behaviors. Therefore, mapping program behaviors to unit-based (function/statement) coverage may not be enough to predict fault detection capability. We propose a new approach AGC (Additional Greedy method Call sequence). Our approach leverages dynamic relation-based coverage as measurement to extend the original additional greedy coverage algorithm in TCP techniques. We conduct our experiments on eight real-world java open source projects and systematically compare AGC against 22 state-of-the-art TCP techniques with different granularities. Results show that AGC outperforms existing techniques on large programs in terms of bug detection capability, and also achieves the highest mean APFD value. The performance demonstrates a growth trend as the size of the program increases."
"Running students' software tests against each others' code: new life for an old"" gimmick""","['SH Edwards', 'Z Shams', 'M Cogswell']",,"At SIGCSE 2002, Michael Goldwasser suggested a strategy for adding software testing practices to programming courses by requiring students to turn in tests along with their solutions, and then running every student's tests against every other student's program. This approach provides a much more robust environment for assessing the quality of student-written tests, and also provides more thorough testing of student solutions. Although software testing is included as a regular part of many more programming courses today, the all-pairs model of executing tests is still a rarity. This is because student-written tests, such as JUnit tests written for Java programs, are now more commonly written in the form of program code themselves, and they may depend on virtually any aspect of their author's own solution. These dependencies may keep one student's tests from even compiling against another student's program. This paper discusses the problem and presents a novel solution for Java that uses bytecode rewriting to transform a student's tests into a form that uses reflection to run against any other solution, regardless of any compile-time dependencies that may have been present in the original tests. Results of applying this technique to two assignments, encompassing 147 student programs and 240,158 individual test case runs, shows the feasibility of the approach and provides some insight into the quality of both student tests and student programs. An analysis of these results is presented."
SS-BDD: automated acceptance testing for spreadsheets,"['L Almeida', 'E Cirilo', 'EA Barbosa']",,"Current Spreadsheet Applications, such as Excel and Google Sheets, provide innumerous built-in facilities, including arithmetic, financial and statistical operations, as well as conditional expressions. Thus, users with little or no formal training in programming can use Spreadsheet Applications to implement their own Spreadsheet Programs. In fact, Spreadsheet Applications have become one of the most popular end-user programming environments nowadays. However, these applications also ease the introduction of errors in Spreadsheet Programs. Minor mistakes in formulas can mislead decisionmaking processes, resulting in uncountable costs to organizations. In general, end-user programmers are unaware of the potential risks that the uncontrolled construction of Spreadsheet Programs can cause. Therefore, a major focus of this paper is to offer an automated approach that makes programmers aware of introduced faults, so that they can build high quality Spreadsheet Programs. In particular, we propose SS-BDD, a framework for building and running Spreadsheets test scenarios, which relies on the use of Behavior Driven Development (BDD). We used SS-BDD to test three different Spreadsheet Programs. Our experience shows that SS-BDD can be used to build end-user friendly test scenarios which can achieve high fault-detection effectiveness."
STADS: Software testing as species discovery,['M Böhme'],,"A fundamental challenge of software testing is the statistically well-grounded extrapolation from program behaviors observed during testing. For instance, a security researcher who has run the fuzzer for a week has currently no means (1) to estimate the total number of feasible program branches, given that only a fraction has been covered so far; (2) to estimate the additional time required to cover 10% more branches (or to estimate the coverage achieved in one more day, respectively); or (3) to assess the residual risk that a vulnerability exists when no vulnerability has been discovered. Failing to discover a vulnerability does not mean that none exists—even if the fuzzer was run for a week (or a year). Hence, testing provides no formal correctness guarantees. In this article, I establish an unexpected connection with the otherwise unrelated scientific field of ecology and introduce a statistical framework that models Software Testing and Analysis as Discovery of Species (STADS). For instance, in order to study the species diversity of arthropods in a tropical rain forest, ecologists would first sample a large number of individuals from that forest, determine their species, and extrapolate from the properties observed in the sample to properties of the whole forest. The estimations (1) of the total number of species, (2) of the additional sampling effort required to discover 10% more species, or (3) of the probability to discover a new species are classical problems in ecology. The STADS framework draws from over three decades of research in ecological biostatistics to address the fundamental extrapolation challenge for automated test generation. Our preliminary empirical study demonstrates a good estimator performance even for a fuzzer with adaptive sampling bias—AFL, a state-of-the-art vulnerability detection tool. The STADS framework provides statistical correctness guarantees with quantifiable accuracy."
STAGE: a software tool for automatic grading of testing exercises: case study paper,"['S Pape', 'J Flake', 'A Beckmann', 'J Jürjens']",,"We report on an approach and associated tool-support for automatically evaluating and grading exercises in Software Engineering courses, by connecting various third-party tools to the online learning platform Moodle. In the case study presented here, the tool was used in several instances of a lecture course to automatically measure the test coverage criteria wrt. the test cases defined by the students for given Java code. We report on empirical evidence gathered using this case-study (involving more than 250 students), including the results of a survey conducted after the exercises (which yielded positive feedback from the students), as well as a performance evaluation of our tool implementation."
Search-based testing in financial applications,['MM Almasi'],,"Automated unit test generation has been extensively studied in the literature in recent years. Previous studies on open source systems have shown that test generation tools are quite effective at detecting faults, but how effective and applicable are they in an industrial application? In this thesis, this question is investigated in two phases. In the first phase, I empirically investigate the effectiveness and applicability of existing automated unit test generation tools and techniques in an industrial financial application known as LifeCalc which is a life insurance products calculator engine owned by SEB Life & Pension Holding AB Riga Branch. In the second phase, I focus more on the software characteristics of financial application domain. In this domain, many legacy applications exist as a collection of formulas implemented in spreadsheets. These legacy code, at some point, will be migrated to more modern development environment. However, migration of such code to a full-edged system is an error-prone process. While small differences in the outputs of numerical calculations produced by the two artifacts are tolerable, large discrepancies could have serious financial implications. Therefore, in this phase, I introduce a novel specialized search-based unit test generation technique that seeks to uncover the deviation failures in the migrated code automatically."
Searching for test data,['K Ghani'],,"In recent years metaheuristic search techniques have been applied successfully to solve many software engineering problems. One area in particular where these techniques have gained much attention is search based test data generation. Many techniques have been applied to generate test data for structural, functional as well as non-functional testing across different levels of abstractions of a software system. In this thesis we extend current search based approaches to cover stronger criteria, extend current work on higher level models to include further optimisation techniques, enhance current approaches to target “difficult” branches, and show how to apply current approaches to refine specifications generated automatically by tools such as Daikon."
Seeding strategies for multi-objective test case selection: an application on simulation-based testing,"['A Arrieta', 'JA Agirre', 'G Sagardui']",,"The time it takes software systems to be tested is usually long. This is often caused by the time it takes the entire test suite to be executed. To optimize this, regression test selection approaches have allowed for improvements to the cost-effectiveness of verification and validation activities in the software industry. In this area, multi-objective algorithms have played a key role in selecting the appropriate subset of test cases from the entire test suite. In this paper, we propose a set of seeding strategies for the test case selection problem that generate the initial population of multi-objective algorithms. We integrated these seeding strategies with an NSGA-II algorithm for solving the test case selection problem in the context of simulation-based testing. We evaluated the strategies with six case studies and a total of 21 fitness combinations for each case study (i.e., a total of 126 problems). Our evaluation suggests that these strategies are indeed helpful for solving the multi-objective test case selection problem. In fact, two of the proposed seeding strategies outperformed the NSGA-II algorithm without seeding population with statistical significance for 92.8 and 96% of the problems."
Semantic-preserving test model transformations for interchangeable coverage criteria,['S Weißleder'],,"Testing cannot be complete. Heuristic means like coverage criteria are applied to measure the quality of tests. In model-based testing, it is common to apply coverage criteria to test models. Beyond test quality measurement, coverage criteria are also used to steer test generation. However, model-based test generators are often restricted to satisfy a limited set of coverage criteria. In this paper, we present test model transformations as an alternative to the satisfaction of unsupported coverage criteria. We show several transformations for different coverage criteria. Thus, model transformations can be understood as a means to make coverage criteria interchangeable. The foundation of this work are experiences from an industrial cooperation."
Semi-automatic security testing of web applications with fault models and properties,['M Büchler'],,"Web applications are complex and face complex attacks, as well. Thus, security vulnerabilities are hard to find. To tackle this complexity we analyze abstract models of these web applications. We generate test cases by (semi-) automatically injecting faults into the models and utilize systematic verification techniques to generate abstract test cases. To test real implementations, we operationalize them with the help of web browsers and penetration testing techniques. Our evaluation shows that non-trivial multi-step XSS and SQL attacks can effectively be found."
Simulation-based test adequacy criteria for distributed systems,"['MJ Rutherford', 'A Carzaniga', 'AL Wolf']",,"Developers of distributed systems routinely construct discrete-event simulations to help understand and evaluate the behavior of inter-component protocols. Simulations are abstract models of systems and their environments, capturing basic algorithmic functionality at the same time as they focus attention on properties critical to distribution, including topology, timing, bandwidth, and overall scalability. We claim that simulations can be treated as a form of specification, and thereby used within a specification-based testing regime to provide developers with a rich new basis for defining and applying system-level test adequacy criteria. We describe a framework for evaluating distributed system test adequacy criteria, and demonstrate our approach on simulations and implementations of three distributed systems, including DNS, the Domain Name System."
Simulation-based testing of distributed systems,"['MJ Rutherford', 'A Carzaniga', 'AL Wolf']",,"Developers of distributed systems routinely construct discrete-event simulations to help them understand and evaluate the behavior of inter-component protocols. Typically written using an imperative programming language, these simulations capture basic algorithmic functionality at the same time as they focus attention on properties critical to distribution, including topology, timing, bandwidth, and overall scalability. We ask the following question Can simulations also be used to help in the testing of distributed-system implementations Because simulations amount to specifications of intended behavior, the code of a simulation can be viewed as an operational, albeit non-traditional, formal model. We claim that this kind of model, when used within a specification-based testing regime, provides developers with the foundations of a powerful new method for selecting effective test suites. The primary tool used in our method is a fault-based analysis of the simulation code in which a set of mutants are generated using standard code-mutation techniques. The analysis can be used to rate the effectiveness of a test suite, as well as the criterion used to form it. We substantiate our claim through experiments performed on the simulations and implementations of two different distributed systems."
Software semantics and syntax as a tool for automated test generation,"['N Nahar', 'K Sakib']",,"Test automation saves time and cost by digitising test generation and execution. The existing techniques fail to produce effective and compliable test scripts for not considering both syntactic and semantic information. The proposed three-layer architecture incorporates these information for generation of proper test scripts. It analyses the source code for extracting syntax and UML diagrams for obtaining semantics. Class methods and sequence of calls are extracted from UMLs, and syntax for class instantiations and method calls are accumulated from source code to generate unit and integration tests. A case study as well as experiments, conducted on sample Java projects, conform the competence of the generation process along with the generated test scripts."
Software testing,"['G Fraser', 'JM Rojas']",,"Any nontrivial program contains some errors in the source code. These “bugs” are annoying for users if they lead to application crashes and data loss, and they are worrisome if they lead to privacy leaks and security exploits. The economic damage caused by software bugs can be huge, and when software controls safety critical systems such as automotive software, then bugs can kill people. The primary tool to reveal and eliminate bugs is software testing: Testing a program means executing it with a selected set of inputs and checking whether the program behaves in the expected way; if it does not, then a bug has been detected. The aim of testing is to find as many bugs as possible, but it is a difficult task as it is impossible to run all possible tests on a program. The challenge of being a good tester is thus to identify which are the best tests that help us find bugs, and to execute them as efficiently as possible. In this chapter, we explore different ways to measure how “good” a set of tests is, as well as techniques to generate good sets of tests."
"Specify and measure, cover and reveal: A unified framework for automated test generation","['S Bardin', 'N Kosmatov', 'M Marcozzi']",,"Automatic test input generation (ATG) is a major topic in software engineering, analysis and security. In this paper, we bridge the gap between state-of-the-art white-box ATG techniques, especially Dynamic Symbolic Execution, and the diversity of test objectives that they may be used to cover in practice, including many of those defined by common source-code coverage criteria. We define a new coverage specification mechanism, called labels, for specifying test objectives, and prove it to be both expressive and amenable to efficient automation. We present an efficient approach for detecting – revealing – infeasible (i.e. uncoverable) test objectives expressed as labels. We demonstrate that measuring the achieved coverage can be efficiently performed for labels. Finally, we propose an innovative extension of DSE resulting in an efficient support for label coverage, while the existing naive approach induces an exponential blow-up of the search space. Experiments show that our ATG technique yields very significant savings and confirm the interest of infeasible label detection, enabling to lift DSE to label coverage with only a slight overhead. Overall, we show that label coverage provides the basis of a rich framework allowing one to express and handle test objectives from various contexts in an efficient and generic manner. To illustrate this framework, we describe LTest, an all-in-one testing toolset based on labels and used in the industry, which offers automatic program annotation, ATG, coverage measurement and detection of infeasible test objectives."
Speeding up mutation testing via the cloud: lessons learned for further optimisations,"['S Vercammen', 'S Demeyer', 'M Borg', 'S Eldh']",,"Background: Mutation testing is the state-of-the-art technique for assessing the fault detection capacity of a test suite. Unfortunately, it is seldom applied in practice because it is computationally expensive. We witnessed 48 hours of mutation testing time on a test suite comprising 272 unit tests and 5,258 lines of test code for testing a project with 48,873 lines of production code. Aims: Therefore, researchers are currently investigating cloud solutions, hoping to achieve sufficient speed-up to allow for a complete mutation test run during the nightly build. Method: In this paper we evaluate mutation testing in the cloud against two industrial projects. Results: With our proof-of-concept, we achieved a speed-up between 12x and 12.7x on a cloud infrastructure with 16 nodes. This allowed to reduce the aforementioned 48 hours of mutation testing time to 3.7 hours. Conclusions: We make a detailed analysis of the delays induced by the distributed architecture, point out avenues for further optimisation and elaborate on the lessons learned for the mutation testing community. Most importantly, we learned that for optimal deployment in a cloud infrastructure, tasks should remain completely independent. Mutant optimisation techniques that violate this principle will benefit less from deploying in the cloud."
Speeding up test execution with increased cache locality,"['P Stratis', 'A Rajan']",,"As the scale and complexity of software increases, the number of tests needed for effective validation becomes extremely large. Executing these large test suites is expensive, both in terms of time and energy. Cache misses are a significant contributing factor to execution time of software. We propose an approach that helps order test executions in a test suite in such a way that instruction cache misses are reduced. We also ensure that the approach scales to large test suite sizes. We conduct an empirical evaluation with 20 subject programs and test suites from the SIR repository, EEMBC suite, and LLVM Symbolizer, comparing execution times and cache misses with test orderings maximising instruction locality versus a traditional ordering maximising coverage and random permutations. We also assess overhead of algorithms in generating the orderings that optimise cache locality. Nature of programs and tests impact the performance gained with our approach. Performance gains were considerable for programs and test suites where the average number of different instructions executed between tests was high. We achieved an average execution speedup of 6.83% and a maximum execution speedup of 17% over subject programs with differing control flow between test executions."
Statement frequency coverage: A code coverage criterion for assessing test suite effectiveness,"['A Aghamohammadi', 'SH Mirian-Hosseinabadi']",,"Context: Software testing is a pivotal activity in the development of high-quality software. As software is evolving through its life cycle, the need for a fault-revealing criterion assessing the effectiveness of the test suite grows. Over the years, researchers have proposed coverage-based criteria, including statement and branch coverage, to solve this issue. In literature, the effectiveness of such criteria is attested in terms of their correlations with the mutation score. Objective: In this paper, we aim at proposing a coverage-based criterion named statement frequency coverage, which outperforms statement and branch coverage in terms of correlation with mutation score. Method: To this end, we incorporated the frequency of executed statements into statement coverage and created a coverage-based criterion for assessing test suite effectiveness. Statement frequency coverage assigns a continuous value to a statement whose value is proportional to the number of times executed during test execution. We evaluated our approach on 22 real-world Python projects with more than 118 000 source lines of code (without blank lines, comments, and test cases) and 21 000 test cases through measuring the correlation between statement frequency coverage and corresponding mutation score. Results: The results show that statement frequency coverage outperforms statement and branch coverage criteria. The correlation between it and the corresponding mutation score is higher than the correlation of statement and branch coverage with their mutation score. The results also show that unlike statement and branch coverage, there is no statistical difference between statement frequency coverage and mutation score. Conclusion: Statement frequency coverage is a better choice compared to statement and branch coverage in assessing test suite effectiveness in the real-world setting. Furthermore, we demonstrate that although statement frequency coverage subsumes statement coverage, it is incomparable to branch coverage under the adequate test suite condition."
Strong model-based mutation testing,['A Fellner'],,"Powerful verification and validation methods are needed to keep up with the complexity of modern systems. While testing remains the most prevalent verification and validation method, scaling testing to huge and interdependent systems poses a big challenge. We address this challenge by presenting scalable methods for model-based mutation testing with a focus on strong mutation and non-deterministic models of concurrent reactive systems. Model-based testing aims to automatically create test cases from a model of some system under test. We use mutations as the driving criterion in model-based test generation. Strong mutation analysis aims to reveal differences in the output of a model and mutations of it via test cases. Mutations mimic implementation errors and a key assumption of mutation testing is that the ability of a test suite to reveal artificial errors carries over to its ability to reveal actual faults.We establish a rigorous theoretical framework for strong model-based mutation testing in presence of non-determinism. We embedded this framework into the theory of hyperproperties, which enables mutation testing via hyperproperty model checking and thus rigorous mutation analysis. Furthermore, we propose an explicit state and exploration-based test case generation algorithm that is tuned for scalability. It executes mutants lazily and explores state spaces in a branching search manner. Finally, we enable test case generation for highly concurrent models by connecting this algorithm with event structure-based partial order reduction. To this end, we map strong killing onto a language inclusion problem over event structures, prove the computational complexity of this problem, provide a decision algorithm for it, and obtain a novel type of test cases that incorporates the concurrent behavior of the model."
Study of integrating random and symbolic testing for object-oriented software,"['M Dimjašević', 'F Howar', 'K Luckow']",,"Testing is currently the main technique adopted by the industry for improving the quality, reliability, and security of software. In order to lower the cost of manual testing, automatic testing techniques have been devised, such as random and symbolic testing, with their respective trade-offs. For example, random testing excels at fast global exploration of software, while it plateaus when faced with hard-to-hit numerically-intensive execution paths. On the other hand, symbolic testing excels at exploring such paths, while it struggles when faced with complex heap class structures. In this paper, we describe an approach for automatic unit testing of object-oriented software that integrates the two techniques. We leverage feedback-directed unit testing to generate meaningful sequences of constructor+method invocations that create rich heap structures, and we in turn further explore these sequences using dynamic symbolic execution. We implement this approach in a tool called JDoop, which we augment with several parameters for fine-tuning its heuristics; such “knobs” allow for a detailed exploration of the various trade-offs that the proposed integration offers. Using JDoop, we perform an extensive empirical exploration of this space, and we describe lessons learned and guidelines for future research efforts in this area."
Swarm testing,"['A Groce', 'C Zhang', 'E Eide', 'Y Chen']",,"Swarm testing is a novel and inexpensive way to improve the diversity of test cases generated during random testing. Increased diversity leads to improved coverage and fault detection. In swarm testing, the usual practice of potentially including all features in every test case is abandoned. Rather, a large “swarm” of randomly generated configurations, each of which omits some features, is used, with configurations receiving equal resources. We have identified two mechanisms by which feature omission leads to better exploration of a system’s state space. First, some features actively prevent the system from executing interesting behaviors; e.g., “pop” calls may prevent a stack data structure from executing a bug in its overflow detection logic. Second, even when there is no active suppression of behaviors, test features compete for space in each test, limiting the depth to which logic driven by features can be explored. Experimental results show that swarm testing increases coverage and can improve fault detection dramatically; for example, in a week of testing it found 42% more distinct ways to crash a collection of C compilers than did the heavily hand-tuned default configuration of a random tester."
Symcretic testing of programs,['P Dinges'],,"Targeted inputs are input values for a program that lead to the execution of a user-specified branch or statement. Targeted inputs are useful: In debugging, for example, they allow programmers to follow the execution towards the program point where a bug occurred. In testing, they constitute a test case that covers a new piece of code. A natural approach to find targeted inputs is symbolic backward execution. However, symbolic backward execution struggles with complicated arithmetic, external method calls, and data-dependent loops that occur in many real-world programs. This dissertation describes symcretic execution, a novel method for efficiently finding targeted inputs. Symcretic execution overcomes the limitations of symbolic backward execution by integrating it with concrete forward execution. The approach consists of two phases: In its first phase, symcretic execution uses symbolic backward execution to find a feasible execution path from the given target to any of the program’s entry points. Unlike prior approaches, symcretic execution ‘skips’ over constraints that are problematic for the symbolic decision procedure and defers their solution until the second phase. The second phase of symcretic execution begins when the symbolic execution reaches an entry point. In this phase, symcretic execution uses concrete forward execution and heuristic search to find inputs that satisfy the constraints that were skipped in the first phase. A comparison with related approaches and an empirical evaluation suggest that symcretic execution finds more inputs that result in relevant executions while avoiding the exploration of uninteresting paths. The heuristic search algorithm employed in the second phase of symcretic execution must be able to handle complicated arithmetic and external method calls. The dissertation therefore introduces an algorithm called concolic walk. The concolic walk algorithm also applies to solving path conditions in customary symbolic and concolic execution and is thus presented in this more general setting. The concolic walk algorithm is a heuristic search based on a geometric interpretation of the task of finding inputs. An evaluation of the algorithm shows that it finds more solutions (and hence improves coverage) than the simplification-based heuristics that have been used in concolic testing. Moreover, the concolic walk algorithm improves the effectiveness of state-of-the-art concolic test generators that are using powerful specialized constraint solvers."
Tailored mutants fit bugs better,"['M Allamanis', 'ET Barr', 'R Just', 'C Sutton']",,"Mutation analysis measures test suite adequacy, the degree to which a test suite detects seeded faults: one test suite is better than another if it detects more mutants. Mutation analysis effectiveness rests on the assumption that mutants are coupled with real faults i.e. mutant detection is strongly correlated with real fault detection. The work that validated this also showed that a large portion of defects remain out of reach. We introduce tailored mutation operators to reach and capture these defects. Tailored mutation operators are built from and apply to an existing codebase and its history. They can, for instance, identify and replay errors specific to the project for which they are tailored. As our point of departure, we define tailored mutation operators for identifiers, which mutation analysis has largely ignored, because there are too many ways to mutate them. Evaluated on the Defects4J dataset, our new mutation operators creates mutants coupled to 14% more faults, compared to traditional mutation operators. These new mutation operators, however, quadruple the number of mutants. To combat this problem, we propose a new approach to mutant selection focusing on the location at which to apply mutation operators and the unnaturalness of the mutated code. The results demonstrate that the location selection heuristics produce mutants more closely coupled to real faults for a given budget of mutation operator applications. In summary, this paper defines and explores tailored mutation operators, advancing the state of the art in mutation testing in two ways: 1) it suggests mutation operators that mutate identifiers and literals, extending mutation analysis to a new class of faults and 2) it demonstrates that selecting the location where a mutation operator is applied decreases the number of generated mutants without affecting the coupling of mutants and real faults."
Test adequacy assessment using test-defect coverage analytic model,"['SM Syed-Mohamad', 'NH Haron']",,"Software testing is an essential activity in software development process that has been widely used as a means of achieving software reliability and quality. The emergence of incremental development in its various forms required a different approach to determining the readiness of the software for release. This approach needs to determine how reliable the software is likely to be based on planned tests, not defect growth and decline as typically shown in reliability growth models. A combination of information from a number of sources into an easily understood dashboard is expected to provide both qualitative and quantitative analyses of test and defect coverage properties. Hence, Test-Defect Coverage Analytic Model (TDCAM) is proposed which combines test and defect coverage information presented in a dashboard to help deciding whether there are enough tests planned. A case study has been conducted to demonstrate the usage of the proposed model. The visual representations and results gained from the case study show the benefits of TDCAM in assisting practitioners making informed test adequacy-related decisions."
Test coverage and impact analysis for detecting refactoring faults: a study on the extract method refactoring,"['ELG Alves', 'T Massoni', 'PDL Machado']",,"Refactoring validation by automated testing is a common practice in agile development processes. However, this practice can be misleading when the test suite is not adequate. Particularly, refactoring faults can be tricky and difficult to detect. While coverage analysis is a standard practice to evaluate a test suite's fault detection capability, there is usually low correlation between coverage and fault detection. In this paper, we present an exploratory study on coverage of refactoring-impacted code, in order to identify shortcomings of test suites, focusing on the Extract Method Refactoring. We consider three open-source projects and their test suites. The results show that, in most cases, the lacking of test case calling the method changed in the refactoring increases the chance of missing faults. Also, a high proportion of test cases that do not cover the callers of that method does not reveal the fault either. Additional analysis of branch coverage on the test cases exercising impacted elements show a higher chance of detecting a fault when branch coverage is also high. It seems reasonable to conclude that a combination of impact analysis with branch coverage could be highly effective in detecting faults introduced by Extract Method."
Test coverage and impact analysis for detecting refactoring faults: a study on the inline method,"['I Alazzam', 'MS Al-Amri']",,"Using refactoring techniques is known as a good practice to enhance the software quality either by decreasing the complexity or enhance the behaviour of the software. Here, we conduct a study using inline method refactoring technique to investigate the significance of this technique, in order to examine how this kind of refactoring affect the coverage of the test suite by applying impact analysis of test coverage. We apply inline method refactoring on one package of JGAP; open source java project and make some experiments. The results show the inline method refactoring has essential benefit in decreasing complexity. On the other hand the results reveal that this refactoring technique has a negative impact on coverage from testing perspective."
Test coverage of impacted code elements for detecting refactoring faults: An exploratory study,"['ELG Alves', 'T Massoni', 'PD de Lima Machado']",,"Refactoring validation by testing is critical for quality in agile development. However, this activity may be misleading when a test suite is insufficiently robust for revealing faults. Particularly, refactoring faults can be tricky and difficult to detect. Coverage analysis is a standard practice to evaluate fault detection capability of test suites. However, there is usually a low correlation between coverage and fault detection. In this paper, we present an exploratory study on the use of coverage data of mostly impacted code elements to identify shortcomings in a test suite. We consider three real open source projects and their original test suites. The results show that a test suite not directly calling the refactored method and/or its callers increases the chance of missing the fault. Additional analysis of branch coverage on test cases shows that there are higher chances of detecting a refactoring fault when branch coverage is high. These results give evidence that a combination of impact analysis with branch coverage could be highly effective in detecting faults introduced by refactoring edits. Furthermore, we propose a statistic model that evidences the correlation of coverage over certain code elements and the suite’s capability of revealing refactoring faults."
Test effort and test coverage: correlation analysis in a safety critical operating system,"['D Di Leo', 'R Natella', 'R Pietrantuono', 'B Ovilio']",x (not English),
Test generation for high coverage with abstraction refinement and coarsening (ARC),['M Baluda'],,"Testing is the main approach used in the software industry to expose failures. Producing thorough test suites is an expensive and error prone task that can greatly benefit from automation. Two challenging problems in test automation are generating test input and evaluating the adequacy of test suites: the first amounts to producing a set of test cases that accurately represent the software behavior, the second requires defining appropriate metrics to evaluate the thoroughness of the testing activities. Structural testing addresses these problems by measuring the amount of code elements that are executed by a test suite. The code elements that are not covered by any execution are natural candidates for generating further test cases, and the measured coverage rate can be used to estimate the thoroughness of the test suite. Several empirical studies show that test suites achieving high coverage rates exhibit a high failure detection ability. However, producing highly covering test suites automatically is hard as certain code elements are executed only under complex conditions while other might be not reachable at all. In this thesis we propose Abstraction Refinement and Coarsening (ARC), a goal oriented technique that combines static and dynamic software analysis to automatically generate test suites with high code coverage. At the core of our approach there is an abstract program model that enables the synergistic application of the different analysis components. In ARC we integrate Dynamic Symbolic Execution (DSE) and abstraction refinement to precisely direct test generation towards the coverage goals and detect infeasible elements. ARC includes a novel coarsening algorithm for improved scalability. We implemented ARC-B, a prototype tool that analyses C programs and produces test suites that achieve high branch coverage. Our experiments show that the approach effectively exploits the synergy between symbolic testing and reachability analysis outperforming state of the art test generation approaches. We evaluated ARC-B on industry relevant software, and exposed previously unknown failures in a safety-critical software component."
Test models and coverage criteria for automatic model-based test generation with UML state machines,['S Weißleder'],,"Testing is an important means of quality management and is widely used in industrial practice. Model-based functional testing is focussed on comparing the system under test to a test model. This comparison usually consists of automatically generating a test suite from the test model, executing the test suite, and comparing the observable behavior to the expected one. Important advantages of model-based testing are formal test specifications that are close to requirements, traceability of these requirements to test cases, and the automation of test case design, which helps reducing test costs. Testing cannot be complete in many cases: For test models that describe, e.g., non-terminating systems, it is possible to derive a huge and possibly infinite number of different test cases. Coverage criteria are a popular heuristic means to measure the fault detection capability of test suites. They are also used to steer and stop the test generation process. There are several open questions about test models and coverage criteria. For instance, the UML 2.1 defines 13 different kinds of diagrams, which are often used in isolation although it might be beneficial to combine them. Furthermore, there are several unconnected kinds of coverage criteria. Most of them are very useful and here, too, the question for ways to combine their benefits is very interesting. Moreover, the relation between test models and coverage criteria is not researched thoroughly yet and the question for mutual dependencies remains. The context of this thesis is automatic model-based test generation with UML state machines. The focus is on test models, coverage criteria, and their relations. We present new approaches to combine coverage criteria, to use model transformations for testing, and to combine state machines with other test models. In detail, we present a test generation algorithm that allows to combine control-flow-, data-flow-, or transition-based coverage criteria with boundary-based coverage criteria. We also show how to transform state machines in order to simulate the satisfaction of coverage criteria, to combine coverage criteria, or to define and implement new coverage criteria. Furthermore, we present ways to combine state machines with class diagrams and with interaction diagrams. We also show how to influence the efficiency of the generated test suite. Finally, we developed the prototype implementation ParTeG for the mentioned contributions and applied it to standard examples, academic applications, and industrial case studies."
Test-splitter: creating unit tests from system tests with different input combinations,['O Demir'],,"In this thesis, an automated test generation technique for creating unit tests from system tests is presented. Our technique includes two main approaches, which are splitting a test into multiple tests and alternating the input values of the tests by applying different input combinations. We also present our tool which allows this technique to be applied on Java projects. We evaluated our technique on popular open-source projects. The results show that our technique can effectively create unit tests from system tests and increase the code coverage of the test suite by applying different combinations for input values."
The application perspective of mutatoin testing.,['Q Zhu'],,"The main goal of this thesis is to investigate, improve and extend the applicability of mutation testing. To seek the potential directions of how to improve and extend the applicability of mutation testing, we have started with a systematic literature review on the current state of how mutation testing is applied. The results from the systematic literature review have further guided us towards three directions of research: (1) speeding up mutation testing; (2) deepening our understanding ofmutation testing; (3) exploring new application domains ofmutation testing. For the first direction, we have leveraged compression techniques and weak mutation information to speed up mutation testing. The results have shown our proposed mutant compression techniques can effectively speed up strong mutation testing up to 94.3 times with an accuracy > 90%. Given the second direction, we are interested in gaining a better understanding of mutation testing especially in the situation where engineers cannot kill all the mutants by just adding test cases. We have investigated the relationships between code quality regarding the testability and observability, and the mutation score. We have observed a correlation between observability metrics and the mutation score. Furthermore, relatively simple refactoring operations/adding tests enable an increase in the mutation score. As for the third direction, we have explored two new application domains: one is physical computing, and the other is GPU programming. In both application domains, we have designed new mutation operators based on our observations of the common mistakes that could happen during the implementation of the software. We have found promising results in that mutation testing can help in revealing weaknesses of the test suite for both application domains. In summary, we have improved the applicability of mutation by proposing a new speed-up approach and investigating the relationship between testability/observability and mutation testing. Also, we have extended the applicability of mutation testing in physical computing and GPU programming domains."
"The correlation between code coverage, cyclomatic complexity and fault frequency",['S Persson'],,"The quality of software gets more and more important as software is introduced to systems that are important to the infrastructure of modern society. This thesis studies one such code base developed at Ericsson AB, that is a vital piece of software for our infrastructure. With an increased need for quality in software, it is important that we have quantifiable metrics that can be used to steer the development of software in a direction that leads to fewer faults. We look at the software metrics cyclomatic complexity and variations of code coverageand analyse how these metrics correlate to faults in the code. We find that code coverage has a weak negative correlation at best, but can have a weak positive correlation at worst (such that faults increase as coverage increases). The cyclomatic complexity metric has not been found to have any correlation at all to software faults."
The effect of program and model structure on the effectiveness of mc/dc test adequacy coverage,"['G Gay', 'A Rajan', 'M Staats', 'M Whalen']",,"Test adequacy metrics defined over the structure of a program, such as Modified Condition and Decision Coverage (MC/DC), are used to assess testing efforts. However, MC/DC can be “cheated” by restructuring a program to make it easier to achieve the desired coverage. This is concerning, given the importance of MC/DC in assessing the adequacy of test suites for critical systems domains. In this work, we have explored the impact of implementation structure on the efficacy of test suites satisfying the MC/DC criterion using four real-world avionics systems. Our results demonstrate that test suites achieving MC/DC over implementations with structurally complex Boolean expressions are generally larger and more effective than test suites achieving MC/DC over functionally equivalent, but structurally simpler, implementations. Additionally, we found that test suites generated over simpler implementations achieve significantly lower MC/DC and fault-finding effectiveness when applied to complex implementations, whereas test suites generated over the complex implementation still achieve high MC/DC and attain high fault finding over the simpler implementation. By measuring MC/DC over simple implementations, we can significantly reduce the cost of testing, but in doing so, we also reduce the effectiveness of the testing process. Thus, developers have an economic incentive to “cheat” the MC/DC criterion, but this cheating leads to negative consequences. Accordingly, we recommend that organizations require MC/DC over a structurally complex implementation for testing purposes to avoid these consequences."
The emerging field of test amplification: A survey,"['B Danglot', 'O Vera-Perez', 'Z Yu', 'M Monperrus', 'B Baudry']",,"Abstract : Context: The increasing adoption of test-driven development results in software projects with strong test suites. These suites include a large number of test cases, in which developers embed knowledge about meaningful input data and expected properties in the form of oracles. Objective: This article surveys various works that aim at exploiting this knowledge in order to enhance these manually written tests with respect to an engineering goal (e.g., improve coverage of changes or increase the accuracy of fault localization). While these works rely on various techniques and address various goals, we believe they form an emerging and coherent field of research, and which we call 'test amplification'. Method: We devised a first set of papers based on our knowledge of the literature (we have been working in software testing for years). Then, we systematically followed the citation graph. Results: This survey is the first that draws a comprehensive picture of the different engineering goals proposed in the literature for test amplification. In particular, we note that the goal of test amplification goes far beyond maximizing coverage only. Conclusion: We believe that this survey will help researchers and practitioners entering this new field to understand more quickly and more deeply the intuitions, concepts and techniques used for test amplification."
The ratio of equivalent mutants: A key to analyzing mutation equivalence,"['I Marsit', 'A Ayad', 'D Kim', 'M Latif', 'JM Loh']",,"Mutation testing is the art of generating syntactic versions (called mutants) of a base program, and is widely used in software testing, most notably the assessment of test suites. Mutants are useful only to the extent that they are semantically distinct from the base program, but some may well be semantically equivalent to the base program, despite being syntactically distinct. Much research has been devoted to identifying, and weeding out, equivalent mutants, but determining whether two programs are semantically equivalent is a non-trivial, tedious, error-prone task. Yet in practice it is not necessary to identify equivalent mutants individually; for most intents and purposes, it suffices to estimate their number. In this paper, we are interested to estimate, for a given number of mutants generated from a program, the ratio of those that are equivalent to the base program; we refer to this as the Ratio of Equivalent Mutants (REM, for short). We argue, on the basis of analytical grounds, that the REM of a program may be estimated from a static analysis of the program, and that it can be used to analyze many mutation related properties of a program. The purpose/ aspiration of this paper is to draw attention to this potentially cost-effective approach to a longstanding stubborn problem."
The risks of coverage-directed test case generation,"['G Gay', 'M Staats', 'M Whalen']",,"A number of structural coverage criteria have been proposed to measure the adequacy of testing efforts. In the avionics and other critical systems domains, test suites satisfying structural coverage criteria are mandated by standards. With the advent of powerful automated test generation tools, it is tempting to simply generate test inputs to satisfy these structural coverage criteria. However, while techniques to produce coverage-providing tests are well established, the effectiveness of such approaches in terms of fault detection ability has not been adequately studied. In this work, we evaluate the effectiveness of test suites generated to satisfy four coverage criteria through counterexample-based test generation and a random generation approach-where tests are randomly generated until coverage is achieved-contrasted against purely random test suites of equal size. Our results yield three key conclusions. First, coverage criteria satisfaction alone can be a poor indication of fault finding effectiveness, with inconsistent results between the seven case examples (and random test suites of equal size often providing similar-or even higher-levels of fault finding). Second, the use of structural coverage as a supplement-rather than a target-for test generation can have a positive impact, with random test suites reduced to a coverage-providing subset detecting up to 13.5 percent more faults than test suites generated specifically to achieve coverage. Finally, Observable MC/DC, a criterion designed to account for program structure and the selection of the test oracle, can-in part-address the failings of traditional structural coverage criteria, allowing for the generation of test suites achieving higher levels of fault detection than random test suites of equal size. These observations point to risks inherent in the increase in test automation in critical systems, and the need for more research in how coverage criteria, test generation approaches, the test oracle used, and system structure jointly influence test effectiveness."
The significance of positive verification in unit test assessment,"['K Buffardi', 'P Valdivia']",,"This study investigates whether computer science students' unit tests can positively verify acceptable implementations. The first phase uses between-subject comparisons to reveal students' tendencies to write tests that yield inaccurate outcomes by either failing acceptable solutions or by passing implementations containing bugs. The second phase uses a novel all-function-pairs technique to compare a student's test performance, independently across multiple functions. The study reveals that students struggle with positive verification and doing so is associated with producing implementations with more bugs. Additionally, students with poor positive verification produce similar number of bugs as those with poor bug identification."
There is limited correlation between coverage and robustness for deep neural networks,"['Y Dong', 'P Zhang', 'J Wang', 'S Liu', 'J Sun', 'J Hao']",,"Deep neural networks (DNN) are increasingly applied in safety-critical systems, e.g., for face recognition, autonomous car control and malware detection. It is also shown that DNNs are subject to attacks such as adversarial perturbation and thus must be properly tested. Many coverage criteria for DNN since have been proposed, inspired by the success of code coverage criteria for software programs. The expectation is that if a DNN is a well tested (and retrained) according to such coverage criteria, it is more likely to be robust. In this work, we conduct an empirical study to evaluate the relationship between coverage, robustness and attack/defense metrics for DNN. Our study is the largest to date and systematically done based on 100 DNN models and 25 metrics. One of our findings is that there is limited correlation between coverage and robustness, i.e., improving coverage does not help improve the robustness. Our dataset and implementation have been made available to serve as a benchmark for future studies on testing DNN."
Thread scheduling sequence generation based on all synchronization pair coverage criteria,"['JX Guo', 'Z Li', 'CF Shi', 'RL Zhao']",,"Testing multi-thread programs becomes extremely difficult because thread interleavings are uncertain, which may cause a program getting different results in each execution. Thus, Thread Scheduling Sequence (TSS) is a crucial factor in multi-thread program testing. A good TSS can obtain better testing efficiency and save the testing cost especially with the increase of thread numbers. Focusing on the above problem, in this paper, we discuss a kind of approach that can efficiently generate TSS based on the concurrent coverage criteria. First, we give a definition of Synchronization Pair (SP) as well as all Synchronization Pairs Coverage (ASPC) criterion. Then, we introduce the Synchronization Pair Thread Graph (SPTG) to describe the relationships between SPs and threads. Moreover, this paper presents a TSS generation method based on the ASPC according to SPTG. Finally, TSSs automatic generation experiments are conducted on six multi-thread programs in Java Library with the help of Java Path Finder (JPF) tool. The experimental results illustrate that our method not only generates TSSs to cover all SPs but also requires less state number, transition number as well as TSS number when satisfying ASPC, compared with other three widely used TSS generation methods. As a result, it is clear that the efficiency of TSS generation is obviously improved."
"To call, or not to call: Contrasting direct and indirect branch coverage in test generation",['G Gay'],,"While adequacy criteria offer an end-point for testing, they do not mandate how targets are covered. Branch Coverage may be attained through direct calls to methods, or through indirect calls between methods. Automated generation is biased towards the rapid gains offered by indirect coverage. Therefore, even with the same end-goal, humans and automation produce very different tests. Direct coverage may yield tests that are more understandable, and that detect faults missed by traditional approaches. However, the added burden for the generation framework may result in lower coverage and faults that emerge through method interactions may be missed. To compare the two approaches, we have generated test suites for both, judging efficacy against real faults. We have found that requiring direct coverage results in lower achieved coverage and likelihood of fault detection. However, both forms of Branch Coverage cover code and detect faults that the other does not. By isolating methods, Direct Branch Coverage is less constrained in the choice of input. However, traditional Branch Coverage is able to leverage method interactions to discover faults. Ultimately, both are situationally applicable within the context of a broader testing strategy."
Towards a framework for generating tests to satisfy complex code coverage in java pathfinder,['M Staats'],,"We present work on a prototype tool based on the JavaPathfinder (JPF) model checker for automatically generating tests satisfying the MC/DC code coverage criterion. Using the Eclipse IDE, developers and testers can quickly instrument Java source code with JPF annotations covering all MC/DC coverage obligations, and JPF can then be used to automatically generate tests that satisfy these obligations. The prototype extension to JPF enables various tasks useful in automatic test generation to be performed, such as test suite reduction and execution of generated tests."
Towards minimal mutation analysis: Using the approximated dominator set of mutants,['A Márki'],,"In mutation testing, variants (i.e., mutants) of the software under test are created. Themutants are then used to design tests that can detect the difference between the mutantsand the original software under test. Empirical studies have shown that test suites thatare effective in detecting mutants are also effective in detecting real faults. Mutationanalysis is therefore often used to benchmark effectiveness of other testing techniques.The main drawback of mutation testing is that it is computationally expensive becauseof the large number of mutants to analyze. It is well known that many of these mutantsare redundant and recent studies have shown that the redundancy among the mutantscan be up to 99%. However, identifying which mutants that are redundant is challengingsince this depends on the software under test as well as the specific mutations. This work aims to combine techniques from areas, such as static analysis and machinelearning, in a process for cost-effective mutation analysis. Such techniques are expectedto provide partial solutions to the problem of avoiding creation of the redundant mutants.The outcome of this research is two-fold: (i) an evaluation of techniques that canbe used to minimize the set of non-redundant mutants that needs to be created, and (ii)a process for mutation analysis combining such minimization techniques. A frameworkwill also be developed to evaluate the minimization techniques and the entire process."
Um arcabouço para a geração automatizada de testes funcionais a partir de cenários BDD,"['NN Marques', 'RA Fernandes']",x (not English),
Uma contribuição para o teste baseado em defeitos de software orientado a aspectos,['FC Ferrari'],x (not English),
Uma investigação sobre o uso de critérios de teste no desenvolvimento baseado em testes para o ensino de programação,['BHP Camara'],x (not English),
Uncertainty-wise testing of cyber-physical systems,"['S Ali', 'H Lu', 'S Wang', 'T Yue', 'M Zhang']",,"As compared with classical software/system testing, uncertainty-wise testing explicitly addresses known uncertainty about the behavior of a System Under Test (SUT), its operating environment, and interactions between the SUT and its operational environment, across all testing phases, including test design, test generation, test optimization, and test execution, with the aim to mainly achieve the following two goals. First, uncertainty-wise testing aims to ensure that the SUT deals with known uncertainty adequately. Second, uncertainty-wise testing should be also capable of learning new (previously unknown) uncertainties such that the SUT's implementation can be improved to guard against newly learned uncertainties during its operation. The necessity to integrate uncertainty in testing is becoming imperative because of the emergence of new types of intelligent and communicating software-based systems such as Cyber-Physical Systems (CPSs). Intrinsically, such systems are exposed to uncertainty because of their interactions with highly indeterminate physical environments. In this chapter, we provide our understanding and experience of uncertainty-wise testing from the aspects of uncertainty-wise model-based testing, uncertainty-wise modeling and evolution of test ready models, and uncertainty-wise multiobjective test optimization, in the context of testing CPSs under uncertainty. Furthermore, we present our vision about this new testing paradigm and its plausible future research directions."
Unit test generation using machine learning,['L Saes'],,"Test suite generators could help software engineers to ensure software quality by detecting software faults. These generators can be applied to software projects that do not have an initial test suite, a test suite can be generated which is maintained and optimized by the developers. Testing helps to check if a program works and, also if it continues to work after changes. This helps to prevent software from failing and aids developers in applying changes and minimizing the possibility to introduce errors in other (critical) parts of the software. State-of-the-art test generators are still only able to capture a small portion of potential software faults. The Search-Based Software Testing 2017 workshop compared four unit test generation tools. These generators were only capable of achieving an average mutation coverage below 51%, which is lower than the score of the initial unit test suite written by software engineers. We propose a test suite generator driven by neural networks, which has the potential to detect mutants that could only be detected by manually written unit tests. In this research, multiple networks, trained on open-source projects, are evaluated on their ability to generate test suites. The dataset contains the unit tests and the code it tests. The unit test method names are used to link unit tests to methods under test. With our linking mechanism, we were able to link 27.41% (36,301 out of 132,449) tests. Our machine learning model could generate parsable code in 86.69% (241/278) of the time. This high number of parsable code indicates that the neural network learned patterns between code and tests, which indicates that neural networks are applicable for test generation."
Unit testing the User Interface: Automatic tests of web UI's in React,['P Christersson Frend'],,"The objective of this study was to investigate tools and techniques for automated user interface tests of components written in the Javascript libraries React and Redux for the web application Console. Console is a social network platform which provides interconnection services that bypass the public internet. The study's aim was to suggest a recommended testing strategy to help prevent regressions and improve developer workflows. The study was performed by comparing two test types: unit and end-to-end, and how they can be incorporated into the front-end testing process. Each test type was evaluated based on its strengths and weaknesses by adding test coverage to a section of Console. Requirements were developed to ensure components could be tested in isolation, that test failures generated informative messages, and that component interactions could accurately be tested. The study found that using a test technique called shallow rendering, most component tests could be moved from the end-to-end level down to the unit level. This achieved a much faster test suite which allowed for continuous execution of the unit tests and provided a tighter feedback loop for developers. Shallow rendering failed to provide enough functionality when it came to testing component interactions and events, but limited interactions could still be tested with a headless browser. Integration tests and end-to-end tests were still seen as useful required test tools, but were not deemed optimal for validating data flow through UI components. These tests were seen as beneficial more for ensuring overall system stability rather than improving developer workflows."
Unit testing tool competition—round four,"['U Rueda', 'R Just', 'JP Galeotti']",,"This paper describes the methodology and results of the 4th edition of the Java Unit Testing Tool Competition. This year's competition features a number of infrastructure improvements, new test effectiveness metrics, and the evaluation of the test generation tools for multiple time budgets. Overall, the competition evaluated four automated test generation tools. This paper details the methodology and contains the full results of the competition."
Using Mutation for the Assessment and optimization of tests and properties,['JS Bradbury'],,"We are interested in exploring the complementary relationship and tradeoffs between testing and property-based analysis with respect to bug detection. In this paper we present an empirical approach to the assessment of testing and property-based analysis tools using metrics to measure the quantity and efficiency of each technique at finding bugs. We have implemented our approach in an assessment component that has been constructed to allow for symmetrical comparison and evaluation of tests versus properties. In addition to assessing test cases and properties we are also interested in using each to optimize the other as well as to develop hybrid quality assurance approaches. We hypothesize that the synergies of using testing and property-based analysis in combination will allow for optimizations in test suites and property sets that are not possible by using both approaches in isolation."
Using machine learning to refine black-box test specifications and test suites,"['LC Briand', 'Y Labiche', 'Z Bawar']",,"In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box testing, we propose a methodology based on machine learning that has shown promising results on a case study."
Using machine learning to refine category-partition test specifications and test suites,"['LC Briand', 'Y Labiche', 'Z Bawar', 'NT Spido']",,"In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box, Category-Partition testing, we propose a methodology and a tool based on machine learning that has shown promising results on a case study involving students as testers."
Using mutants to help developers distinguish and debug (compiler) faults,"['J Holmes', 'A Groce']",,"Measuring the distance between two program executions is a fundamental problem in dynamic analysis of software and useful in many test generation and debugging algorithms. This paper proposes a metric for measuring distance between executions and specializes it to an important application: determining similarity of failing test cases for the purpose of automated fault identification and localization in debugging based on automatically generated compiler tests. The metric is based on a causal concept of distance where executions are similar to the degree that changes in the program itself, introduced by mutation, cause similar changes in the correctness of the executions. Specifically, if two failing test cases for a compiler can be made to pass by applying the same mutant, those two tests are more likely to be due to the same fault. We evaluate our metric using more than 50 faults and 2,800 test cases for two widely used real-world compilers and demonstrate improvements over state-of-the-art methods for fault identification and localization. A simple operator selection approach to reducing the number of mutants can reduce the cost of our approach by 70%, while producing a gain in fault identification accuracy. We additionally show that our approach, although devised for compilers, is applicable as a conservative fault localization algorithm for other types of programs and can help triage certain types of crashes found in fuzzing non-compiler programs more effectively than a state-of-the-art technique."
Using predictive models to evaluate the quality of a test suite at class and method level.,"['KL Silva', 'E Cota']",,"Testing is an indispensable part of the software development process and is a continuous process during the development life cycle. In this context, examining the behavior of software systems to reveal potential problems is a crucial task. To this end, the test suites usually are utilized to examine the software quality. However, test suite quality control is hard for the tester, especially in an evolving system. Such control is needed to assure and improve the test suite's quality and the application as a consequence. Currently, test coverage criteria are used as a mechanism to assist the tester in analyzing the test suite (e.g., find the weaknesses, and add a new test case or test inputs). However, more strong coverage criteria (potentially showing less glaring weaknesses) are challenging to assess. In this work, we propose a different approach to support the developer in evaluating the test suite quality based on more powerful test coverage criteria. We will follow the Knowledge Discovery in Database process using machine learning algorithms to estimate the prime path coverage at the method and class level. For this purpose, we will create two large datasets consisting of source code metrics and test case metrics from 12 open-source Java projects, and these datasets will be used in the training process to build the predictive models. Using the built models, we expected to predict the prime path coverage at the method and class level with a reliable prediction performance."
Utilizing artificial intelligence in software testing,['M Mäkelä'],,"Artificial Intelligence has become more and more important part of computer science and IT business. Anyhow, it has not been used in the software testing widely. At the same time the demand for using the test automation and testing more efficiently has increased. Using the AI and machine learning could be one approach to reduce the manual work in the software testing and also in the traditional test automation which still requires tremendous amunt of manual work. However, Artificial Intelligence and machine learning technologies still are pretty unknown for the major part of the software testing community. The primary objective of the study was to form recommendations how the artificial intelligence could be utilized in the software testing. The secondary objective was to present the methods as part of standardized test process. The research was conducted by creating the research keywords based on the testing standards and best practices. The different machine learning solutions related to software testing and its sub categories were searched both from the academic publications and online materials of the test tool providers, conference recordings and trainings provided by the AI testing specialists. The actual search results are collected and categorized in four sections. In the first section as a theoretical background the AI and machine learning high level approaches have been presented and also challenges on testing the AI and with an AI. In the second section the AI Testing model by AI for Software Testing Association is presented and reflected to a Paul Gerrard´s New Model for Testing. In the third section the fundamental testing process has been used as a frame in which the different machine learning approaches from the other researches have been collected. In the last section the different testing tools are presented and how the machine learning could be used to improve the efficiency using them. The section also presents some existing commercial and open source tools that are having macine learning features in their implementations."
A Dissection of the Test-Driven Development Process: Does It Really Matter to Test-First or to Test-Last?,"Davide, Hakan, Burak, Markku, Natalia",,"Background: Test-driven development (TDD) is a technique that repeats short coding cycles interleaved with testing. The developer first writes a unit test for the desired functionality, followed by the necessary production code, and refactors the code. Many empirical studies neglect unique process characteristics related to TDD iterative nature. Aim: We formulate four process characteristic: sequencing, granularity, uniformity, and refactoring effort. We investigate how these characteristics impact quality and productivity in TDD and related variations. Method: We analyzed 82 data points collected from 39 professionals, each capturing the process used while performing a specific development task. We built regression models to assess the impact of process characteristics on quality and productivity. Quality was measured by functional correctness. Result: Quality and productivity improvements were primarily positively associated with the granularity and uniformity. Sequencing, the order in which test and production code are written, had no important influence. Refactoring effort was negatively associated with both outcomes. We explain the unexpected negative correlation with quality by possible prevalence of mixed refactoring. Conclusion: The claimed benefits of TDD may not be due to its distinctive test-first dynamic, but rather due to the fact that TDD-like processes encourage fine-grained, steady steps that improve focus and flow."
A Little Language for Testing,"Alex, Jervis",,"The difficulty of writing test harnesses is a major obstacle to the adoption of automated testing and model checking. Languages designed for harness definition are usually tied to a particular tool and unfamiliar to programmers; moreover, such languages can limit expressiveness. Writing a harness directly in the language of the software under test (SUT) makes it hard to change testing algorithms, offers no support for the common testing idioms, and tends to produce repetitive, hard-to-read code. This makes harness generation a natural fit for the use of an unusual kind of domain-specific language (DSL). This paper defines a template scripting testing language, TSTL, and shows how it can be used to produce succinct, readable definitions of state spaces. The concepts underlying TSTL are demonstrated in Python but are not tied to it."
A Practitioner’s Guide to Software Test Design,"Copeland, L.",x (Book),
A Study and Review on the Development of Mutation Testing Tools for Java and Aspect-J Programs,"Pradeep, , Om Prakash, Arun, , ",,"Mutation analysis in software testing is observed as the most effective way to validate the software under inspection. In last decade, number of researchers developed various methods and tools to apply mutation testing on Aspect Oriented Programs. In this paper, authors analyzed numerous mutation testing based tools available to test the Java and AspectJ programs. All effective and popular Aspect-J testing tools have been considered and analyzed in this paper, based on essential requirements in this context, considered to be fulfilled by testing tools decided by testing professional and researchers for such tools. This paper analyzed the work progress in the field of mutation testing techniques and tools specific to Java and AspectJ. This work considered essential parameters on which the analysis of analyzed tools is carried out. In case of addition parameters considered for evaluation, some of the resultant metrics may vary slightly under modification in basic requirements. Based on the numeric value estimated, it is finally suggested the merits of a mutation tool under different circumstances. This is the extension of the work carried by us in previous review for aspect based mutation testing techniques."
A Survey of Coverage-Based Testing Tools,"Q., J. J., D. M.",,"Test coverage is sometimes used to measure how thoroughly software is tested and developers and vendors sometimes use it to indicate their confidence in the readiness of their software. This survey studies and compares 17 coverage-based testing tools primarily focusing on, but not restricted to, coverage measurement. We also survey features such as program prioritization for testing, assistance in debugging, automatic generation of test cases and customization of test reports. Such features make tools more useful and practical, especially for large-scale, commercial software applications. Our initial motivations were both to understand the available test coverage tools and to compare them to a tool that we have developed, called eXVantage (a tool suite that includes code coverage testing, debugging, performance profiling and reporting). Our study shows that each tool has some unique features tailored to its application domains. The readers may use this study to help pick the right coverage testing tools for their needs and environment. This paper is also valuable to those who are new to the practice and the art of software coverage testing, as well as those who want to understand the gap between industry and academia."
"A Theoretical and Empirical Study of Search-Based Testing: Local, Global, and Hybrid Search","M., P.",,"Search-based optimization techniques have been applied to structural software test data generation since 1992, with a recent upsurge in interest and activity within this area. However, despite the large number of recent studies on the applicability of different search-based optimization approaches, there has been very little theoretical analysis of the types of testing problem for which these techniques are well suited. There are also few empirical studies that present results for larger programs. This paper presents a theoretical exploration of the most widely studied approach, the global search technique embodied by Genetic Algorithms. It also presents results from a large empirical study that compares the behavior of both global and local search-based optimization on real-world programs. The results of this study reveal that cases exist of test data generation problem that suit each algorithm, thereby suggesting that a hybrid global-local search (a Memetic Algorithm) may be appropriate. The paper presents a Memetic Algorithm along with further empirical results studying its performance."
A manager’s guide to evaluating test suites,"Marick, B. and Bach, J. and Kaner, C.Cem",x (Web),
A practical tutorial on modified condition/decision coverage,"Hayhurst, K. and Veerhusen, D. and Rierson, L.",x (Book),
A survey on model-based testing approaches,"Arilo C., Rajesh, Marlon, Guilherme H.",,"This paper describes a systematic review performed on model-based testing (MBT) approaches. A selection criterion was used to narrow the initially identified four hundred and six papers to focus on seventy-eight papers. Detailed analysis of these papers shows where MBT approaches have been applied, the characteristics, and the limitations. The comparison criteria includes representation models, support tools, test coverage criteria, the level of automation, intermediate models, and the complexity. This paper defines and explains the review methodology and presents some results."
A systematic review of state-based test tools,"Muhammad, Yvan",,"Model-based testing (MBT) is about testing a software system using a model of its behaviour. To benefit fully from MBT, automation support is required. The goal of this systematic review is determining the current state of the art of prominent MBT tool support where we focus on tools that rely on state-based models. We automatically searched different source of information including digital libraries and mailing lists dedicated to the topic. Precisely defined criteria are used to compare selected tools and comprise support for test adequacy and coverage criteria, level of automation for various testing activities and support for the construction of test scaffolding. Simple adequacy criteria are supported but not advanced ones; data(-flow) criteria are seldom supported; support for creating test scaffolding varies a great deal. The results of this review should be of interest to a wide range of stakeholders: software companies interested in selecting the most appropriate MBT tool for their needs; organizations willing to invest into creating MBT tool support; researchers interested in setting research directions."
A taxonomy of model-based testing approaches,"Mark, Alexander, Bruno",,"Model-based testing (MBT) relies on models of a system under test and/or its environment to derive test cases for the system. This paper discusses the process of MBT and defines a taxonomy that covers the key aspects of MBT approaches. It is intended to help with understanding the characteristics, similarities and differences of those approaches, and with classifying the approach used in a particular MBT tool. To illustrate the taxonomy, a description of how three different examples of MBT tools fit into the taxonomy is provided."
A theoretical & empirical znalysis of evolutionary testing and hill climbing for structural test data generation,"Mark, Phil",,"Evolutionary testing has been widely studied as a technique for automating the process of test case generation. However, to date, there has been no theoretical examination of when and why it works. Furthermore, the empirical evidence for the effectiveness of evolutionary testing consists largely of small scale laboratory studies. This paper presents a first theoretical analysis of the scenarios in which evolutionary algorithms are suitable for structural test case generation. The theory is backed up by an empirical study that considers real world programs, the search spaces of which are several orders of magnitude larger than those previously considered."
ADTEST: a test data generation suite for Ada software systems,"M.J., V.",,"Presents the design of the software system ADTEST (ADa TESTing), for generating test data for programs developed in Ada83. The key feature of this system is that the problem of test data generation is treated entirely as a numerical optimization problem and, as a consequence, this method does not suffer from the difficulties commonly found in symbolic execution systems, such as those associated with input variable-dependent loops, array references and module calls. Instead, program instrumentation is used to solve a set of path constraints without explicitly knowing their form. The system supports not only the generation of integer and real data types, but also non-numerical discrete types such as characters and enumerated types. The system has been tested on large Ada programs (60,000 lines of code) and found to reduce the effort required to test programs as well as providing an increase in test coverage."
AUSTIN: A Tool for Search Based Software Testing for the C Language and Its Evaluation on Deployed Automotive Systems,"Kiran, Mark, Hamilton",,"Despite the large number of publications on Search--Based Software Testing (SBST), there remain few publicly available tools. This paper introduces AUSTIN, a publicly available SBST tool for the C language. The paper validates the tool with an empirical study of its effectiveness and efficiency in achieving branch coverage compared to random testing and the Evolutionary Testing Framework (ETF), which is used in-house by Daimler and others for Evolutionary Testing. The programs used in the study consist of eight non--trivial, real-world C functions drawn from three embedded automotive software modules. For the majority of the functions, AUSTIN is at least as effective (in terms of achieved branch coverage) as the ETF, and is considerably more efficient."
Adaptive Random Testing: The ART of test case diversity,"Tsong Yueh, Fei-Ching, Robert G., T.H.",,"Random testing is not only a useful testing technique in itself, but also plays a core role in many other testing methods. Hence, any significant improvement to random testing has an impact throughout the software testing community. Recently, Adaptive Random Testing (ART) was proposed as an effective alternative to random testing. This paper presents a synthesis of the most important research results related to ART. In the course of our research and through further reflection, we have realised how the techniques and concepts of ART can be applied in a much broader context, which we present here. We believe such ideas can be applied in a variety of areas of software testing, and even beyond software testing. Amongst these ideas, we particularly note the fundamental role of diversity in test case selection strategies. We hope this paper serves to provoke further discussions and investigations of these ideas."
Agile High Assurance: Testing re-imagined,"Binder, R.V.",x (Presentation),
An Empirical Evaluation of Mutation Testing for Improving the Test Quality of Safety-Critical Software,"Richard, Ibrahim",,"Testing provides a primary means for assuring software in safety-critical systems. To demonstrate, particularly to a certification authority, that sufficient testing has been performed, it is necessary to achieve the test coverage levels recommended or mandated by safety standards and industry guidelines. Mutation testing provides an alternative or complementary method of measuring test sufficiency, but has not been widely adopted in the safety-critical industry. In this study, we provide an empirical evaluation of the application of mutation testing to airborne software systems which have already satisfied the coverage requirements for certification. Specifically, we apply mutation testing to safety-critical software developed using high-integrity subsets of C and Ada, identify the most effective mutant types, and analyze the root causes of failures in test cases. Our findings show how mutation testing could be effective where traditional structural coverage analysis and manual peer review have failed. They also show that several testing issues have origins beyond the test activity, and this suggests improvements to the requirements definition and coding process. Our study also examines the relationship between program characteristics and mutation survival and considers how program size can provide a means for targeting test areas most likely to have dormant faults. Industry feedback is also provided, particularly on how mutation testing can be integrated into a typical verification life cycle of airborne software."
An Empirical Study of JUnit Test-Suite Reduction,"Lingming, Darko, Lu, Sarfraz",,"As test suites grow larger during software evolution, regression testing becomes expensive. To reduce the cost of regression testing, test-suite reduction aims to select a minimal subset of the original test suite that can still satisfy all the test requirements. While traditional test-suite reduction techniques were intensively studied on C programs with specially generated test suites, there are limited studies for test-suite reduction on programs with real-world test suites. In this paper, we investigate test-suite reduction techniques on Java programs with real-world JUnit test suites. We implemented four representative test-suite reduction techniques for JUnit test suites. We performed an empirical study on 19 versions of four real-world Java programs, ranging from 1.89 KLoC to 80.44 KLoC. Our study investigates both the benefits and the costs of test-suite reduction. The results show that the four traditional test-suite reduction techniques can effectively reduce these JUnit test suites without substantially reducing their fault-detection capability. Based on the results, we provide a guideline for achieving cost-effective JUnit test suite reduction."
An Environment for Training Computer Science Students on Software Testing,"J., K.",,"Software testing is essential to ensure software quality. On most software projects testing activities consume at least 30 percent of the project effort. On safety critical applications, software testing can consume between 50 to 80 percent of project effort. There is a vast amount of information available on software testing techniques and tools and some universities offer software testing courses at the advanced undergraduate and graduate level. Software testing must also be stressed in beginning courses and even in the high schools when students are first learning to program. It is also important in these early years to instill a respect for software testing and some interest in possible testing careers. This paper describes a project to develop a learning and training environment that enables students to develop the knowledge and skills to perform requirement based testing. The target audience for the environment are beginning programming students at either the high school or university level. The software training environment consists of Web-based instructional materials as well as a testing simulator which enables students to actually test software programs. This paper describes the educational objectives of the test training environment, its implementation and results from utilizing the environment with beginning programming students"
An Information Retrieval Approach for Regression Test Prioritization Based on Program Changes,"Ripon K., Lingming, Sarfraz, Dewayne E.",,"Regression testing is widely used in practice for validating program changes. However, running large regression suites can be costly. Researchers have developed several techniques for prioritizing tests such that the higher-priority tests have a higher likelihood of finding bugs. A vast majority of these techniques are based on dynamic analysis, which can be precise but can also have significant overhead (e.g., for program instrumentation and test-coverage collection). We introduce a new approach, REPiR, to address the problem of regression test prioritization by reducing it to a standard Information Retrieval problem such that the differences between two program versions form the query and the tests constitute the document collection. REPiR does not require any dynamic profiling or static program analysis. As an enabling technology we leverage the open-source IR toolkit Indri. An empirical evaluation using eight open-source Java projects shows that REPiR is computationally efficient and performs better than existing (dynamic or static) techniques for the majority of subject systems."
An empirical investigation on the readability of manual and generated test cases,"Giovanni, Simone, Harald C., Rocco",,"Software testing is one of the most crucial tasks in the typical development process. Developers are usually required to write unit test cases for the code they implement. Since this is a time-consuming task, in last years many approaches and tools for automatic test case generation - such as EvoSuite - have been introduced. Nevertheless, developers have to maintain and evolve tests to sustain the changes in the source code; therefore, having readable test cases is important to ease such a process. However, it is still not clear whether developers make an effort in writing readable unit tests. Therefore, in this paper, we conduct an explorative study comparing the readability of manually written test cases with the classes they test. Moreover, we deepen such analysis looking at the readability of automatically generated test cases. Our results suggest that developers tend to neglect the readability of test cases and that automatically generated test cases are generally even less readable than manually written ones."
An orchestrated survey of methodologies for automated software test case generation,"Saswat, Edmund K., Tsong Yueh, John, Myra B., Wolfgang, Mark, Mary Jean, Phil, Antonia, J., Hong",,"Test case generation is among the most labour-intensive tasks in software testing. It also has a strong impact on the effectiveness and efficiency of software testing. For these reasons, it has been one of the most active research topics in software testing for several decades, resulting in many different approaches and tools. This paper presents an orchestrated survey of the most prominent techniques for automatic generation of software test cases, reviewed in self-standing sections. The techniques presented include: (a) structural testing using symbolic execution, (b) model-based testing, (c) combinatorial testing, (d) random testing and its variant of adaptive random testing, and (e) search-based testing. Each section is contributed by world-renowned active researchers on the technique, and briefly covers the basic ideas underlying the method, the current state of the art, a discussion of the open research problems, and a perspective of the future development of the approach. As a whole, the paper aims at giving an introductory, up-to-date and (relatively) short overview of research in automatic test case generation, while ensuring a comprehensive and authoritative treatment."
Analysis of Mutation Operators for the Python Language,"Anna, Konrad",,"A mutation introduced into a source code of a dynamically typed program can generate an incompetent mutant. Such a mutant manifests a type-related error that cannot be detected before the mutant execution. To avoid this problem, a program mutation can be provided at run-time, or incompetent mutants should be automatically detected and eliminated. We showed that the latter solution can effectively be applied providing selected mutation operators. This paper discusses mutation operators to be used for mutation testing of Python programs. Standard and object-oriented mutation operators were applied to the Python language. Python-related operators dealing with decorators and collection slices were proposed. The operators were implemented in MutPy, the tool for mutation testing of Python programs, and experimentally evaluated."
Analyzing regression test selection techniques,"G., M.J.",,"Regression testing is a necessary but expensive maintenance activity aimed at showing that code has not been adversely affected by changes. Regression test selection techniques reuse tests from an existing test suite to test a modified program. Many regression test selection techniques have been proposed, however, it is difficult to compare and evaluate these techniques because they have different goals. This paper outlines the issues relevant to regression test selection techniques, and uses these issues as the basis for a framework within which to evaluate the techniques. The paper illustrates the application of the framework by using it to evaluate existing regression test selection techniques. The evaluation reveals the strengths and weaknesses of existing techniques, and highlights some problems that future work in this area should address."
App testing now consumes a quarter of IT budget,"Vizard, M.",x (Web),
Assessing the Influence of Multiple Test Case Selection on Mutation Experiments,"Marcio E., Jeff",,"Mutation testing is widely used in experiments. Some papers experiment with mutation directly, while others use it to introduce faults to measure the effectiveness of tests created by other methods. There is some random variation in the mutation score depending on the specific test values used. When generating tests to use in experiments, a common, although not universal practice, is to generate multiple sets of tests to satisfy the same criterion or according to the same procedure, and then to compute their average performance. Averaging over multiple test sets is thought to reduce the variation in the mutation score. This practice is extremely expensive when tests are generated by hand (as is common) and as the number of programs increase (a current positive trend in software engineering experimentation). The research reported in this short paper asks a simple and direct question: do we need to generate multiple sets of test cases? That is, how do different test sets influence the cost and effectiveness results? In a controlled experiment, we generated 10 different test cases to be adequate for the Statement Deletion (SSDL) mutation operator for 39 small programs and functions, and then evaluated how they differ in terms of cost and effectiveness. We found that averaging over multiple programs was effective in reducing the variance in the mutation scores introduced by specific tests."
Assessing the test suite of a large scale system based on code coverage and derived metrics,"L. Vidács, F. Horváth, D. Tengeri and Beszédes, Á.",x (not found),
Automatic Selection of Test Cases for Regression Testing,"Cláudio, Flávia, Alexandre, Eliot",,"Regression testing is a safety measure to attest that changes made on a system preserve prior accepted behavior. Identifying which test cases must compose a regression test suite in a certain development stage is tricky, particularly when one only has test cases and change requests described in natural language, and the execution of the test suite will be performed manually. That is the case of our industrial partner. We propose a selection of regression test cases based on information retrieval and implement as a web-service. In performed experiments, we show that we can improve the creation of regression test suites of our industrial partner by providing more effective test cases based on keywords analysis in an automatic way."
Automatic Test Case Generation and Optimization Based on Mutation Testing,"Yunqi, Ya, Haiyang, Nimako, Yong",,"Based on defect implantation mutation testing technique not only serves as a standard for evaluating test cases but also guides how to generate high-quality test case sets. In order to reduce the number of mutants, we propose a mutation operator selection strategy according to Selective Mutation. From 19 mutation operators of Mujava we select 5 mutation operators to obtain a subset. Test cases using this subset are able to achieve an average variation score of more than 95% on the variants of the complete set. Then we propose a test case generation method combining mutation testing with a genetic algorithm. The crossover, insertion, change, and deletion operators of the test case set are redefined, and the test cases are optimized. Finally compared with some algorithms and tools we obtain a set of test cases with higher coverage and higher mutation score."
Automatic Test-case Generation from Formal Models of Software,"Rayadurgam, S.",x (Book),
Automatic mutation test input data generation via ant colony,"Kamel, Salah, Giuliano",,"Fault-based testing is often advocated to overcome limitations ofother testing approaches; however it is also recognized as beingexpensive. On the other hand, evolutionary algorithms have beenproved suitable for reducing the cost of data generation in the contextof coverage based testing. In this paper, we propose a newevolutionary approach based on ant colony optimization for automatictest input data generation in the context of mutation testingto reduce the cost of such a test strategy. In our approach the antcolony optimization algorithm is enhanced by a probability densityestimation technique. We compare our proposal with otherevolutionary algorithms, e.g., Genetic Algorithm. Our preliminaryresults on JAVA testbeds show that our approach performed significantlybetter than other alternatives."
Automatic test case generation based on genetic algorithm and mutation analysis,"Hirohide, Akihisa",,"This paper proposes a method that automatically generates software test cases based on a genetic algorithm and mutation analysis. Our method combines random generation and refinement. Each test case is generated randomly in the first step, and then a set of test cases is refined by the genetic algorithm. To measure the adequacy of the test case set, we use mutation scores, which are based on the mutation analysis of software testing. Our proposed method, which is applied to a C programing language program, automatically generated test case sets with 100% branch and boundary value coverages. The generation time of one test case set was approximately 130 ms."
Automatically Finding Hidden Industrial Criteria used in Test Selection,"Cláudio, Alexandre, Eliot",,"In this paper we propose a way to find weights of a ranking function semi-automatically. From the manual choices made by (experienced) human test architects, our idea is to propose an optimization model that tries to find the necessary weights automatically. We present some experiments by encoding our optimization model in the Z3 SMT solver and using real Motorola Mobility data."
Automatically identifying focal methods under test in unit test cases,"Mohammad, Carlo, Konstantin",,"Modern iterative and incremental software development relies on continuous testing. The knowledge of test-to-code traceability links facilitates test-driven development and improves software evolution. Previous research identified traceability links between test cases and classes under test. Though this information is helpful, a finer granularity technique can provide more useful information beyond the knowledge of the class under test. In this paper, we focus on Java classes that instantiate stateful objects and propose an automated technique for precise detection of the focal methods under test in unit test cases. Focal methods represent the core of a test scenario inside a unit test case. Their main purpose is to affect an object's state that is then checked by other inspector methods whose purpose is ancillary and needs to be identified as such. Distinguishing focal from other (non-focal) methods is hard to accomplish manually. We propose an approach to detect focal methods under test automatically. An experimental assessment with real-world software shows that our approach identifies focal methods under test in more than 85% of cases, providing a ground for precise automatic recovery of test-to-code traceability links."
"Automatically performing weak mutation with the aid of symbolic execution, concolic testing and search-based testing","Mike, Nicos",,"Automating software testing activities can increase the quality and drastically decrease the cost of software development. Toward this direction, various automated test data generation tools have been developed. The majority of existing tools aim at structural testing, while a quite limited number aim at a higher level of testing thoroughness such as mutation. In this paper, an attempt toward automating the generation of mutation-based test cases by utilizing existing automated tools is proposed. This is achieved by reducing the killing mutants’ problem into a covering branches one. To this extent, this paper is motivated by the use of state of the art techniques and tools suitable for covering program branches when performing mutation. Tools and techniques such as symbolic execution, concolic execution, and evolutionary testing can be easily adopted toward automating the test input generation activity for the weak mutation testing criterion by simply utilizing a special form of the mutant schemata technique. The propositions made in this paper integrate three automated tools in order to illustrate and examine the method’s feasibility and effectiveness. The obtained results, based on a set of Java program units, indicate the applicability and effectiveness of the suggested technique. The results advocate that the proposed approach is able to guide existing automating tools in producing test cases according to the weak mutation testing criterion. Additionally, experimental results with the proposed mutation testing regime show that weak mutation is able to speedup the mutant execution time by at least 4.79 times when compared with strong mutation."
Basic mistakes in database testing,"Guz, S.",x (Web),
Beyond testing configurable systems: applying variational execution to automatic program repair and higher order mutation testing,"Chu-Pan, Jens, Christian",,"Generate-and-validate automatic program repair and higher order mutation testing often use search-based techniques to find optimal or good enough solutions in huge search spaces. As search spaces continue to grow, finding solutions that require interactions of multiple changes can become challenging. To tackle the huge search space, we propose to use variational execution. Variational execution has been shown to be effective in exhaustively exploring variations and identifying interactions in a huge but often finite configuration space. The key idea is to encode alternatives in the search space as variations and use variational execution as a black-box technique to generate useful insights so that existing search heuristics can be informed. We show that this idea is promising and identify criteria for problems in which variational execution is a promising tool, which may be useful to identify further applications."
Calibrated Mutation Testing,"Jaechang, David, Andreas",,"During mutation testing, artificial defects are inserted into a program, in order to measure the quality of a test suite and to provide means for improvement. These defects are generated using predefined mutation operators-inspired by faults that programmers tend to make. As the type of faults varies between different programmers and projects, mutation testing might be improved by learning from past defects-Does a sample of mutations similar to past defects help to develop better tests than a randomly chosen sample of mutations? In this paper, we present the first approach that uses software repository mining techniques to calibrate mutation testing to the defect history of a project. Furthermore, we provide an implementation and evaluation of calibrated mutation testing for the Jaxen project. However, first results indicate that calibrated mutation testing cannot outperform random selection strategies."
Clover Java and groovy code coverage tool homepage,Atlassian,x (Web),
Code‐aware combinatorial interaction testing,"Bestoun S., Angelo, Kamal Z., Cemal, Miroslav, Marek",,"Combinatorial interaction testing (CIT) is a useful testing technique to address the interaction of input parameters in software systems. CIT has been used as a systematic technique to sample the enormous test possibilities. Most of the research activities focused on the generation of CIT test suites as a computationally complex problem. Less effort has been paid for the application of CIT. To apply CIT, practitioners must identify the input parameters for the Software-under-test (SUT), feed these parameters to the CIT test generation tool, and then run those tests on the application with some pass and fail criteria for verification. Using this approach, CIT is used as a black-box testing technique without knowing the effect of the internal code. Although useful, practically, not all the parameters having the same impact on the SUT. This paper introduces a different approach to use the CIT as a gray-box testing technique by considering the internal code structure of the SUT to know the impact of each input parameter and thus use this impact in the test generation stage. The case studies results showed that this approach would help to detect new faults as compared to the equal impact parameter approach."
Combinatorial Interaction Testing for Automated Constraint Repair,"Angelo, Justyna, Marco",,"Highly-configurable software systems can be easily adapted to address user's needs. Modelling parameter configurations and their relationships can facilitate software reuse. Combinatorial Interaction Testing (CIT) methods are already often used to drive systematic testing of software system configurations. However, a model of the system's configurations not conforming with respect to its software implementation, must be repaired in order to restore conformance. In this paper we extend CIT by devising a new search-based technique able to repair a model composed of a set of constraints among the various software system's parameters. Our technique can be used to detect and fix faults both in the model and in the real software system. Experiments for five real-world systems show that our approach can repair on average 37% of conformance faults. Moreover, we also show it can infer parameter constraints in a large real-world software system, hence it can be used for automated creation of CIT models."
Combining search-based and constraint-based testing,"Jan, Gordon",,"Many modern automated test generators are based on either meta-heuristic search techniques or use constraint solvers. Both approaches have their advantages, but they also have specific drawbacks: Search-based methods get stuck in local optima and degrade when the search landscape offers no guidance; constraint-based approaches, on the other hand, can only handle certain domains efficiently. In this paper we describe a method that integrates both techniques and delivers the best of both worlds. On a high-level view, our method uses a genetic algorithm to generate tests, but the twist is that during evolution a constraint solver is used to ensure that mutated offspring efficiently explores different control flow. Experiments on 20 case study examples show that on average the combination improves branch coverage by 28% over search-based techniques and by 13% over constraint-based techniques."
Considering rigor and relevance when evaluating test driven development: A systematic review,"Hussan, Misagh, Kai",,"Context: Test driven development (TDD) has been extensively researched and compared to traditional approaches (test last development, TLD). Existing literature reviews show varying results for TDD. Objective: This study investigates how the conclusions of existing literature reviews change when taking two study quality dimension into account, namely rigor and relevance. Method: In this study a systematic literature review has been conducted and the results of the identified primary studies have been analyzed with respect to rigor and relevance scores using the assessment rubric proposed by Ivarsson and Gorschek 2011. Rigor and relevance are rated on a scale, which is explained in this paper. Four categories of studies were defined based on high/low rigor and relevance. Results: We found that studies in the four categories come to different conclusions. In particular, studies with a high rigor and relevance scores show clear results for improvement in external quality, which seem to come with a loss of productivity. At the same time high rigor and relevance studies only investigate a small set of variables. Other categories contain many studies showing no difference, hence biasing the results negatively for the overall set of primary studies. Given the classification differences to previous literature reviews could be highlighted. Conclusion: Strong indications are obtained that external quality is positively influenced, which has to be further substantiated by industry experiments and longitudinal case studies. Future studies in the high rigor and relevance category would contribute largely by focusing on a wider set of outcome variables (e.g. internal code quality). We also conclude that considering rigor and relevance in TDD evaluation is important given the differences in results between categories and in comparison to previous reviews."
Constrained Interaction Testing: A Systematic Literature Study,"Bestoun S., Kamal Z., Wasif, Miroslav",,"Interaction testing can be used to effectively detect faults that are otherwise difficult to find by other testing techniques. However, in practice, the input configurations of software systems are subjected to constraints, especially in the case of highly configurable systems. Handling constraints effectively and efficiently in combinatorial interaction testing is a challenging problem. Nevertheless, researchers have attacked this challenge through different techniques, and much progress has been achieved in the past decade. Thus, it is useful to reflect on the current achievements and shortcomings and to identify potential areas of improvements. This paper presents the first comprehensive and systematic literature study to structure and categorize the research contributions for constrained interaction testing. Following the guidelines of conducting a literature study, the relevant data are extracted from a set of 103 research papers belonging to constrained interaction testing. The topics addressed in constrained interaction testing research are classified into four categories of constraint test generation, application, generation and application, and model validation studies. The papers within each of these categories are extensively reviewed. Apart from answering several other research questions, this paper also discusses the applications of constrained interaction testing in several domains, such as software product lines, fault detection and characterization, test selection, security, and graphical user interface testing. This paper ends with a discussion of limitations, challenges, and future work in the area."
Constrained mutation in c programs,"Wong, W.E. and Maldonado, J.C. and Delamaro, M.E. and Mathur, A.P.",x (not found),
Correction to: Evaluating testing methods by delivered reliability,"Frankl, Phyllis and Hamlet, Dick and Littlewood, Bev and Strigini, Lorenzo",x (no paper),
Coverage estimation for symbolic model checking,"Yatin, Timothy, Pei-Hsin, Xudong",,"Although model checking is an exhaustive formal verification method, a bug can still escape detection if the erroneous behavior does not violate any verified property. We propose a coverage metric to estimate the 'completeness' of a set of properties verified by model checking. A symbolic algorithm is presented to compute this metric for a subset of the CTL property specification language. It has the same order of computational complexity as a model checking algorithm. Our coverage estimator has been applied in the course of some real-world model checking projects. We uncovered several coverage holes including one that eventually led to the discovery of a bug that escaped the initial model checking effort."
"Coverage-based regression test case selection, minimization and prioritization: a case study on an industrial system","Daniel, Nadia, Lionel, Yvan",,"This paper presents a case study of coverage-based regression testing techniques on a real world industrial system with real regression faults. The study evaluates four common prioritization techniques, a test selection technique, a test suite minimization technique and a hybrid approach that combines selection and minimization. The study also examines the effects of using various coverage criteria on the effectiveness of the studied approaches. The results show that prioritization techniques that are based on additional coverage with finer grained coverage criteria perform significantly better in fault detection rates. The study also reveals that using modification information in prioritization techniques does not significantly enhance fault detection rates. The results show that test selection does not provide significant savings in execution cost (<2%), which might be attributed to the nature of the changes made to the system. Test suite minimization using finer grained coverage criteria could provide significant savings in execution cost (79.5%) while maintaining a fault detection capability level above 70%, thus representing a possible trade-off. The hybrid technique did not provide a significant improvement over traditional minimization techniques."
"Covrig: a framework for the analysis of code, test, and coverage evolution in real software","Paul, Petr, Cristian",,"Software repositories provide rich information about the construction and evolution of software systems. While static data that can be mined directly from version control systems has been extensively studied, dynamic metrics concerning the execution of the software have received much less attention, due to the inherent difficulty of running and monitoring a large number of software versions. In this paper, we present Covrig, a flexible infrastructure that can be used to run each version of a system in isolation and collect static and dynamic software metrics, using a lightweight virtual machine environment that can be deployed on a cluster of local or cloud machines. We use Covrig to conduct an empirical study examining how code and tests co-evolve in six popular open-source systems. We report the main characteristics of software patches, analyse the evolution of program and patch coverage, assess the impact of nondeterminism on the execution of test suites, and investigate whether the coverage of code containing bugs and bug fixes is higher than average."
"Developer Testing in the IDE: Patterns, Beliefs, and Behavior","Moritz, Georgios, Annibale, Sebastian, Sven, Andy",,"Software testing is one of the key activities to achieve software quality in practice. Despite its importance, however, we have a remarkable lack of knowledge on how developers test in real-world projects. In this paper, we report on a large-scale field study with 2,443 software engineers whose development activities we closely monitored over 2.5 years in four integrated development environments (IDEs). Our findings, which largely generalized across the studied IDEs and programming languages Java and C#, question several commonly shared assumptions and beliefs about developer testing: half of the developers in our study do not test; developers rarely run their tests in the IDE; most programming sessions end without any test execution; only once they start testing, do they do it extensively; a quarter of test cases is responsible for three quarters of all test failures; 12 percent of tests show flaky behavior; Test-Driven Development (TDD) is not widely practiced; and software developers only spend a quarter of their time engineering tests, whereas they think they test half of their time. We summarize these practices of loosely guiding one's development efforts with the help of testing in an initial summary on Test-Guided Development (TGD), a behavior we argue to be closer to the development reality of most developers than TDD."
Directed test suite augmentation,"Zhihong, Yunho, Moonzoo, Gregg, Myra B.",,"As software evolves, engineers use regression testing to evaluate its fitness for release. Such testing typically begins with existing test cases, and many techniques have been proposed for reusing these cost-effectively. After reusing test cases, however, it is also important to consider code or behavior that has not been exercised by existing test cases and generate new test cases to validate these. This process is known as test suite augmentation. In this paper we present a directed test suite augmentation technique, that utilizes results from reuse of existing test cases together with an incremental concolic testing algorithm to augment test suites so that they are coverage-adequate for a modified program. We present results of an empirical study examining the effectiveness of our approach."
Effective Unit Testing: A guide for Java developers,"Koskela, L.",x (Book),
Effective fault localization via mutation analysis,"Mike, Yves",,"When programs fail, developers face the problem of identifying the code fragments responsible for this failure. To this end, fault localization techniques try to identify suspicious program places (program statements) by observing the spectrum of the failing and passing test executions. These statements are then pointed out to assist the debugging activity. This paper considers mutation-based fault localization and suggests the use of a sufficient mutant set to locate effectively the faulty statements. Experimentation reveals that mutation-based fault localization is significantly more effective than current state-of-the-art fault localization techniques. Additionally, the results show that the proposed approach is capable of reducing the overheads of mutation analysis. In particular the number of mutants to be considered is reduced to 20% with only a limited loss on the method's effectiveness."
Efficient Guiding Strategies for Testing of Temporal Properties of Hybrid Systems,"Tommaso, Thao, Alexandre, James, Xiaoqing, Jyotirmoy V.",,"Techniques for testing cyberphysical systems (CPS) currently use a combination of automatic directed test generation and random testing to find undesirable behaviors. Existing techniques can fail to efficiently identify bugs because they do not adequately explore the space of system behaviors. In this paper, we present an approach that uses the rapidly exploring random trees (RRT) technique to explore the state-space of a CPS. Given a Signal Temporal Logic (STL) requirement, the RRT algorithm uses two quantities to guide the search: The first is a robustness metric that quantifies the degree of satisfaction of the STL requirement by simulation traces. The second is a metric for measuring coverage for a dense state-space, known as the star discrepancy measure. We show that our approach scales to industrial-scale CPSs by demonstrating its efficacy on an automotive powertrain control system."
Employing second-order mutation for isolating first-order equivalent mutants,"Marinos, Mike, Nicos",,"The equivalent mutant problem is a major hindrance to mutation testing. Being undecidable in general, it is only susceptible to partial solutions. In this paper, mutant classification is utilised for isolating likely to be first-order equivalent mutants. A new classification technique, Isolating Equivalent Mutants (I-EQM), is introduced and empirically investigated. The proposed approach employs a dynamic execution scheme that integrates the impact on the program execution of first-order mutants with the impact on the output of second-order mutants. An experimental study, conducted using two independently created sets of manually classified mutants selected from real-world programs revalidates previously published results and provides evidence for the effectiveness of the proposed technique. Overall, the study shows that I-EQM substantially improves previous methods by retrieving a considerably higher number of killable mutants, thus, amplifying the quality of the testing process."
Emulation of software faults by educated mutations at machine-code level,"J., H.",,"This paper proposes a new technique to emulate software faults by educated mutations introduced at the machine-code level and presents an experimental study on the accuracy of the injected faults. The proposed method consists of finding key programming structures at the machine code-level where high-level software faults can be emulated. The main advantage of emulating software faults at the machine-code level is that software faults can be injected even when the source code of the target application is not available, which is very important for the evaluation of COTS components or for the validation of software fault tolerance techniques in COTS based systems. The technique was evaluated using several real programs and different types of faults and, additionally, it includes our study on the key aspects that may impact on the technique accuracy. The portability of the technique is also addressed. The results show that classes of faults such as assignment, checking, interface, and simple algorithm faults can be directly emulated using this technique."
Evaluating the efficacy of test-driven development,"Thirumalesh, Nachiappan",,"This paper discusses software development using the Test Driven Development (TDD) methodology in two different environments (Windows and MSN divisions) at Microsoft. In both these case studies we measure the various context, product and outcome measures to compare and evaluate the efficacy of TDD. We observed a significant increase in quality of the code (greater than two times) for projects developed using TDD compared to similar projects developed in the same organization in a non-TDD fashion. The projects also took at least 15% extra upfront time for writing the tests. Additionally, the unit tests have served as auto documentation for the code when libraries/APIs had to be used as well as for code maintenance."
Evaluation of the cost of alternate mutation strategies,"Mathur, A.P. and Wong, W.E.",x (not found),
Evolutionary Generation of Whole Test Suites,"Gordon, Andrea",,"Recent advances in software testing allow automatic derivation of tests that reach almost any desired point in the source code. There is, however, a fundamental problem with the general idea of targeting one distinct test coverage goal at a time: Coverage goals are neither independent of each other, nor is test generation for any particular coverage goal guaranteed to succeed. We present EVOSUITE, a search-based approach that optimizes whole test suites towards satisfying a coverage criterion, rather than generating distinct test cases directed towards distinct coverage goals. Evaluated on five open source libraries and an industrial case study, we show that EVOSUITE achieves up to 18 times the coverage of a traditional approach targeting single branches, with up to 44% smaller test suites."
Evolutionary test environment for automatic structural testing,"Joachim, Andre, Harmen",,"Recent advances in software testing allow automatic derivation of tests that reach almost any desired point in the source code. There is, however, a fundamental problem with the general idea of targeting one distinct test coverage goal at a time: Coverage goals are neither independent of each other, nor is test generation for any particular coverage goal guaranteed to succeed. We present EVOSUITE, a search-based approach that optimizes whole test suites towards satisfying a coverage criterion, rather than generating distinct test cases directed towards distinct coverage goals. Evaluated on five open source libraries and an industrial case study, we show that EVOSUITE achieves up to 18 times the coverage of a traditional approach targeting single branches, with up to 44% smaller test suites."
Exploring variability-aware execution for testing plugin-based web applications,"Hung Viet, Christian, Tien N.",,"In plugin-based systems, plugin conflicts may occur when two or more plugins interfere with one another, changing their expected behaviors. It is highly challenging to detect plugin conflicts due to the exponential explosion of the combinations of plugins (i.e., configurations). In this paper, we address the challenge of executing a test case over many configurations. Leveraging the fact that many executions of a test are similar, our variability-aware execution runs common code once. Only when encountering values that are different depending on specific configurations will the execution split to run for each of them. To evaluate the scalability of variability-aware execution on a large real-world setting, we built a prototype PHP interpreter called Varex and ran it on the popular WordPress blogging Web application. The results show that while plugin interactions exist, there is a significant amount of sharing that allows variability-aware execution to scale to 2^50 configurations within seven minutes of running time. During our study, with Varex, we were able to detect two plugin conflicts: one was recently reported on WordPress forum and another one was not previously discovered."
Factors Limiting Industrial Adoption of Test Driven Development: A Systematic Review,"Adnan, Daniel, Sasikumar",,"Test driven development (TDD) is one of the basic practices of agile software development and both academia and practitioners claim that TDD, to a certain extent, improves the quality of the code produced by developers. However, recent results suggest that this practice is not followed to the extent preferred by industry. In order to pinpoint specific obstacles limiting its industrial adoption we have conducted a systematic literature review on empirical studies explicitly focusing on TDD as well as indirectly addressing TDD. Our review has identified seven limiting factors viz., increased development time, insufficient TDD experience/knowledge, lack of upfront design, domain and tool specific issues, lack of developer skill in writing test cases, insufficient adherence to TDD protocol, and legacy code. The results of this study is of special importance to the testing community, since it outlines the direction for further detailed scientific investigations as well as highlights the requirement of guidelines to overcome these limiting factors for successful industrial adoption of TDD."
Foundations of Software Testing: Fundamental Algorithms and Techniques,"Mathur, A.P.",x (Book),
Generating software test data by evolution,"C.C., G., M.A.",,"This paper discusses the use of genetic algorithms (GAs) for automatic software test data generation. This research extends previous work on dynamic test data generation where the problem of test data generation is reduced to one of minimizing a function. In our work, the function is minimized by using one of two genetic algorithms in place of the local minimization techniques used in earlier research. We describe the implementation of our GA-based system and examine the effectiveness of this approach on a number of programs, one of which is significantly larger than those for which results have previously been reported in the literature. We also examine the effect of program complexity on the test data generation problem by executing our system on a number of synthetic programs that have varying complexities."
Gerard. xUnit test patterns: Refactoring test code,Meszaros,x (Book),
HOMAJ: A Tool for Higher Order Mutation Testing in AspectJ and Java,"Elmahdi, Sudipto, Darrell",,"The availability of automated tool support is an important consideration for software developers before they can incorporate higher order mutation testing into their software development processes. This paper presents HOMAJ, a higher order mutation testing tool for AspectJ and Java. HOMAJ automates the process of generating and evaluating first order mutants (FOMs) and higher order mutants (HOMs). In particular, HOMAJ can be used to generate subtle HOMs, which are HOMs that cannot be killed by an existing test set that kills all the FOMs. Subtle HOMs can be valuable for improving test effectiveness because they can simulate complex and non-trivial faults that cannot be simulated with the use of traditional FOMs. HOMAJ implements a number of different techniques for generating subtle HOMs, including several search-based software engineering techniques, enumeration search, and random search. HOMAJ is designed in a modular way to make it easy to incorporate a new search strategy. In this paper we demonstrate the use of HOMAJ to evaluate the implemented techniques."
Improving student performance by evaluating how well students test their own programs,Stephen H.,,"Students need to learn more software testing skills. This paper presents an approach to teaching software testing in a way that will encourage students to practice testing skills in many classes and give them concrete feedback on their testing performance, without requiring a new course, any new faculty resources, or a significant number of lecture hours in each course where testing will be practiced. The strategy is to give students basic exposure to test-driven development, and then provide an automated tool that will assess student submissions on-demand and provide feedback for improvement. This approach has been demonstrated in an undergraduate programming languages course using a prototype tool. The results have been positive, with students expressing appreciation for the practical benefits of test-driven development on programming assignments. Experimental analysis of student programs shows a 28% reduction in defects per thousand lines of code."
Jtest manuals version 4.5,Parasoft,x (User Manual),
Killing strategies for model-based mutation testing,"Bernhard K., Harald, Elisabeth, Willibald, Rupert, Stefan",,"This article presents the techniques and results of a novel model-based test case generation approach that automatically derives test cases from UML state machines. The main contribution of this article is the fully automated fault-based test case generation technique together with two empirical case studies derived from industrial use cases. Also, an in-depth evaluation of different fault-based test case generation strategies on each of the case studies is given and a comparison with plain random testing is conducted. The test case generation methodology supports a wide range of UML constructs and is grounded on the formal semantics of Back's action systems and the well-known input–output conformance relation. Mutation operators are employed on the level of the specification to insert faults and generate test cases that will reveal the faults inserted. The effectiveness of this approach is shown and it is discussed how to gain a more expressive test suite by combining cheap but undirected random test case generation with the more expensive but directed mutation-based technique. Finally, an extensive and critical discussion of the lessons learnt is given as well as a future outlook on the general usefulness and practicability of mutation-based test case generation."
Making System User Interactive Tests Repeatable: When and What Should We Control?,"Zebao, Yalan, Myra B., Atif M., Zhen",,"System testing and invariant detection is usually conducted from the user interface perspective when the goal is to evaluate the behavior of an application as a whole. A large number of tools and techniques have been developed to generate and automate this process, many of which have been evaluated in the literature or internally within companies. Typical metrics for determining effectiveness of these techniques include code coverage and fault detection, however, with the assumption that there is determinism in the resulting outputs. In this paper we examine the extent to which a common set of factors such as the system platform, Java version, application starting state and tool harness configurations impact these metrics. We examine three layers of testing outputs: the code layer, the behavioral (or invariant) layer and the external (or user interaction) layer. In a study using five open source applications across three operating system platforms, manipulating several factors, we observe as many as 184 lines of code coverage difference between runs using the same test cases, and up to 96 percent false positives with respect to fault detection. We also see some a small variation among the invariants inferred. Despite our best efforts, we can reduce, but not completely eliminate all possible variation in the output. We use our findings to provide a set of best practices that should lead to better consistency and smaller differences in test outcomes, allowing more repeatable and reliable testing and experimentation."
Measuring the cost of regression testing in practice: a study of Java projects using continuous integration,"Adriaan, Laura, Reid",,"Software defects cost time and money to diagnose and fix. Consequently, developers use a variety of techniques to avoid introducing defects into their systems. However, these techniques have costs of their own; the benefit of using a technique must outweigh the cost of applying it. In this paper we investigate the costs and benefits of automated regression testing in practice. Specifically, we studied 61 projects that use Travis CI, a cloud-based continuous integration tool, in order to examine real test failures that were encountered by the developers of those projects. We determined how the developers resolved the failures they encountered and used this information to classify the failures as being caused by a flaky test, by a bug in the system under test, or by a broken or obsolete test. We consider that test failures caused by bugs represent a benefit of the test suite, while failures caused by broken or obsolete tests represent a test suite maintenance cost. We found that 18% of test suite executions fail and that 13% of these failures are flaky. Of the non-flaky failures, only 74% were caused by a bug in the system under test; the remaining 26% were due to incorrect or obsolete tests. In addition, we found that, in the failed builds, only 0.38% of the test case executions failed and 64% of failed builds contained more than one failed test. Our findings contribute to a wider understanding of the unforeseen costs that can impact the overall cost effectiveness of regression testing in practice. They can also inform research into test case selection techniques, as we have provided an approximate empirical bound on the practical value that could be extracted from such techniques. This value appears to be large, as the 61 systems under study contained nearly 3 million lines of test code and yet over 99% of test case executions could have been eliminated with a perfect oracle."
Mining unit test cases to synthesize API usage examples,"Mohammad, Konstantin, Mohammad Mehdi",,"Software developers study and reuse existing source code to understand how to properly use application programming interfaces (APIs). However, manually finding sufficient and adequate code examples for a given API is a difficult and a time-consuming activity. Existing approaches to find or generate examples assume availability of a reasonable set of client code that uses the API. This assumption does not hold for newly released API libraries, non-widely used APIs, nor private ones. In this work we reuse the important information that is naturally present in test code to circumvent the lack of usage examples for an API when other sources of client code are not available. We propose an approach for automatically identifying the most representative API uses within each unit test case. We then develop an approach to synthesize API usage examples by extracting relevant statements representing the usage of such APIs. We compare the output of a prototype implementation of our approach to both human-written examples and to a state-of-the-art approach. The obtained results are encouraging; the examples automatically generated with our approach are superior to the state-of-the-art approach and highly similar to the manually constructed examples."
Mobile Application Testing: A Tutorial,"Jerry, Xiaoying, Wei-Tek, Tadahiro",,"To cope with frequent upgrades of mobile devices and technologies, engineers need a reusable and cost-effective environment for testing mobile applications and an elastic infrastructure to support large-scale test automation."
Model-Based Testing of Reactive Systems,,x (Book),
MuTMuT: Efficient Exploration for Mutation Testing of Multithreaded Code,"Milos, Vilas, Darko",,"Mutation testing is a method for measuring the quality of test suites. Given a system under test and a test suite, mutations are systematically inserted into the system, and the test suite is executed to determine which mutants it detects. A major cost of mutation testing is the time required to execute the test suite on all the mutants. This cost is even greater when the system under test is multithreaded: not only are test cases from the test suite executed on many mutants, but also each test case is executed for multiple possible thread schedules. We introduce a general framework that can reduce the time for mutation testing of multithreaded code. We present four techniques within the general framework and implement two of them in a tool called MuTMuT. We evaluate MuTMuT on eight multithreaded programs. The results show that MuTMuT reduces the time for mutation testing, substantially over a straightforward mutant execution and up to 77% with the advanced technique over the basic technique."
Mull It Over: Mutation Testing Based on LLVM,"Alex, Stanislav",,"This paper describes Mull, an open-source tool for mutation testing based on the LLVM framework. Mull works with LLVM IR, a low-level intermediate representation, to perform mutations, and uses LLVM JIT for just-in-time compilation. This design choice enables the following two capabilities of Mull: langu?age independence and fine-grained control over compilation and execution of a tested program and its mutations. Mull can work with code written in any programming language that supports compilation to LLVM IR, such as C, C++, Rust, or Swift. Direct manipulation of LLVM IR allows Mull to do less work to generate mutations: only modified fragments of IR code are recompiled, and this results in faster processing of mutated programs. To our knowledge, no existing mutation testing tool provides these capabilities for compiled programming languages. We describe the algorithm and implementation details of Mull, highlight current limitations of Mull, and present the results of our evaluation of Mull on real-world projects such as RODOS, OpenSSL, LLVM."
Mutant unification for improved vectorization,"Mathur, A.P. and Krauser, E.W.",x (not found),
Mutation Testing for Java Database Applications,"Chixiang, Phyllis",,"Database application programs are ubiquitous, so good techniques for testing them are needed. Recently, several research groups have proposed new approaches to generating tests for database applications and for assessing test data adequacy. This paper describes a mutation testing tool, JDAMA (Java database application mutation analyzer), for Java programs that interact with a database via the JDBC interface. Our approach extends the mutation testing approach for SQL by Tuya et al, by integrating it with analysis and instrumentation of the application bytecode. JDAMA's use is illustrated through a small study which uses mutation scores to compare two test generation techniques for database applications."
Mutation analysis of program test data[ph. d. thesis,"Budd, T.A.",x (not found),
Mutation based test case generation via a path selection strategy,"Mike, Nicos",,"Context: Generally, mutation analysis has been identified as a powerful testing method. Researchers have shown that its use as a testing criterion exercises quite thoroughly the system under test while it achieves to reveal more faults than standard structural testing criteria. Despite its potential, mutation fails to be adopted in a widespread practical use and its popularity falls significantly short when compared with other structural methods. This can be attributed to the lack of thorough studies dealing with the practical problems introduced by mutation and the assessment of the effort needed when applying it. Such an incident, masks the real cost involved preventing the development of easy and effective to use strategies to circumvent this problem. Objective: In this paper, a path selection strategy for selecting test cases able to effectively kill mutants when performing weak mutation testing is presented and analysed. Method: The testing effort is highly correlated with the number of attempts the tester makes in order to generate adequate test cases. Therefore, a significant influence on the efficiency associated with a test case generation strategy greatly depends on the number of candidate paths selected in order to achieve a predefined coverage goal. The effort can thus be related to the number of infeasible paths encountered during the test case generation process. Results: An experiment, investigating well over 55 million of program paths is conducted based on a strategy that alleviates the effects of infeasible paths. Strategy details, along with a prototype implementation are reported and analysed through the experimental results obtained by its employment to a set of program units. Conclusio: The results obtained suggest that the strategy used can play an important role in making the mutation testing method more appealing and practical."
Mutation-Based Fault Localization for Real-World Multilingual Programs (T),"Shin, Byeongcheol, Taehoon, Yiru, Bongsuk, Yunho, Moonzoo",,"Programmers maintain and evolve their software in a variety of programming languages to take advantage of various control/data abstractions and legacy libraries. The programming language ecosystem has diversified over the last few decades, and non-trivial programs are likely to be written in more than a single language. Unfortunately, language interfaces such as Java Native Interface and Python/C are difficult to use correctly and the scope of fault localization goes beyond language boundaries, which makes debugging multilingual bugs challenging. To overcome the aforementioned limitations, we propose a mutation-based fault localization technique for real-world multilingual programs. To improve the accuracy of locating multilingual bugs, we have developed and applied new mutation operators as well as conventional mutation operators. The results of the empirical evaluation for six non-trivial real-world multilingual bugs are promising in that the proposed technique identifies the buggy statements as the most suspicious statements for all six bugs."
Mutation-based fuzzing,"Zeller, A. and Gopinath, R. and Böhme, M. and Fraser, G. and Holler, C.",x (Web),
On the use of a similarity function for test case selection in the context of model-based testing,"Emanuela G., Patrícia D. L., Francisco G. Oliveira",,"Test case selection in model-based testing is discussed focusing on the use of a similarity function. Automatically generated test suites usually have redundant test cases. The reason is that test generation algorithms are usually based on structural coverage criteria that are applied exhaustively. These criteria may not be helpful to detect redundant test cases as well as the suites are usually impractical due to the huge number of test cases that can be generated. Both problems are addressed by applying a similarity function. The idea is to keep in the suite the less similar test cases according to a goal that is defined in terms of the intended size of the test suite. The strategy presented is compared with random selection by considering transition-based and fault-based coverage. The results show that, in most of the cases, similarity-based selection can be more effective than random selection when applied to automatically generated test suites."
One evaluation of model-based testing and its automation,"A., W., S., C., M., B., R., T.",,"Model-based testing relies on behavior models for the generation of model traces: input and expected output---test cases---for an implementation. We use the case study of an automotive network controller to assess different test suites in terms of error detection, model coverage, and implementation coverage. Some of these suites were generated automatically with and without models, purely at random, and with dedicated functional test selection criteria. Other suites were derived manually, with and without the model at hand. Both automatically and manually derived model-based test suites detected significantly more requirements errors than hand-crafted test suites that were directly derived from the requirements. The number of detected programming errors did not depend on the use of models. Automatically generated model-based test suites detected as many errors as hand-crafted model-based suites with the same number of tests. A sixfold increase in the number of model-based tests led to an 11% increase in detected errors."
"Oops, My Tests Broke the Build: An Explorative Analysis of Travis CI with GitHub","Moritz, Georgios, Andy",,"Continuous Integration (CI) has become a best practice of modern software development. Yet, at present, we have a shortfall of insight into the testing practices that are common in CI-based software development. In particular, we seek quantifiable evidence on how central testing is to the CI process, how strongly the project language influences testing, whether different integration environments are valuable and if testing on the CI can serve as a surrogate to local testing in the IDE. In an analysis of 2,640,825 Java and Ruby builds on Travis CI, we find that testing is the single most important reason why builds fail. Moreover, the programming language has a strong influence on both the number of executed tests, their run time, and proneness to fail. The use of multiple integration environments leads to 10% more failures being caught at build time. However, testing on Travis CI does not seem an adequate surrogate for running tests locally in the IDE. To further research on Travis CI with GitHub, we introduce TravisTorrent."
PCTgen: Automated Generation of Test Cases for Application Workflows,Miroslav,,"Functional testing of application workflows is one of the most frequently used testing methods. To reduce test design effort and decrease a possibility of human mistake, it is suitable to support the process by an automated method. In this paper we present the PCTgen, solution, which is open and flexible, available for free to the test designer community and do not assume existence of UML design documentation of certain quality and consistency on the project. The PCTgen is bringing several innovative features as well as the possibility to interchange data with design and test management tools. Together with this solution, an algorithm for the generation of workflow test cases is introduced."
PIT: a practical mutation testing tool for Java (demo),"Henry, Thomas, Christopher, Mike, Anthony",,"Mutation testing introduces artificial defects to measure the adequacy of testing. In case candidate tests can distinguish the behaviour of mutants from that of the original program, they are considered of good quality -- otherwise developers need to design new tests. While, this method has been shown to be effective, industry-scale code challenges its applicability due to the sheer number of mutants and test executions it requires. In this paper we present PIT, a practical mutation testing tool for Java, applicable on real-world codebases. PIT is fast since it operates on bytecode and optimises mutant executions. It is also robust and well integrated with development tools, as it can be invoked through a command line interface, Ant or Maven. PIT is also open source and hence, publicly available at http://pitest.org/"
Pit mutation testing,"Coles, H.",x (not found),
Pit mutation testing: Mutators,"Coles, H.",x (not found),
Practical regression test selection with dynamic file dependencies,"Milos, Lamyaa, Darko",,"Regression testing is important but can be time-intensive. One approach to speed it up is regression test selection (RTS), which runs only a subset of tests. RTS was proposed over three decades ago but has not been widely adopted in practice. Meanwhile, testing frameworks, such as JUnit, are widely adopted and well integrated with many popular build systems. Hence, integrating RTS in a testing framework already used by many projects would increase the likelihood that RTS is adopted. We propose a new, lightweight RTS technique, called Ekstazi, that can integrate well with testing frameworks. Ekstazi tracks dynamic dependencies of tests on files, and unlike most prior RTS techniques, Ekstazi requires no integration with version-control systems. We implemented Ekstazi for Java and JUnit, and evaluated it on 615 revisions of 32 open-source projects (totaling almost 5M LOC) with shorter- and longer-running test suites. The results show that Ekstazi reduced the end-to-end testing time 32% on average, and 54% for longer-running test suites, compared to executing all tests. Ekstazi also has lower end-to-end time than the existing techniques, despite the fact that it selects more tests. Ekstazi has been adopted by several popular open source projects, including Apache Camel, Apache Commons Math, and Apache CXF."
Prioritizing Mutation Operators Based on Importance Sampling,"Mohan, Akbar Siami",,"Mutation testing is a fault-based testing technique for measuring the adequacy of a test suite. Test suites are assigned scores based on their ability to expose synthetic faults (i.e., mutants) generated by a range of well-defined mathematical operators. The test suites can then be augmented to expose the mutants that remain undetected and are not semantically equivalent to the original code. However, the mutation score can be increased superfluously by mutants that are easy to expose. In addition, it is infeasible to examine all the mutants generated by a large set of mutation operators. Existing approaches have therefore focused on determining the sufficient set of mutation operators and the set of equivalent mutants. Instead, this paper proposes a novel Bayesian approach that prioritizes operators whose mutants are likely to remain unexposed by the existing test suites. Probabilistic sampling methods are adapted to iteratively examine a subset of the available mutants and direct focus towards the more informative operators. Experimental results show that the proposed approach identifies more than 90% of the important operators by examining ? 20% of the available mutants, and causes a 6% increase in the importance measure of the selected mutants."
Prioritizing test cases with string distances,"Yves, Alexandre, Sergiy, Nadine",,"Test case prioritisation aims at finding an ordering which enhances a certain property of an ordered test suite. Traditional techniques rely on the availability of code or a specification of the program under test. We propose to use string distances on the text of test cases for their comparison and elaborate a prioritisation algorithm. Such a prioritisation does not require code or a specification and can be useful for initial testing and in cases when code is difficult to instrument. In this paper, we also report on experiments performed on the “Siemens Test Suite”, where the proposed prioritisation technique was compared with random permutations and four classical string distance metrics were evaluated. The obtained results, confirmed by a statistical analysis, indicate that prioritisation based on string distances is more efficient in finding defects than random ordering of the test suite: the test suites prioritized using string distances are more efficient in detecting the strongest mutants, and, on average, have a better APFD than randomly ordered test suites. The results suggest that string distances can be used for prioritisation purposes, and Manhattan distance could be the best choice."
Program testing by specification mutation,"Timothy A., Ajei S.",,"Both theoretical and empirical arguments suggest that specifications and implementations are equally important sources of information for generating test cases. Nevertheless, the majority of test generation procedures described in the literature deal only with the program source, ignoring specifications. In this paper we outline a procedure for measuring test case effectiveness using specifications given in predicate calculus form. This method is similar to the mutation analysis method of testing programs."
Randomized directed testing (REDIRECT) for Simulink/Stateflow models,"Manoranjan, Anand, S.",,"The Simulink/Stateflow (SL/SF) environment from Math-works is becoming the de facto standard in industry for model based development of embedded control systems. Many commercial tools are available in the market for test case generation from SL/SF designs; however, we have observed that these tools do not achieve satisfactory coverage in cases when designs involve nonlinear blocks and Stateflow blocks occur deep inside the Simulink blocks. The recent past has seen the emergence of several novel techniques for testing large C, C++ and Java programs; prominent among them are directed automated random testing (DART), hybrid concolic testing and feedback-directed random testing. We believe that some of these techniques could be lifted to testing of SL/SF based designs; REDIRECT (RandomizEd DIRECted Testing), the proposed testing method of this paper, is an attempt towards this direction. Specifically, REDIRECT uses a careful combination of the above techniques, and in addition, the method uses a set of pattern-guided heuristics for tackling nonlinear blocks. A prototype tool has been developed and the tool has been applied to many industrial strength case studies. Our experiments indicate that a careful choice of heuristics and certain combinations of random and directed testing achieve better coverages as compared to the existing commercial tools."
Robotic Testing of Mobile Apps for Truly Black-Box Automation,"Ke, Mark, Yue",,"Robots are widely used for many repetitive tasks. Why not software testing? Robotic testing could give testers a new form of testing that's inherently more black-box than anything witnessed previously. Toward that end, researchers developed Axiz, a robotic-test generator for mobile devices."
SPLat: lightweight dynamic analysis for reducing combinatorics in testing configurable systems,"Chang Hwan Peter, Darko, Sarfraz, Don, Sabrina, Paulo, Marcelo",,"Many programs can be configured through dynamic and/or static selection of configuration variables. A software product line (SPL), for example, specifies a family of programs where each program is defined by a unique combination of features. Systematically testing SPL programs is expensive as it can require running each test against a combinatorial number of configurations. Fortunately, a test is often independent of many configuration variables and need not be run against every combination. Configurations that are not required for a test can be pruned from execution. This paper presents SPLat, a new way to dynamically prune irrelevant configurations: the configurations to run for a test can be determined during test execution by monitoring accesses to configuration variables. SPLat achieves an optimal reduction in the number of configurations and is lightweight compared to prior work that used static analysis and heavyweight dynamic execution. Experimental results on 10 SPLs written in Java show that SPLat substantially reduces the total test execution time in many cases. Moreover, we demonstrate the scalability of SPLat by applying it to a large industrial code base written in Ruby on Rails."
"Search-Based Software Testing: Past, Present and Future",Phil,,"Search-Based Software Testing is the use of a meta-heuristic optimizing search technique, such as a Genetic Algorithm, to automate or partially automate a testing task, for example the automatic generation of test data. Key to the optimization process is a problem-specific fitness function. The role of the fitness function is to guide the search to good solutions from a potentially infinite search space, within a practical time limit. Work on Search-Based Software Testing dates back to 1976, with interest in the area beginning to gather pace in the 1990s. More recently there has been an explosion of the amount of work. This paper reviews past work and the current state of the art, and discusses potential future research areas and open problems that remain in the field."
Search-based data-flow test generation,"Mattia, Andre, Alessandra, Gordon",,"Coverage criteria based on data-flow have long been discussed in the literature, yet to date they are still of surprising little practical relevance. This is in part because 1) manually writing a unit test for a data-flow aspect is more challenging than writing a unit test that simply covers a branch or statement, 2) there is a lack of tools to support data-flow testing, and 3) there is a lack of empirical evidence on how well data-flow testing scales in practice. To overcome these problems, we present 1) a search-based technique to automatically generate unit tests for data-flow criteria, 2) an implementation of this technique in the Evosuite test generation tool, and 3) a large empirical study applying this tool to the SF100 corpus of 100 open source Java projects. On average, the number of coverage objectives is three times as high as for branch coverage. However, the level of coverage achieved by Evosuite is comparable to other criteria, and the increase in size is only 15%, leading to higher mutation scores. These results counter the common assumption that data-flow testing does not scale, and should help to re-establish data-flow testing as a viable alternative in practice."
Searching and generating test inputs for mutation testing,"Mike, Nicos",,"Mutation testing is usually regarded as an important method towards fault revealing. Despite this advantage, it has proved to be impractical for industrial use because of its expenses. To this extend, automated techniques are needed in order to apply and reduce the method’s demands. Whilst there is much evidence that automated test data generation techniques can effectively automate the testing process, there has been little work on applying them in the context of mutation testing. In this paper, search-based testing is used in order to effectively generate test inputs capable of revealing mutants. To this end, a dynamic execution scheme capable of introducing and guiding the search towards the sought mutants is proposed. Experimentation with the proposed approach reveals its superiority from the previously proposed methods. Additionally, the framework’s feasibility and practicality of producing mutation based test cases are also demonstrated."
Selecting a software engineering tool: lessons learnt from mutation analysis,"Mickaël, Lydie",,"Software developers employ many tools in every step of the development. As automation progresses, tools take a more and more important place. A common and difficult problem is choosing a tool among every tool for a given task. As a particular instance of this problem, this paper considers mutation analysis tools. Mutation analysis is a way to evaluate the quality of a test suite. The quality is measured as the ability of the test suite to detect faults injected into the program under tests. A fault is detected if at least one test case gives different results on the original program and the fault-injected one. Mutation tools aim at automating and speeding both the generation of fault-injected variants, called mutants, and the execution of the test suite on those mutants. This paper proposes a methodology to compare tools and applies it for comparing mutation tools. This methodology proposes to dress a list of comparison criteria as well as a list of usage profiles. Mutation tools for Java are compared on paper and by experiments. The work is then extended to other languages to assert the pertinence of the comparison criteria and the usage profiles. Finally, lessons are drawn from our selection process."
Seleção Automática de Casos de Teste de Regressão Baseada em Similaridade e Valores,"Francisco Gomes, Patrícia Duarte de Lima",x (not English),
Shared Execution for Efficiently Testing Product Lines,"Chang Hwan Peter, Sarfraz, Don",,"A software product line (SPL) is a family of related programs, each of which is uniquely defined by a combination of features. Testing an SPL requires running each of its programs, which may be computationally expensive as the number of programs in an SPL is potentially exponential in the number of features. It is also wasteful since instructions common to many programs must be repeatedly executed, rather than just once. To reduce this waste, we propose the idea of shared execution, which runs instructions just once for a set of programs until a variable read yields multiple values, causing execution to branch for each value until a common execution point that allows shared execution to resume. Experiments show that shared execution can be faster than conventionally running each program from start to finish, despite its overhead."
Software Testing Techniques,"Beizer, B.",x (Book),
"Software testing and analysis: process, principles, and techniques","Pezze, M. and Young, M.",x (Book),
State coverage,"Ken, David",x (not found),
State coverage for the dynamic analysis of concurrent programs,"Sherman, E.",x (not found),
Taming Google-scale continuous testing,"Atif, , , Sanjeev, Eric, Rob, John",,"Growth in Google's code size and feature churn rate has seen increased reliance on continuous integration (CI) and testing to maintain quality. Even with enormous resources dedicated to testing, we are unable to regression test each code change individually, resulting in increased lag time between code check-ins and test result feedback to developers. We report results of a project that aims to reduce this time by: (1) controlling test workload without compromising quality, and (2) distilling test results data to inform developers, while they write code, of the impact of their latest changes on quality. We model, empirically understand, and leverage the correlations that exist between our code, test cases, developers, programming languages, and code-change and test-execution frequencies, to improve our CI and development processes. Our findings show: very few of our tests ever fail, but those that do are generally 'closer' to the code they test, certain frequently modified code and certain users/tools cause more breakages, and code recently modified by multiple developers (more than 3) breaks more often."
The Art of Application Performance Testing,"Molyneaux, I.",x (Book),
The Art of Unit Testing With Examples in .NET,"Osherove, R.",x (Book),
The Effects of Test-Driven Development on External Quality and Productivity: A Meta-Analysis,"Yahya, Vojislav B.",,"This paper provides a systematic meta-analysis of 27 studies that investigate the impact of Test-Driven Development (TDD) on external code quality and productivity. The results indicate that, in general, TDD has a small positive effect on quality but little to no discernible effect on productivity. However, subgroup analysis has found both the quality improvement and the productivity drop to be much larger in industrial studies in comparison with academic studies. A larger drop of productivity was found in studies where the difference in test effort between the TDD and the control group's process was significant. A larger improvement in quality was also found in the academic studies when the difference in test effort is substantial; however, no conclusion could be derived regarding the industrial studies due to the lack of data. Finally, the influence of developer experience and task size as moderator variables was investigated, and a statistically significant positive correlation was found between task size and the magnitude of the improvement in quality."
The Mothra software testing environment user’s manual,"DeMillo, R.A. and Martin, R.J.",x (User Manual),
The art of software testing,"Myers, Glenford J. and Sandler, Corey and Badgett, Tom",x (Book),
The economic impacts of inadequate infrastructure for software testing,"Tassey, G.",x (Book),
Threats to the validity and value of empirical assessments of the accuracy of coverage-based fault locators,"Friedrich, Marcus, Rui",,"Resuming past work on coverage-based fault localization, we find that empirical assessments of its accuracy are subject to so many imponderables that they are of limited value. To improve on this situation, we have compiled a comprehensive list of threats to be considered when attempting such assessments in the future. In addition, we propose the establishment of theoretical lower and upper bounds of fault localization accuracy that depend on properties of the subject programs (including their test suites) only. We make a suggestion for a lower bound and show that well-known fault locators do not uniformly perform better."
Toward variability-aware testing,"Christian, Alexander, Sebastian, Jonas, Sven, Tillmann, Klaus",,"We investigate how to execute a unit test for all products of a product line without generating each product in isolation in a brute-force fashion. Learning from variability-aware analyses, we (a) design and implement a variability-aware interpreter and, alternatively, (b) reencode variability of the product line to simulate the test cases with a model checker. The interpreter internally reasons about variability, executing paths not affected by variability only once for the whole product line. The model checker achieves similar results by reusing powerful off-the-shelf analyses. We experimented with a prototype implementation for each strategy. We compare both strategies and discuss trade-offs and future directions. In the long run, we aim at finding an efficient testing approach that can be applied to entire product lines with millions of products."
Towards building a solid empirical body of knowledge in testing techniques,"N., A. M., S.",,"Testing technique-related empirical studies have been performed for 25 years. We have managed to accumulate a fair number of experiments in this time, which might lead us to think that we now could have a sizeable empirically backed body of knowledge (BoK) on testing techniques. However, the experiments in this field have some flaws, and, consequently, the empirical BoK we have on testing techniques is far from solid. In this paper, we use the results of a survey that we did on empirical testing techniques studies to identify and discuss solutions that could lead to the formation of a solid empirical BoK. The solutions are related to two fundamental experimental issues: (1) the rigorousness of the experimental design and analysis, and (2) the need for a series of community-wide agreements to coordinate empirical research and assure that studies ratify and complement each other."
Transforming mutation testing from the technology of the future into the technology of the present,"Ammann, P.",x (Presentation),
Unit Test Frameworks: Tools for High-Quality Software Development,"Hamill, Paul",x (Book),
Unit testing with JUnit - tutorial,"Vogella, L.",x (Web),
Using Constraints for Equivalent Mutant Detection,"Simona, Franz",,"In mutation testing the question whether a mutant is equivalent to its program is important in order to compute the correct mutation score. Unfortunately, answering this question is not always possible and can hardly be obtained just by having a look at the program's structure. In this paper we introduce a method for solving the equivalent mutant problem using a constraint representation of the program and its mutant. In particularly the approach is based on distinguishing test cases, i.e., test inputs that force the program and its mutant to behave in a different way. Beside the foundations of the approach, in this paper we also present the algorithms and first empirical results."
Visualizing code and coverage changes for code review,"Sebastiaan, Arie van, Roberta, Anand Ashok, Alberto",,"One of the tasks of reviewers is to verify that code modifications are well tested. However, current tools offer little support in understanding precisely how changes to the code relate to changes to the tests. In particular, it is hard to see whether (modified) test code covers the changed code. To mitigate this problem, we developed Operias, a tool that provides a combined visualization of fine-grained source code differences and coverage impact. Operias works both as a stand-alone tool on specific project versions and as a service hooked to GitHub. In the latter case, it provides automated reports for each new pull request, which reviewers can use to assess the code contribution. Operias works for any Java project that works with maven and its standard Cobertura coverage plugin. We present how Operias could be used to identify test-related problems in real-world pull requests. Operias is open source and available on GitHub with a demo video: https://github.com/SERG-Delft/operias"
Whole Test Suite Generation,"Gordon, Andrea",,"Not all bugs lead to program crashes, and not always is there a formal specification to check the correctness of a software test's outcome. A common scenario in software testing is therefore that test data are generated, and a tester manually adds test oracles. As this is a difficult task, it is important to produce small yet representative test sets, and this representativeness is typically measured using code coverage. There is, however, a fundamental problem with the common approach of targeting one coverage goal at a time: Coverage goals are not independent, not equally difficult, and sometimes infeasible-the result of test generation is therefore dependent on the order of coverage goals and how many of them are feasible. To overcome this problem, we propose a novel paradigm in which whole test suites are evolved with the aim of covering all coverage goals at the same time while keeping the total size as small as possible. This approach has several advantages, as for example, its effectiveness is not affected by the number of infeasible targets in the code. We have implemented this novel approach in the EvoSuite tool, and compared it to the common approach of addressing one goal at a time. Evaluated on open source libraries and an industrial case study for a total of 1,741 classes, we show that EvoSuite achieved up to 188 times the branch coverage of a traditional approach targeting single branches, with up to 62 percent smaller test suites."
XSTRESSOR : Automatic Generation of Large-Scale Worst-Case Test Inputs by Inferring Path Conditions,"Charitha, Jinkyu, Milind, Saurabh",,"An important part of software testing is generation of worst-case test inputs, which exercise a program under extreme loads. For such a task, symbolic execution is a useful tool with its capability to reason about all possible execution paths of a program, including the one with the worst case behavior. However, symbolic execution suffers from the path explosion problem and frequent calls to a constraint solver, which make it impractical to be used at a large scale. To address the issue, this paper presents XSTRESSOR that is able to generate test inputs that can run specific loops in a program with the worst-case complexity in a large scale. XSTRESSOR synthetically generates the path condition for the large-scale, worst-case execution from a predictive model that is built from a set of small scale tests. XSTRESSOR avoids the scaling problem of prior techniques by limiting full-blown symbolic execution and run-time calls to constraint solver to small scale tests only. We evaluate XSTRESSOR against WISE and SPF-WCA, the most closely related tools to generate worst-case test inputs. Results show that XSTRESSOR can generate the test inputs faster than WISE and SPF-WCA, and also scale to much larger input sizes."
xUnit Test Patterns: Refactoring Test Code,"Meszaros, G.",x (Book),
A framework to advise tests using tests,"['Y Wang', 'S Person', 'S Elbaum', 'MB Dwyer']",,"Tests generated by different approaches can form a rich body of information about the system under test (SUT), which can then be used to amplify the power of test suites. Diversity in test representations, however, creates an obstacle to extracting and using this information. In this work, we introduce a test advice framework which enables extraction and application of information contained in existing tests to help improve other tests or test generation techniques. Our framework aims to 1) define a simple, yet expressive test case language so that different types of tests can be represented using a unified language, and 2) define an advice extraction function that enables the elicitation and application of the information encoded in a set of test cases. Preliminary results show how test advice can be used to generate amplified test suites with higher code coverage and improved mutants killed scores over the original test suite."
A multi-objective optimization approach for selection of second order mutant generation strategies,"['JAP Lima', 'SR Vergilio']",,"The use of Higher-Order Mutants (HOMs) presents some advantages concerning the traditional use of First-Order Mutants (FOMs). HOMs can better simulate real and subtle faults, reduce the number of generated mutants and test cases, and so on. However, the HOM space is potentially huge, and an efficient strategy to generate the best HOMs is fundamental. In the literature different strategies were proposed and evaluated, mainly to generate Second-Order Mutants (SOMs), but none has been proved to perform better in different situations. Due to this, the selection of the best strategy is an important task. Most times a lot of experiments need to be conducted. To help the tester in this task and to allow the use of HOMs in practice, this paper proposes a hyper-heuristic approach. Such approach is based on NSGA-II and uses the selection method Choice Function to automatically choose among different Low-Level Heuristics (LLHs), which, in this case, are search-operators related to existing SOM generation strategies. The performance of each LLH is related to some objectives such as the number of SOMs generated, the capacity to capture subtler faults and replace the constituent FOMs. In comparison with existing strategies, our approach obtained better results considering the used objectives, and statistically equivalent results considering mutation score with respect to the FOMs."
A replicated study on random test case generation and manual unit testing: How many bugs do professional developers find?,"['R Ramler', 'K Wolfmaier']",,"This paper describes the replication of an empirical study comparing tool-supported test case generation and manual development of unit tests. As variation to the original study, which was based on test results from students performing manual unit testing for 60 minutes, the replication involves professional software developers with several years of industry experience and extends the initial time restriction. As part of the replication the paper explores the differences in unit testing by students and professionals and investigates the impact of the extended time limit. The main findings are: There are no significant differences in the results produced by students and by professional developers when performing manual unit testing for 60 minutes. Furthermore, there is a non-linear increase in the number of defects found when the time limit is extended from one to two hours, which indicates the transition from the initial ramp-up phase to productive testing. The replication also confirms the conclusions of the original study: Automated test case generation can be equally efficient as manual unit testing under severe time restrictions and it may be used to complement a manual testing approach."
A study of bugs in test code and a test model for analyzing tests,['A Vahabzadeh Sefiddarbon'],,"Testing has become a wide-spread practice among practitioners. Test cases are written to verify that production code functions as expected and are modified alongside the production code. Over time the quality of the test code can degrade. The test code might contain bugs, or it can accumulate redundant test cases or very similar ones with many redundant parts. The work presented in this dissertation has focused on addressing these issues by characterizing bugs in test code, and proposing a test model to analyze test cases and support test reorganization. To characterize the prevalence and root causes of bugs in the test code, we mine the bug repositories and version control systems of 448 Apache Software Foundation projects. Our results show that around half of all the projects had bugs in their test code; the majority of test bugs are false alarms, i.e., test fails while the production code is correct, while a minority of these bugs result in silent horrors, i.e., test passes while the production code is incorrect; missing and incorrect assertions are the dominant root cause of silent horror bugs; semantic, flaky, environment related bugs are the dominant root cause categories of false alarms. We present a test model for analyzing tests and performing test reorganization tasks in test code. Redundancies increase the maintenance overhead of the test suite and increase the test execution time without increasing the test suite coverage and effectiveness. We propose a technique that uses our test model to reorganize test cases in a way that reduces the redundancy in the test suite. We implement our approach in a tool and evaluate it on four open-source softwares. Our empirical evaluation shows that our approach can reduce the number of redundant test cases up to 85% and the test execution time by up to 2.5% while preserving the test suite’s behaviour."
A systematic mapping study on higher order mutation testing,"['JA do Prado Lima', 'SR Vergilio']",,"Context: Higher Order Mutants (HOMs) present some advantages concerning the First-Order Mutants (FOMs). HOMs can better simulate real and subtle faults, reduce the number of generated mutants and test cases, and so on. Objective: In order to characterize the Higher Order Mutation Testing (HOMT) field, this paper presents results of a mapping study, by synthesizing characteristics of the HOMT approaches, HOM generation strategies, evaluation aspects, trends and research opportunities. Method: We followed a research plan to locate, assess, extract and group the outcomes from relevant studies. We found 69 primary studies, which were classified based on dimensions related to aspects of the conducted evaluation, purpose and use of HOMs. Results: Java is the preferred language. Most approaches use Second-Order Mutants (SOMs). We found 50 different techniques used to generate/select HOMs. We observed that from 39 primary studies which apply a strategy, ≈49% use search-based techniques. Conclusions: HOMT has been arising interest in the last years. The results herein presented provide researchers the start-of-the-art on HOMT, allowing them to understand existing approaches, and how the HOMs have been used and evaluated. Furthermore, this paper points out open issues and not addressed topics, which require more investigation, discussing trends and research opportunities in the field."
A systematic review of agent-based test case generation for regression testing,"['PK Arora', 'R Bhatia']",,"There is an urgent need to create awareness about the potential benefits of using agents in software test case generation and to identify the need to develop agent-based regression testing techniques and approaches. It may help in reducing time and cost required for testing. This study reports systematic literature review of existing test case generation approaches for regression testing and agent-based software testing systems. The emphasis is articulated on agent-based regression test case generation. Further research directions are recommended. In the systematic literature review, we framed three sets of research questions. Based on our inclusion and exclusion criteria, we identified 115 potential research papers on test case generation in regression testing and agent-based software testing. We explored journals, international conferences, workshops and identified 59 studies in test case generation for regression testing and 56 studies in agent-based software testing. The data extracted from our study are classified into seven broader areas of agent-based software testing. Based on our systematic literature survey, we recognized available techniques, approaches, platforms as well as methodologies for regression test case generation and developing agent-based software testing systems. This study will benefit the researchers to carry forward their work in the domain of regression test case generation and agent-based software testing. To cut down on schedule and cost, mobile agent-based software testing can be a promising alternative."
Access control policy coverage assessment through monitoring,"['A Calabrò', 'F Lonetti', 'E Marchetti']",,"Testing access control policies relies on their execution on a security engine and the evaluation of the correct responses. Coverage measures can be adopted to know which parts of the policy are most exercised. This paper proposes an access control infrastructure for enabling the coverage criterion selection, the monitoring of the policy execution and the analysis of the policy coverage assessment. The framework is independent from the policy specification language and does not require the instrumentation of the evaluation engine. We show an instantiation of the proposed infrastructure for assessing the XACML policy testing."
Achieving scalable mutation-based generation of whole test suites,"['G Fraser', 'A Arcuri']",,"Without complete formal specification, automatically generated software tests need to be manually checked in order to detect faults. This makes it desirable to produce the strongest possible test set while keeping the number of tests as small as possible. As commonly applied coverage criteria like branch coverage are potentially weak, mutation testing has been proposed as a stronger criterion. However, mutation based test generation is hampered because usually there are simply too many mutants, and too many of these are either trivially killed or equivalent. On such mutants, any effort spent on test generation would per definition be wasted. To overcome this problem, our search-based EvoSuite test generation tool integrates two novel optimizations: First, we avoid redundant test executions on mutants by monitoring state infection conditions, and second we use whole test suite generation to optimize test suites towards killing the highest number of mutants, rather than selecting individual mutants. These optimizations allowed us to apply EvoSuite to a random sample of 100 open source projects, consisting of a total of 8,963 classes and more than two million lines of code, leading to a total of 1,380,302 mutants. The experiment demonstrates that our approach scales well, making mutation testing a viable test criterion for automated test case generation tools, and allowing us to analyze the relationship of branch coverage and mutation testing in detail."
Adapting automated test generation to GUI testing of industry applications,"['R Ramler', 'G Buchgeher', 'C Klammer']",,"Context: Automated test generation promises to improve the effectiveness of software testing and to reduce the involved manual effort. While automated test generation has been successfully applied for code-level API testing, it has not found widespread adoption in practice for testing of graphical user interfaces. Tools for test generation do not support GUI testing out-of-the-box but require dedicated extensions. Objective: This paper explores the applicability of automated test generation for testing GUIs of industry applications. We propose a test adapter approach to bridge the gap between automated test generation tools and industry applications. Method: A multiple case study was conducted in which automated test generation with test adapters has been applied at the unit, integration, and system test level in three industry projects from two different companies. Results: Automated test generation via test adapters could be applied at all test levels. It has led to an increase of coverage as well as the detection of new defects that were not found by preceding testing activities in the projects. While test adapters can easily be implemented at the unit test level, their complexity and the corresponding effort for providing adapter implementations rises at higher test levels. Conclusion: Test adapters can be used for applying automated test generation for testing GUIs of industry applications. They bridge the gap between automated test generation tools and industry applications. The development of test adapters requires no tool-specific knowledge and can be performed by members of the development team."
Adaptive test-case prioritization guided by output inspection,"['D Hao', 'X Zhao', 'L Zhang']",,"Test-case prioritization is to schedule the execution order of test cases so as to maximize some objective (e.g., revealing faults early). The existing test-case prioritization approaches separate the process of test-case prioritization and the process of test-case execution by presenting the execution order of all test cases before programmers start running test cases. As the execution information of the modified program is not available for the existing test-case prioritization approaches, these approaches mainly rely on only the execution information of the previous program before modification. To address this problem, we present an adaptive test-case prioritization approach, which determines the execution order of test cases simultaneously during the execution of test cases. In particular, the adaptive approach selects test cases based on their fault-detection capability, which is calculated based on the output of selected test cases. As soon as a test case is selected and runs, the fault-detection capability of each unselected test case is modified according to the output of the latest selected test case. To evaluate the effectiveness of the proposed adaptive approach, we conducted an experimental study on eight C programs and four Java programs. The experimental results show that the adaptive approach is usually significantly better than the total test-case prioritization approach and competitive to the additional test-case prioritization approach. Moreover, the adaptive approach is better than the additional approach on some subjects (e.g, replace and schedule)."
An approach for the generation of higher order mutants using genetic algorithms,"['A Abuljadayel', 'F Wedyan']",,"Mutation testing is a structural testing technique in which the effectiveness of a test suite is measured by the suite ability to detect seeded faults. One fault is seeded into a copy of the program, called mutant, leading to a large number of mutants with a high cost of compiling and running the test suite against the mutants. Moreover, many of the mutants produce the same output as the original program (called equivalent mutants), such mutants need to be minimized to produce accurate results. Higher order mutation testing aims at solving these problems by allowing more than one fault to be seeded in the mutant. Recent work in higher order mutation show promising result in reducing the cost of mutation testing and increasing the approach effectiveness. In this paper, we present an approach for generating higher order mutants using a genetic algorithm. The aim of the proposed approach is to produce subtle and harder to kill mutants, and reduce the percentage of produced equivalent mutants. A Java tool has been developed, called HOMJava (Higher Order Mutation for Java), which implements the proposed approach. An experimental study was performed to evaluate the effectiveness of the proposed approach. The results show that the approach was able to produce subtle higher order mutants, the fitness of mutants improved by almost 99% compared with the first order mutants used in the experiment. The percentage of produced equivalent mutants was about 4%."
An automated framework for continuous development and testing of access control systems,"['S Daoudagh', 'F Lonetti']",,"Automated testing in DevOps represents a key factor for providing fast release of new software features assuring quality delivery. In this paper, we introduce DOXAT, an automated framework for continuous development and testing of access control mechanisms based on the XACML standard. It leverages mutation analysis for the selection and assessment of the test strategies and provides automated facilities for test oracle definition, test execution, and results analysis, in order to speedup and automate the Plan, Code, Build, and Test phases of DevOps process. We show the usage of the framework during the planning and testing phases of the software development cycle of a PDP example."
An empirical study on the application of mutation testing for a safety-critical industrial software system,"['R Ramler', 'T Wetzlmaier', 'C Klammer']",,"Background: Testing is an essential activity in safety-critical software development, following high standards in terms of code coverage. Mutation testing allows assessing the effectiveness of testing and helps to further improve test cases. However, mutation testing is not widely practiced due to scalability problems when applied to real-world systems. Objective: The objective of the study is to investigate the applicability and usefulness of mutation testing for improving the quality of unit testing in context of safety-critical software systems. Method: A case study has been conducted together with an engineering company developing safety-critical systems. Mutation analysis has been applied to the studied system under test (60,000 LOC of C code) producing 75,043 mutants of which 27,158 survived test execution. A sample of 200 live mutants has been reviewed by the engineers, who also improved the existing unit test suite based on their findings. Findings: The reviewed sample contained 24+ equivalent mutants and 12+ duplicated mutants. It revealed a weak spot in the testing approach and provided valuable guidance to improve the existing unit test suite. Two new faults were found in the code when improving the tests. Test execution against the mutants required over 4,000 hours computing time. The overall effort was about half a person year."
An experimental assessment of module documentation-based testing,"['S Baharom', 'Z Shukur']",,"Context: Testing a module that has memory using the black-box approach has been found to be expensive and relatively ineffective. Instead, testing without knowledge of the specifications (white-box approach) may not be effective in showing whether a program has been properly implemented as stated in its specifications. We propose instead a grey-box approach called Module Documentation-based Testing or MD-Test, the heart of which is an automatic generation of the test oracle from the external and internal views of the module. Objective: This paper presents an empirical analysis and comparison of MD-Test against three existing testing tools. Method: The experiment was conducted using a mutation-testing approach, in two phases that assess the capability of MD-Test in general and its capability of evaluating test results in particular. Results: The results of the general assessment indicate that MD-Test is more effective than the other three tools under comparison, where it is able to detect all faults. The second phase of the experiment, which is significant to this study, compares the capabilities of MD-Test and JUnit-black using the test evaluation results. Likewise, an analysis of the test evaluation results shows that MD-Test is more effective and efficient, where MD-Test is able to detect at least the same number of faults as, or is at par with, the black-box approach. Conclusion: It is concluded that test evaluation using grey-box approach is more effective and efficient that the black-box approach when testing a module that has memory."
Analysing the combination of cost reduction techniques in Android mutation testing,['M Polo‐Usaola'],,"When applied to mobile software, mutation testing is particularly costly due to the deployment of the app under test onto the device: if one deployment is made for each generated mutant, the execution time becomes unapproachable. This paper analyses how the combination of different cost reduction techniques improves the execution time of mutation testing in mobile apps. The techniques reviewed and combined are mutant schema, parallel execution and two different ways of executing tests against the mutants (all against all and all against mutants remaining alive), as well as greedy algorithm for reducing the test suite size. This paper also presents a mathematical model of cost reduction and checks its validity with several experiments. Furthermore, the exhaustive and long experimentation has led the authors to compile a set of good practices which are also presented in a set of lessons learned."
Applying automated test case generation in industry: a retrospective,"['R Ramler', 'C Klammer']",,"Automated test case generation promises to reduce the high effort of manually developing and maintaining test cases, to improve the effectiveness of testing, and to speed-up testing cycles. Research on generating test cases has advanced over the past decades and today a wide range of techniques and tools are available, including studies showing their successful evaluation in real-world scenarios. We conducted a multi-firm research project on automated software testing that involved the application of automated test case generation approaches in industry projects. This paper provides a retrospective on the related activities. It reports on our observations and insights from applying automated test case generation in practice, identifies pitfalls and gaps in current research, and summarizes lessons learned from transferring software testing research results to industry."
Applying selective mutation strategies to the AsmetaL language,"['O Alkrarha', 'J Hassine']",,"Abstract state machines (ASMs) have been introduced as a computation model that is more powerful and more universal than standard computation models. The early validation of ASM models would help reduce the cost and risk of having defects propagate, through refinement, to other models, and eventually to code; thus, adversely affecting the quality of the end product. Mutation testing is a well-established fault-based technique for assessing and improving the quality of test suites. However, little research has been devoted to mutation analysis in the context of ASMs. Mutation testing is known to be computationally expensive due to the large number of generated mutants that are executed against a test set. In this study, the authors empirically investigate the application of cost reduction strategies to AsmetaL, an ASM-based formal language. Furthermore, they evaluate experimentally the effectiveness and the savings resulting from applying two techniques: namely, random mutants selection and operator-based selective mutation, in the context of the AsmetaL language. The quantitative results show that both techniques achieved good savings without major impact on effectiveness."
Arbitcheck: A highly automated property-based testing tool for java,"['K Yatoh', 'K Sakamoto', 'F Ishikawa']",,"Lightweight property-based testing tools are becoming popular these days. With property-based testing, developers can test properties of the system under test against large varieties of randomly generated inputs without writing test cases. Despite the advantages of property-based testing, current property-based testing tools have a major drawback: they require developers to write generator functions for user-defined types. This is because it is difficult for a tool to infer the possible values for the type. However, user-defined generators sometimes fail to find faults by only producing overly limited varieties of values. In this paper, we present a new property-based testing tool, called ArbitCheck, which automates object generation by adapting the feedback-directed random test generation technique. With the help of feedback-directed random test generation, ArbitCheck exhaustively generates possible values of user-defined types and tests properties with them, so that it can reveal faults that are hard to find with either manually written tests or existing property-based testing tools."
"Are mutants really natural? a study on how"" naturalness"" helps mutant selection","['M Jimenez', 'TT Checkam', 'M Cordy']",,"Background: Code is repetitive and predictable in a way that is similar to the natural language. This means that code is 'natural' and this 'naturalness' can be captured by natural language modelling techniques. Such models promise to capture the program semantics and identify source code parts that `smell', i.e., they are strange, badly written and are generally error-prone (likely to be defective). Aims: We investigate the use of natural language modelling techniques in mutation testing (a testing technique that uses artificial faults). We thus, seek to identify how well artificial faults simulate real ones and ultimately understand how natural the artificial faults can be. Our intuition is that natural mutants, i.e., mutants that are predictable (follow the implicit coding norms of developers), are semantically useful and generally valuable (to testers). We also expect that mutants located on unnatural code locations (which are generally linked with error-proneness) to be of higher value than those located on natural code locations. Method: Based on this idea, we propose mutant selection strategies that rank mutants according to a) their naturalness (naturalness of the mutated code), b) the naturalness of their locations (naturalness of the original program statements) and c) their impact on the naturalness of the code that they apply to (naturalness differences between original and mutated statements). We empirically evaluate these issues on a benchmark set of 5 open-source projects, involving more than 100k mutants and 230 real faults. Based on the fault set we estimate the utility (i.e. capability to reveal faults) of mutants selected on the basis of their naturalness, and compare it against the utility of randomly selected mutants. Results: Our analysis shows that there is no link between naturalness and the fault revelation utility of mutants. We also demonstrate that the naturalness-based mutant selection performs similar (slightly worse) to the random mutant selection. Conclusions: Our findings are negative but we consider them interesting as they confute a strong intuition, i.e., fault revelation is independent of the mutants' naturalness."
Assessing the applicability of a combinatorial testing tool within an industrial environment,"['PM Kruse', 'O Shehory', 'D Citron']",,"This paper describes a case study executed to evaluate a combinatorial test design approach within the industrial setting of IBM Research. An existing combinatorial test suite was compared against a prioritized combinatorial test suite that was generated with the Combinatorial Tree Editor XL Profesional (CTE). The prioritization technique was recently developed and added to the CTE in the context of the FITTEST project. Test design for the new test suite was carried out by the developers of the prioritization technique. Test implementation and execution was done by the industrial partner of the System Under Test. This case study has investigated whether the prioritized combinatorial technique is useful to complement current testing practices at IBM Research. The focus of this study is on fault finding capability of artificially injected faults that have been selected and prioritized using domain knowledge and expertise, and efficiency of test case execution. Conclusions of this study are that for the testing of the target product in a simulated environment, the improved combinatorial testing tools do qualify as useful and this type of testing will be included in current practices."
Auto test generator: a framework to generate test cases from requirements in natural language,['TML PINA'],,"Testing is essential in the software engineering development process. However, it is also one of the most costly tasks. Thus, test automation has become the goal of many researches. Since design, implementation, and execution phases depend substantially on the system requirements, it is of the utmost importance that requirements text is standardized and clear. However, most companies use free natural language to write these documents, which entails the phenomenon of (lexical and structural) ambiguity, giving rise to different interpretations. An option to mitigate this problem is via the use of a Controlled Natural Language (CNL), aiming at standardization and accuracy of texts. A CNL is a subset of a natural language that uses a restrict lexicon to a particular domain, and follow grammatical rules which guide the elaboration of sentences, thus reducing ambiguity and allowing mechanized processing, like the automatic generation of test cases from CNL requirements. This work, in the software testing area, presents the Auto Test Generator (ATG), a tool to assist the writing of requirements and the automatic generation of test cases written in English, which are then automatically translated in test scripts using an automation framework. From a requirement written in CNL, the ATG creates a Use Case (UC). Due to the standardization of the language, it is possible to perform a consistency and dependency analysis, for each UC step, through a graph of associations (dependencies and cancellations) between test actions. Test cases are generated automatically in a transparent way from UCs to the user. ATG was developed and evaluated in partnership with Motorola Mobility. Experimental evaluations were performed. From the seven requirements analyzed, it was possible to create 34 test cases in total. The generated test cases resulted in 151 steps, which were passed to the Zygon (a proprietary automated tool for testing) in order to be automated. As a result, 131 test steps were correctly automated (86% of the total given as input)."
Automated test generation for multi-state systems,"['P Reales Mateo', 'M Polo Usaola']",,"This paper describes a genetic algorithm based on mutation testing to generate test cases for classes with multiple states. The fitness function is based on the coverability and the killability of the individuals. The paper includes a small empirical section that shows evidences of the ability of the algorithm to generate good test cases."
"Automated test oracles: State of the art, taxonomies, and trends","['RAP Oliveira', 'U Kanewala', 'PA Nardi']",,"Test oracle methods have changed significantly over time, which has resulted in clear shifts in the research literature. Over the years, the testing techniques, strategies, and criteria utilized by researchers went through technical developments due to the improvement of technologies and programming languages. Software testing designers, known as testers, currently have several resources to increase their confidence in the software under test correctness. All of these software testing resources are supposed to include a mechanism to decide whether a particular execution is considered a failure or not. In software testing environments, this decision is the responsibility of the test oracle. Despite the evolution and adaptation of testing techniques over more than 30 years, test oracles remain a particular and relevant issue. In this chapter, using literary evidence from a pool of about 300 studies directly related to test oracles, we present a classification of test oracles based on a taxonomy that considers their source of information and notations. Based on this classification, we perform a quantitative analysis to highlight the shifts in (evolution of) research on test oracles. Exploring geographical and quantitative information, we analyzed the maturity of this field using coauthorship networks among studies published between 1978 and 2013. Further, we determine the most prolific authors and their countries, main conferences and journals, supporting tools, and academic efforts and use a comparative analysis between academia and industry. Finally, from these analyses, we draw an analytic reflection about contemporary test oracle approaches and a criticism about oracle trends."
Automatic test case evolution,"['M Mirzaaghaei', 'F Pastore']",,"Software systems evolve incrementally both during and after development, and many test cases become obsolete while software evolves. Updating test suites in the context of software evolution is a complex and time consuming activity. This article focuses on the problem of updating test suites automatically, and identifies eight scenarios that allow either to repair test cases or to use test cases to generate new ones, and proposes eight test evolution algorithms that automatically repair and generate test cases by adapting existing ones. This article presents a framework, TestCareAssistant (TCA), that implements the algorithms to support the evolution of test suites written in Java. The framework has been extensively evaluated on five different open source projects where it has been applied to repair 138 broken test cases, and to generate the test cases for 727 new classes and 2462 new methods. The results obtained with TCA indicate that the approach can successfully repair 90% of the broken test cases, create test cases that cover a large amount of code and complement the test cases that can be generated by state of the art techniques."
Automatic test suite evolution,['M Mirzaaghaei'],,"Software evolves continuously, and developers need to retest it frequently. To save time and effort, developers often reuse existing test cases to verify the functionality of software systems after changes, but they often need to adapt or augment the test cases to match the new characteristics of the software systems. Adapting test cases is tedious and expensive. Current automated techniques often generate invalid and incomplete test cases, and require manual inspection and correction of the generated test cases. My research aims to introduce new automated approaches for evolving and generating test cases, to keep them aligned with the corresponding software evolution. The new approach is based on the observation that software developers follow common patterns to identify changes and adapt test cases. I experimentally identified patterns that developers use in presence of specific changes, and I am working on an automated approach that generalizes these patterns into a set of test adaptation patterns that can automatically evolve existing test cases and generate new ones. My preliminary evaluation shows the applicability and effectiveness of the approach."
Automatically generating complex test cases from simple ones,['K Rubinov'],,"While source code expresses and implements design considerations for software system, test cases capture and represent the domain knowledge of software developer, her assumptions on the implicit and explicit interaction protocols in the system, and the expected behavior of different modules of the system in normal and exceptional conditions. Moreover, test cases capture information about the environment and the data the system operates on. As such, together with the system source code, test cases integrate important system and domain knowledge. Besides being an important project artifact, test cases embody up to the half the overall software development cost and effort. Software projects produce many test cases of different kind and granularity to thoroughly check the system functionality, aiming to prevent, detect, and remove different types of faults. Simple test cases exercise small parts of the system aiming to detect faults in single modules. More complex integration and system test cases exercise larger parts of the system aiming to detect problems in module interactions and verify the functionality of the system as a whole. Not surprisingly, the test case complexity comes at a cost -- developing complex test cases is a laborious and expensive task that is hard to automate. Our intuition is that important information that is naturally present in test cases can be reused to reduce the effort in generation of new test cases. This thesis develops this intuition and investigates the phenomenon of information reuse among test cases. We first empirically investigated many test cases from real software projects and demonstrated that test cases of different granularity indeed share code fragments and build upon each other. Then we proposed an approach for automatically generating complex test cases by extracting and exploiting information in existing simple ones. In particular, our approach automatically generates integration test cases from unit ones. We implemented our approach in a prototype to evaluate its ability to generate new and useful test cases for real software systems. Our studies show that test cases generated with our approach reveal new interaction faults even in well tested applications. We evaluated the effectiveness of our approach by comparing it with the state of the art test generation techniques. The evaluation results show that our approach is effective, it finds relevant faults differently from other approaches that tend to find different and usually less relevant faults."
Automatically generating test templates from test names (n),"['B Zhang', 'E Hill', 'J Clause']",,"Existing specification-based testing techniques require specifications that either do not exist or are too difficult to create. As a result, they often fall short of their goal of helping developers test expected behaviors. In this paper we present a novel, natural language-based approach that exploits the descriptive nature of test names to generate test templates. Similar to how modern IDEs simplify development by providing templates for common constructs such as loops, test templates can save time and lower the cognitive barrier for writing tests. The results of our evaluation show that the approach is feasible: despite the difficulty of the task, when test names contain a sufficient amount of information, the approach's accuracy is over 80% when parsing the relevant information from the test name and generating the template."
Avaliação da ferramenta de testes Selenium no desenvolvimento guiado por teste de uma aplicação web,['RP Santori'],x (not English),
Binary mutation analysis of tests using reassembleable disassembly,"['N Emamdoost', 'V Sharma', 'T Byun']",,"Good tests are important in software development, but it can be hard to tell whether tests will reveal future faults that are themselves unknown. Mutation analysis, which checks whether tests reveal inserted changes in a program, is a strong measure of test suite adequacy, but common source- or compiler-level approaches to mutation testing are not applicable to software available only in binary form. We explore mutation analysis as an application of the reassembleable disassembly approach to binary rewriting, building a tool for x86 binaries on top of the previously-developed Uroboros system, and apply it to the C benchmarks from SPEC CPU 2006 and to five examples of embedded control software. The results demonstrate that our approach works effectively across these software domains: as expected, tests designed for performance benchmarking reveal fewer mutants than tests generated to achieve high code coverage, but mutation scores indicate differences in test origins and features such as code size and fault-tolerance. Our binary-level tool also achieves comparable results to source-level mutation analysis despite supporting a more limited set of mutation operators. More generally we also argue that our experience shows how reassembleable disassembly is a valuable approach for constructing novel binary rewriting tools."
Building a test suite for web application scanners,"['E Fong', 'R Gaucher', 'V Okun', 'PE Black']",,"This paper describes the design of a test suite for thorough evaluation of web application scanners. Web application scanners are automated, black-box testing tools that examine web applications for security vulnerabilities. For several common vulnerability types, we classify defense mechanisms that can be implemented to prevent corresponding attacks. We combine the defense mechanisms into 'levels of defense' of increasing strength. This approach allows us to develop an extensive test suite that can be easily configured to switch on and off vulnerability types and select a level of defense. We evaluate the test suite experimentally using several web application scanners, both open-source and proprietary. The experiments suggest that the test suite is effective at distinguishing the tools based on their vulnerability detection rate; in addition, its use can suggest areas for tool improvement."
CCmutator: A mutation generator for concurrency constructs in multithreaded C/C++ applications,"['M Kusano', 'C Wang']",,"We introduce CCmutator, a mutation generation tool for multithreaded C/C++ programs written using POSIX threads and the recently standardized C++11 concurrency constructs. CCmutator is capable of performing partial mutations and generating higher order mutants, which allow for more focused and complex combinations of elementary mutation operators leading to higher quality mutants. We have implemented CCmutator based on the popular Clang/LLVM compiler framework, which allows CCmutator to be extremely scalable and robust in handling real-world C/C++ applications. CCmutator is also designed in such a way that all mutants of the same order can be generated in parallel, which allows the tool to be easily parallelized on commodity multicore hardware to improve performance."
Challenges of aligning requirements engineering and system testing in large-scale agile: A multiple case study,"['FGDO Neto', 'J Horkoff', 'E Knauss']",,"As agile methods become more pervasive, agile practices are applied to more large-scale systems with a scope that goes beyond pure software. The expansion of agile in these contexts provides benefits, but creates new challenges. Widespread use of agile has changed the way we must think about practices both in Requirements Engineering (RE) and in System Testing (ST). Our experience shows that many challenges in the application of large-scale agile development relate to either RE or ST, and in particular to the alignment between these areas. In this paper we present large-scale agile-related challenges from a multiple case study which relate to REST alignment. We map our challenges to an existing framework for REST alignment, and make an initial attempt to suggest agile RE practices from the literature which may alleviate these challenges. Our results show that the interviewed companies need to first adopt more agile RE practices to enhance REST alignment and then leverage agile testing. Future work will look more towards evaluating these best practices."
Combining bug detection and test case generation,['M Kellogg'],,"Detecting bugs in software is an important software engineering activity. Static bug finding tools can assist in detecting bugs automatically, but they suffer from high false positive rates. Automatic test generation tools can generate test cases which can find bugs, but they suffer from an oracle problem. We present N-Prog, a hybrid of the two approaches. N-Prog iteratively presents the developer an interesting, real input/output pair. The developer either classifies it as a bug (when the output is incorrect) or adds it to the regression test suite (when the output is correct). N-Prog selects input/output pairs whose input produces different output on a mutated version of the program which passes the test suite of the original. In initial experiments, N-Prog detected bugs and rediscovered test cases that had been removed from a test suite."
Conceptual approach for reuse of test automation artifacts on various architectural levels,"['D Almog', 'SH Chassidim', 'Y Tsubery']",,"When creating a test automation infrastructure, one of the main considerations for the buildup process is its efficiency. A main cause and method for improvement might come from reuse of test automation artifacts. Following that, one may ask “To what extent can the test automation artifacts be re-used?”. In this paper we present a model and test automation architecture for achieving such a goal. Repository Driven Test Automation (RDTA) is a conceptual approach for the buildup process of test automation infrastructure that employs reuse of testing artifacts. This paper discusses aspects of reuse of software test automation artifacts on various levels. Then, practical implications and adjustments arising from the implementation of this new paradigm are discussed. The proposed concept is documented by a case study in an international innovative computer hardware manufacturer, one of leaders in the market. The documented results are significant and confirm the validity of the concept."
Concrete hyperheuristic framework for test case prioritization,"['Y Bian', 'Z Li', 'J Guo', 'R Zhao']",,"Test case prioritization (TCP), which aims to find the optimal test case execution sequences for specific testing objects, has been widely used in regression testing. A wide variety of search methodologies and algorithms have been proposed to optimize test case execution sequences, namely, search-based TCP. However, different algorithms perform differently and have different implementation costs and specific situations where an algorithm usually performs with high effectiveness and efficiency. When facing a new testing scenario, it is actually difficult to decide which algorithm is suitable. In this paper, to address the algorithm selection problem for different test scenarios, a more generally applicable algorithm based on a hyperheuristic strategy is proposed for search-based TCP. This includes a range of multiobjective algorithms with a variety of crossover strategies and a learning agent strategy to evaluate and select the appropriate algorithm execution sequence dynamically for different scenarios. The concrete hyperheuristic framework for multiobjective TCP is presented with an algorithm's repository in the low level and the learning agent strategy in the higher level. Experiments show that the proposed learning agent strategy can accurately evaluate algorithms in multiobjective problems and select the appropriate algorithm in each iteration."
Context-aware test case adaptation,['P Sun'],,"During software evolution, both production code and test cases evolve frequently. To assure software quality, test cases should evolve in time. However, test case evolution is usually delayed and error-prone. To facilitate this process, this paper proposes a context-aware test case adaptation approach (CAT), which first identifies and generalizes test case adaptation patterns, and then applies these patterns to automatically evolve test cases by analyzing their context. We conducted a preliminary study on three open-source projects and found that CAT correctly adapts 71.91% of test cases."
Continuous development and testing of access and usage control: a systematic literature review,"['S Daoudagh', 'F Lonetti', 'E Marchetti']",,"Context: Development and testing of access/usage control systems is a growing research area. With new trends in software development such as DevOps, the development of access/usage control also has to evolve. Objective: The main aim of this paper is to provide an overview of research proposals in the area of continuous development and testing of access and usage control systems. Method: The paper uses a Systematic Literature Review as a research method to define the research questions and answer them following a systematic approach. With the specified search string, 210 studies were retrieved. After applying the inclusion and exclusion criteria in two phases, a final set of 20 primary studies was selected for this review. Results: Results show that primary studies are mostly published in security venues followed by software engineering venues. Furthermore, most of the studies are based on the standard XACML access control language. In addition, a significant portion of the proposals for development and testing is automated with test assessment and generation the most targeted areas. Some general guidelines for leveraging continuous developing and testing of the usage and access control systems inside the DevOps process are also provided."
Contribuições ao suporte cognitivo em teste de software unitário: um framework de tarefas e uma agenda de pesquisa,['MP Prado'],x (not English),
Criterios basados en abstracciones de comportamiento para testing de conformidad de protocolos,['H Czemerinski'],x (not English),
Dependent-test-aware regression testing techniques,"['W Lam', 'A Shi', 'R Oei', 'S Zhang', 'MD Ernst']",,"Developers typically rely on regression testing techniques to ensure that their changes do not break existing functionality. Unfortunately, these techniques suffer from flaky tests, which can both pass and fail when run multiple times on the same version of code and tests. One prominent type of flaky tests is order-dependent (OD) tests, which are tests that pass when run in one order but fail when run in another order. Although OD tests may cause flaky-test failures, OD tests can help developers run their tests faster by allowing them to share resources. We propose to make regression testing techniques dependent-test-aware to reduce flaky-test failures. To understand the necessity of dependent-test-aware regression testing techniques, we conduct the first study on the impact of OD tests on three regression testing techniques: test prioritization, test selection, and test parallelization. In particular, we implement 4 test prioritization, 6 test selection, and 2 test parallelization algorithms, and we evaluate them on 11 Java modules with OD tests. When we run the orders produced by the traditional, dependent-test-unaware regression testing algorithms, 82% of human-written test suites and 100% of automatically-generated test suites with OD tests have at least one flaky-test failure. We develop a general approach for enhancing regression testing algorithms to make them dependent-test-aware, and apply our approach to 12 algorithms. Compared to traditional, unenhanced regression testing algorithms, the enhanced algorithms use provided test dependencies to produce orders with different permutations or extra tests. Our evaluation shows that, in comparison to the orders produced by unenhanced algorithms, the orders produced by enhanced algorithms (1) have overall 80% fewer flaky-test failures due to OD tests, and (2) may add extra tests but run only 1% slower on average. Our results suggest that enhancing regression testing algorithms to be dependent-test-aware can substantially reduce flaky-test failures with only a minor slowdown to run the tests."
"Distributed systems, discrete-event simulation, test adequacy criteria, fault-based analysis.","['MJ Rutherford', 'A Carzaniga', 'AL Wolf']",x (not found),
Dynamic analysis of shared execution in software product line testing,['B Wang'],,"Software product line (SPL), a family-based software development process, has proven to be a more effective technology than single software systems. Testing SPL products individually is redundant for product lines testing. Meanwhile, the complexity of systematically testing SPL programs is combinatorial, which limits the scalability of testing SPL. In this paper, I will introduce the idea of accelerating SPL testing by dynamic analysis. I intend to investigate a dynamic analysis of SPL testing, which analyzes all variants during the execution of a SPL, and forks the execution only a variant leads to a different state. In addition, to get the preliminary result, we can encode a family of variants into a single program to simulate a realization of SPL testing. The experimental result collected on the mutated C program, printtokens in Software-artifact Infrastructure Repository, shows our approach can accelerate the SPL testing with a speedup up to 4.83X than testing each variants at a time and pruning 87% of the variants."
Efficient mutation testing in configurable systems,"['M Al-Hajjaji', 'J Krüger', 'F Benduhn']",,"Mutation testing is a technique to evaluate the quality of test cases by assessing their ability to detect faults. Mutants are modified versions of the original program that are generated automatically and should contain faults similar to those caused by developers' mistakes. For configurable systems, existing approaches propose mutation operators to produce faults that may only exist in some configurations. However, due to the number of possible configurations, generating and testing all mutants for each program is not feasible. To tackle this problem, we discuss to use static analysis and adopt the idea of T-wise testing to limit the number of mutants. In particular, we i) discuss dependencies that exist in configurable systems, ii) how we can use them to identify code to mutate, and iii) assess the expected outcome. Our preliminary results show that variability analysis can help to reduce the number of mutants and, thus, costs for testing."
Empirically revisiting the test independence assumption,"['S Zhang', 'D Jalali', 'J Wuttke', 'K Muşlu', 'W Lam']",,"In a test suite, all the test cases should be independent: no test should affect any other test’s result, and running the tests in any order should produce the same test results. Techniques such as test prioritization generally assume that the tests in a suite are independent. Test dependence is a little-studied phenomenon. This paper presents five results related to test dependence. First, we characterize the test dependence that arises in practice. We studied 96 real-world dependent tests from 5 issue tracking systems. Our study shows that test dependence can be hard for programmers to identify. It also shows that test dependence can cause non-trivial consequences, such as masking program faults and leading to spurious bug reports. Second, we formally define test dependence in terms of test suites as ordered sequences of tests along with explicit environments in which these tests are executed. We formulate the problem of detecting dependent tests and prove that a useful special case is NP-complete. Third, guided by the study of real-world dependent tests, we propose and compare four algorithms to detect dependent tests in a test suite. Fourth, we applied our dependent test detection algorithms to 4 real-world programs and found dependent tests in each human-written and automatically-generated test suite. Fifth, we empirically assessed the impact of dependent tests on five test prioritization techniques. Dependent tests affect the output of all five techniques; that is, the reordered suite fails even though the original suite did not."
Enabling test case prioritization for component based software development,"['S Ali', 'Y Hafeez']",,"Frequent evolution of modern software systems increases complexity and system failure. Therefore, to overcome these issues the component-based system was developed that consists of integrated reuse components that work together to perform specific tasks or new application development. Mostly component based systems use configuration capabilities to adopt the changes and external uncertainties. Quality of these systems can be assessed through customer satisfaction after modification to verify the performance during maintenance activities. Software engineers for high-reliability, overall requirements functionality needs to verify before release of new product. One of the common ways to evaluate system quality in a sequence of releases is regression testing. Software quality engineers use to ensure that no faults introduced after changes. The purpose of this research work to identify the limitations in existing studies that create complexity and increase efforts during testing component based software and eliminate those factors through the proposed approach. The mixed research methodology will be followed in this context comprising qualitative and quantitative methods. To investigate the potential benefits of the proposed approach; will be performed a case study and experiment. Preliminary results indicated that the proposed approach significantly improve faults detection rate after changes alongwith less effort and cost in component based system development."
Enabling test case selection of automatically generated unit tests through traceability: An empirical study,"['M Jobe', 'M Mahboob']",,"Anticipating the effects of changes/modifications to source code, is a difficult if not an impossible process, unless the right tools or methods are applied. One way of handling change impact analysis is through test case selection which can cut down the testing time, as it only selects and runs the tests that have been affected by a change. In order to realize this, the method of traceability is applied on source code and automatically generated unit tests. This approach aims at facilitating software maintenance by cutting down the time and the effort required to re-validate changes. This paper investigates the impact of traceability with the intention of evaluating the effects on debugging time and mutation kill score. By conducting an experiment with 8 subjects, the results showed that no major statistical differences were found, which is likely to change with a larger sample size. Nonetheless, to generalize the impact of traceability between code and automated unit tests, further research is required, however the paper provides insights and deeper understanding of the problem as well a guideline for future studies."
"Engineering of Software Test-Code: Developing, verifying and maintaining high-quality automated test scripts","['V Garousi', 'M Felderer']",x (no Abstract),
Enhanced optimizer algorithm and its application to software testing,"['SN Fakhouri', 'A Hudaib', 'HN Fakhouri']",,"Optimisation algorithm is currently one of the most applicable techniques to solve real-world problems by finding the best solution from all feasible solutions in the search space. This paper proposes enhanced multiverse optimiser algorithm that is inspired from the physics multiverse theory. The proposed algorithm suggests an enhancement of multiverse optimiser algorithm . It enhances the performance of multiverse optimiser to find the global minimal value among search space and solve the problems in the multiverse optimiser algorithm. In order to confirm the performance of the suggested algorithm, it has been benchmarked with benchmark functions challenging optimisation problems. The proposed algorithm is compared with state-of-the-art optimisation algorithm to confirm its performance; it is being compared with particle swarm optimisation, sine cosine algorithm, grey wolf optimiser, moth-flame optimisation and multiverse optimiser. Also, the algorithm is applied on software testing and test data generation, the results of the benchmarked functions and the test data generation proves that the proposed algorithm is able to provide very competitive results and outperforms other compared algorithms over the tested cases."
Enhanced regression testing technique for agile software development and continuous integration strategies,"['S Ali', 'Y Hafeez', 'S Hussain', 'S Yang']",,"To survive in competitive marketplaces, most organizations have adopted agile methodologies to facilitate continuous integration and faster application delivery and rely on regression testing during application development to validate the quality and reliability of the software after changes have been made. Consequently, for large projects with cost and time constraints, it is extremely difficult to determine which test cases to run at the end of each release. In this paper, a test case prioritization and selection approach is proposed to improve the quality of releases. From existing literature, we analyzed prevailing problems and proposed solution relevant to regression testing in agile practices. The proposed approach is based on two phases. First, test cases are prioritized by clustering those test cases that frequently change. In case of a tie, test cases are prioritized based on their respective failure frequencies and coverage criteria. Second, test cases with a higher frequency of failure or coverage criteria are selected. The proposed technique was validated by an empirical study on three industrial subjects. The results show that the method successfully selects an optimal test suite and increases the fault detection rate (i.e., more than 90% in the case of proposed technique and less than 50% in other techniques), which reduces the number of irrelevant test cases and avoids detecting duplicate faults. The results of evaluation metrics illustrate that the proposed technique significantly outperform (i.e., between 91 and 97%) as compared to other existing regression testing techniques (i.e., between 52 and 68%). Therefore, our model enhances the test case prioritization and selection with the ability for earlier and high fault detection. Thus, pruning out irrelevant test cases and redundant faults and enhancing the regression testing process for agile applications."
Equivalent mutants in configurable systems: An empirical study,"['L Carvalho', 'MA Guimarães', 'M Ribeiro']",,"Mutation testing is a program-transformation technique that evaluates the quality of test cases by assessing their capability to detect injected artificial faults. The costs of using mutation testing are usually high, hindering its use in industry. Previous research has reported that roughly one-third of the mutants generated in single systems are equivalents. In configurable systems, a set of mutation operators that focus on preprocessor directives (e.g., #ifdef) has been proposed. However, there is a lack of existing studies that investigate whether equivalent mutants do occur with these operators. To perform this investigation, we provide a tool that implements the aforementioned mutation operators and we conduct an empirical study using 20 C files of four industrial-scale systems. In particular, we provide examples of equivalent mutants and detailed information, such as which mutation operators generate these mutants and how often they occur. Our preliminary results show that nearly 40% of the generated mutants are equivalent. Hence, testing costs can be drastically reduced if the community comes up with efficient techniques to avoid these equivalent mutants."
Erkennung von semantisch zusammenhängenden Quelltextabschnitten anhand von Komponententests,['M Wittlinger'],,"Die Rückverfolgbarkeit von Quelltext zu Anforderungen ist ein wichtiger werdendes Problem. Eine Garantie der Implementierung aller Anforderungen kann zur Steigerung von Softwarequalität führen. Für das Erstellen der Rückverfolgbarkeitsinformationen ist ein Verständnis des Quelltextes nötig. In dieser Arbeit wurden anhand von Komponententests semantisch zusammenhängende Methoden erkannt. Semantisch zusammenhängende Methoden erfülen eine Funktionalität miteinander und verbessern das Verständnis von Quelltext. Für die Erkennung wurde ein heuristisches Verfahren entwickelt, welches aus mehreren Teilverfahren besteht, die sowohl auf den textuellen als auch den strukturellen Bestandteilen des Komponententest- und Quelltextes arbeiten. Für die Teilverfahren wurde eine Zerteilung und Transformation von Quelltext entwickelt. Es wurden verschiedene Textähnlichkeitsalgorithmen mit einem maschinellen Lernverfahren (fastTex) verglichen. Zur Bewertung wurden drei Softwareprojekte verwendet, mit einer höchsten Präzision von 74 %, bei einer Ausbeute von 19%. Mit einer anderen Parameterkonfiguration wurde ein F1-Wert von 46 % erreicht."
Evaluating different strategies for reduction of mutation testing costs,"['JAP Lima', 'G Guizzo', 'SR Vergilio', 'APC Silva']",,"Mutation testing presents high efficacy in terms of revealed faults, but with high computational costs, because test cases must be executed against a great number of mutants. To reduce such costs several strategies exist. In general, they select a reduced number of mutants that maintain a great overall mutation score. Recently, Higher-Order Mutation Testing (HOM) was proposed. HOM introduces more than one fault at a time in the mutants such that they are harder to kill. This kind of testing can also be used as a cost reduction strategy. However, few works in literature evaluate the cost reduction potential of HOM or compare it to other existing strategies. In this work, we evaluate HOM as a mutation testing cost reduction strategy. We conducted an experiment to compare four HOM-based strategies (First to Last, Random Mix, Different Operators, and Each-Choice) and three conventional ones (Random Mutant Selection, Selective Mutation, and Search-Based Mutation by using Genetic Algorithm). The analysis considers the number of selected mutants, number of test cases, mutation score and efficiency measures. Selective Mutation presented the best results overall. Among the HOM-based strategies, Each-Choice was the best."
Evaluation of GUI testing techniques for system crashing: from real to model-based controlled experiments,['C Bertolini'],x (not English),
Evaluation of mutant sampling criteria in object-oriented mutation testing,"['A Derezińska', 'M Rudnik']",,"Mutation testing of object-oriented programs differs from that of standard (traditional) mutation operators in accordance to the number of generated mutants and ability of tests to kill mutants. Therefore, outcomes of cost reduction analysis cannot be directly transferred from a standard mutation to an object-oriented one. Mutant sampling is one of reduction methods of the number of generated and tested mutants. We proposed different mutant sampling criteria based on equivalence partitioning in respect to object-oriented program features. The criteria were experimentally evaluated for object-oriented and standard mutation operators applied in C# programs. We compared results using a quality metric, which combines mutation score accuracy with mutation cost factors. In result, class random sampling and operator random sampling are recommended for OO and standard mutation testing, accordingly. With a reasonable decline of result accuracy, the mutant sampling technique is easily applicable in comparison to other cost reduction techniques."
Experimental evaluation of mutation testing approaches to python programs,"['A Derezinska', 'K Halas']",,"Mutation testing of Python programs raises a problem of incompetent mutants. Incompetent mutants cause execution errors due to inconsistency of types that cannot be resolved before run-time. We present a practical approach in which incompetent mutants can be generated, but the solution is transparent for a user and incompetent mutants are detected by a mutation system during test execution. Experiments with 20 traditional and object-oriented operators confirmed that the overhead can be accepted. The paper presents an experimental evaluation of the first- and higher-order mutation. Four algorithms to the 2nd and 3rd order mutant generation were applied. The impact of code coverage consideration on the process efficiency is discussed. The experiments were supported by the MutPy system for mutation testing of Python programs."
Explorando gamificação no ensino de teste de software,['GM Jesus'],x (not English),
Extending the Bacterio tool for web application mutation testing.,"['M Polo', 'D Caivano', 'PR Mateo']",x (not found),
Fault Evaluator: a tool for experimental investigation of effectiveness in software testing,"['W Jenkins', 'S Vilkomir']",,"The specifications for many software systems, including safety-critical control systems, are often described using complex logical expressions. It is important to find effective methods to test implementations of such expressions. Analyzing the effectiveness of the testing of logical expressions manually is a tedious and error prone endeavor, thus requiring special software tools for this purpose. This paper presents Fault Evaluator, which is a new tool for experimental investigation of testing logical expressions in software. The goal of this tool is to evaluate logical expressions with various test sets that have been created according to a specific testing method and to estimate the effectiveness of the testing method for detecting specific faulty variations of the original expressions. The main functions of the tool are the generation of complete sets of faults in logical expressions for several specific types of faults; gaining expected (Oracle) values of logical expressions; testing faulty expressions and detecting whether a test set reveals a specific fault; and evaluating the effectiveness of a testing approach."
Finding redundancy in web mutation operators,"['U Praphamontripong', 'J Offutt']",,"New web development technologies enhance functionality of web applications but also introduce challenges in testing the software. As mutation analysis has been shown to be effective at designing tests for traditional software, we previously proposed web mutation testing. However, applying mutation analysis can be computationally expensive due to an extensive number of test requirements. This paper introduces, evaluates, and refines web mutation operators with the goal of reducing the number of test requirements. This paper evaluates redundancy among web mutation operators by analyzing the types of mutants that can be killed by tests generated specifically to kill other types of mutants and the types of mutants (and the operators that generate them) that can be excluded from testing while maintaining the same level of fault detection. An experimental study was conducted on 12 subject web applications using 15 web mutation operators. The redundancy in web mutation operators is computed as the percentage of the mutants of each operator that are killed by tests designed specifically to kill mutants of other operators. Tests designed specifically to kill mutants of some operators can also kill mutants generated from other operators. Three overlapping web mutation operators (WFUR, WHID, and WLUD) are redundant and can be excluded from mutation testing with minimal loss in fault detection capability."
Fine-grained test minimization,"['A Vahabzadeh', 'A Stocco']",,"As a software system evolves, its test suite can accumulate redundancies over time. Test minimization aims at removing redundant test cases. However, current techniques remove whole test cases from the test suite using test adequacy criteria, such as code coverage. This has two limitations, namely (1) by removing a whole test case the corresponding test assertions are also lost, which can inhibit test suite effectiveness, (2) the issue of partly redundant test cases, i.e., tests with redundant test statements, is ignored. We propose a novel approach for fine-grained test case minimization. Our analysis is based on the inference of a test suite model that enables automated test reorganization within test cases. It enables removing redundancies at the test statement level, while preserving the coverage and test assertions of the test suite. We evaluated our approach, implemented in a tool called Testler, on the test suites of 15 open source projects. Our analysis shows that over 4,639 (24%) of the tests in these test suites are partly redundant, with over 11,819 redundant test statements in total. Our results show that Testler removes 43% of the redundant test statements, reducing the number of partly redundant tests by 52%. As a result, test suite execution time is reduced by up to 37% (20% on average), while maintaining the original statement coverage, branch coverage, test assertions, and fault detection capability."
Generate test selection statistics with automated selective mutation,['GD Charan'],,"Context. Software systems are under constant updating for being faulty and to improve and introduce features. The Software testing is the most commonly used  method for validating the quality of software systems. Agile processes help to  automate testing process. A regression test is the main strategy used in testing. Regression testing is time consuming, but with increase in codebases is making it more time extensive and time consuming. Making regression testing time efficient for continuous integration is the new strategy. Objectives. This thesis focuses on co-relating code packages to test packages by automating mutation to inject error into C code. Regression testing against mutated code establishes co-relations. Co-relation data of particular modified code packages can be used for test selections. This method is most effective than the traditional test selection method. For this thesis to reduce the mutation costs selective mutation method is selected. Demonstrating the proof of concept helps to prove proposed  hypothesis. Methods. An experiment answers the research questions. Testing of hypothesis on open source C programs will evaluate efficiency. Using this correlation method testers can reduce the testing cycles regardless of test environments. Results. Experimenting with sample programs using automated selective mutation the efficiency to co-relate tests to code packages was 93.4%. Results. After experimenting with sample programs using automated selective mutation the efficiency to co-relate tests to code packages was 93.4%. Conclusions. This research concludes that the automated mutation to obtain test selection statistics can be adopted. Though it is difficult for mutants to fail every test case, supposing that this method works with 93.4% efficient test failure on an average, then this method can reduce the test suite size to 5% for the particular modified code package."
HMER: a hybrid mutation execution reduction approach for mutation-based fault localization,"['Z Li', 'H Wang', 'Y Liu']",,"Identifying the location of faults in programs has been recognized as one of the most manually and time cost activities during software debugging process. Fault localization techniques, which seek to identify faulty program statements as quickly as possible, can assist developers in alleviating the time and manual cost of software debugging. Mutation-based fault localization(MBFL) has a promising fault localization accuracy, but suffered from huge mutation execution cost. To reduce the cost of MBFL, we propose a Hybrid Mutation Execution Reduction(HMER) approach in this paper. HMER consists of two steps: Weighted Statement-Oriented Mutant Sampling(WSOME) and Dynamic Mutation Execution Strategy(DMES). In the first step, we employ Spectrum-Based Fault Localization(SBFL) techniques to calculate the suspiciousness value of statements, and guarantee that the mutants generated from statements with higher suspiciousness value will have more chance to be remained in the sampling process. Next, a dynamic mutation execution strategy is used to execute the reduced mutant set on test suite to avoid worthless execution. Empirical results on 130 versions from 9 subject programs show that HMER can reduce 74.5%-93.4% mutation execution cost while keeping almost the same fault localization accuracy with the original MBFL. A further indicates that when employing HMER strategy in MBFL, the fault localization accuracy has no statistically significant difference in most cases compared with the original MBFL without any reduction techniques."
Harnessing automated test case generators for GUI testing in industry,"['C Klammer', 'R Ramler']",,"Modern graphical user interfaces (GUIs) are highly dynamic and support multi-touch interactions and screen gestures besides conventional inputs via mouse and keyboard. Hence, the flexibility of modern GUIs enables countless usage scenarios and combinations including all kind of interactions. From the viewpoint of testing, this flexibility results in a combinatorial explosion of possible interaction sequences. It dramatically raises the required time and effort involved in GUI testing, which brings manual exploration as well as conventional regression testing approaches to its limits. Automated test generation (ATG) has been proposed as a solution to reduce the effort for manually designing test cases and to speed-up test execution cycles. In this paper we describe how we successfully harnessed a state-of-the-art ATG tool (Randoop) developed for code-based API testing to generate GUI test cases. The key is an adapter that transforms API calls to GUI events. The approach is the result of a research transfer project with the goal to apply ATG for testing of human machine interfaces used to control industrial machinery. In this project the ATG tool was used to generate unit test cases for custom GUI controls and system tests for exploring navigation scenarios. It helped to increase the test coverage and was able reveal new defects in the implementation of the GUI controls as well as in the GUI application."
Hybrid methods for reducing database schema test suites: Experimental insights from computational and human studies,"['A Alsharif', 'GM Kapfhammer', 'P McMinn']",,"Given that a relational database is a critical component of many software applications, it is important to thoroughly test the integrity constraints of a database's schema, because they protect the data. Although automated test data generation techniques ameliorate the otherwise manual task of database schema testing, they often create test suites that contain many, sometimes redundant, tests. Since prior work presented a hybridized test suite reduction technique, called STICCER, that beneficially combined Greedy test suite reduction with a test merging method customized for database schemas, this paper experimentally evaluates a different hybridization. Motivated by prior results showing that test suite reduction with the Harrold-Gupta-Soffa (HGS) method can be more effective than Greedy at reducing database schema test suites, this paper evaluates an HGS-driven STICCER variant with both a computational and a human study. Using 34 database schemas and tests created by two test data generators, the results from the computational study reveal that, while STICCER is equally efficient and effective when combined with either Greedy or HGS, it is always better than the isolated use of either Greedy or HGS. Involving 27 participants, the human study shows that, when compared to test suites reduced by HGS, those reduced by a STICCER-HGS hybrid allow humans to inspect test cases faster, but not always more accurately."
Identifikace potenciálně znovupoužitelných částí v neoptimálně strukturovaných automatických testovacích skriptech,['M Filipský'],x (not English),
Identifying method-level mutation subsumption relations using Z3,"['R Gheyi', 'M Ribeiro', 'B Souza', 'M Guimaraes']",,"Context: Mutation analysis is a popular but costly approach to assess the quality of test suites. One recent promising direction in reducing costs of mutation analysis is to identify redundant mutations, i.e., mutations that are subsumed by some other mutations. A previous approach found redundant mutants manually through truth tables but it cannot be applied to all mutations. Another work derives them using automatic test suite generators but it is a time consuming task to generate mutants and tests, and to execute tests. Objective: This article proposes an approach to discover redundant mutants by proving subsumption relations among method-level mutation operators using weak mutation testing. Method: We conceive and encode a theory of subsumption relations in the Z3 theorem prover for 37 mutation targets (mutations of an expression or statement). Results: We automatically identify and prove a number of subsumption relations using Z3, and reduce the number of mutations in a number of mutation targets. To evaluate our approach, we modified MuJava to include the results of 24 mutation targets and evaluate our approach in 125 classes of 5 large open source popular projects used in prior work. Our approach correctly discards mutations in 75.93% of the cases, and reduces the number of mutations by 71.38%. Conclusions: Our approach offers a good balance between the effort required to derive subsumption relations and the effectiveness for the targets considered in our evaluation in the context of strong mutation testing."
Identifying mutation subsumption relations,['B Souza'],,"One recent promising direction in reducing costs of mutation analysis is to identify redundant mutations. We propose a technique to discover redundant mutations by proving subsumption relations among method-level mutation operators using weak mutation testing. We conceive and encode a theory of subsumption relations in Z3 for 40 mutation targets (mutations of an expression or statement). Then we prove a number of subsumption relations using the Z3 theorem prover, and reduce the number of mutations in a number of mutation targets. MuJava-M includes some subsumption relations in MuJava. We apply MuJava and MuJava-M to 187 classes of 17 projects. Our approach correctly discards mutations in 74.97% of the cases, and reduces the number of mutations by 72.52%."
Identifying useful mutants to test time properties,"['B Lindström', 'J Offutt']",,"Real-time systems have to be verified and tested for timely behavior as well as functional behavior. Thus, time is an extra dimension that adds to the complexity of software testing. A timed automata model with a model-checker can be used to generate timed test traces. To properly test the timely behavior, the set of test traces should challenge the different time constraints in the model. This paper describes and adapts mutation operators that target such time constraints in timed automata models. Time mutation operators apply a delta to the time constraints to help testers design tests that exceed the time constraints. We suggest that the size of this delta determines how easy the mutant is to kill and that the optimal delta varies by the program, mutation operator, and the individual mutant. To avoid trivial and equivalent time mutants, the delta should be set individually for each mutant. We discuss mutant subsumption and define the problem of finding dominator mutants in this new domain. In this position paper, we outline an iterative tuning process where a statistical model-checker, UPPAAL SMC, is used to: (i) create a tuned set of dominator time mutants, and (ii) generate test traces that kill the mutants."
Impacts de l'AOP sur les tests dans un environnement Agile: utilisation de Mocks pour les tests unitaires d'aspects,['FA Bourbonnais-Bigras'],x (not English),
Improving fault localization for Simulink models using search-based testing and prediction models,"['B Liu', 'S Nejati', 'LC Briand']",,"Real-time systems have to be verified and tested for timely behavior as well as functional behavior. Thus, time is an extra dimension that adds to the complexity of software testing. A timed automata model with a model-checker can be used to generate timed test traces. To properly test the timely behavior, the set of test traces should challenge the different time constraints in the model. This paper describes and adapts mutation operators that target such time constraints in timed automata models. Time mutation operators apply a delta to the time constraints to help testers design tests that exceed the time constraints. We suggest that the size of this delta determines how easy the mutant is to kill and that the optimal delta varies by the program, mutation operator, and the individual mutant. To avoid trivial and equivalent time mutants, the delta should be set individually for each mutant. We discuss mutant subsumption and define the problem of finding dominator mutants in this new domain. In this position paper, we outline an iterative tuning process where a statistical model-checker, UPPAAL SMC, is used to: (i) create a tuned set of dominator time mutants, and (ii) generate test traces that kill the mutants."
Improving mutation testing process of python programs,"['A Derezinska', 'K Hałas']",,"Mutation testing helps in evaluation of test suite quality and test development. It can be directed to programs of different languages. High cost of a mutation testing process limits its applicability. This paper focuses on mutation testing of Python programs, discussing several issues of mutant creation and execution. It was showed how they can be effectively handled in the Python environment. We discuss introduction of first and higher order mutation in an abstract syntax tree with use of generators, dealing with code coverage with AST, executing mutants via mutant injection into tests. The solutions were used in reengineering of MutPy - a mutation testing tool for Python programs. The improvements were positively verified in mutation experiments."
Improving oracle quality by detecting brittle assertions and unused inputs in tests,"['C Huo', 'J Clause']",,"Writing oracles is challenging. As a result, developers often create oracles that check too little, resulting in tests that are unable to detect failures, or check too much, resulting in tests that are brittle and difficult to maintain. In this paper we present a new technique for automatically analyzing test oracles. The technique is based on dynamic tainting and detects both brittle assertions—assertions that depend on values that are derived from uncontrolled inputs—and unused inputs—inputs provided by the test that are not checked by an assertion. We also presented OraclePolish, an implementation of the technique that can analyze tests that are written in Java and use the JUnit testing framework. Using OraclePolish, we conducted an empirical evaluation of more than 4000 real test cases. The results of the evaluation show that OraclePolish is effective; it detected 164 tests that contain brittle assertions and 1618 tests that have unused inputs. In addition, the results also demonstrate that the costs associated with using the technique are reasonable."
Improving readability in automatic unit test generation,['E Daka'],,"In object-oriented programming, quality assurance is commonly provided through writing unit tests, to exercise the operations of each class. If unit tests are created and maintained manually, this can be a time-consuming and laborious task. For this reason, automatic methods are often used to generate tests that seek to cover all paths of the tested code. Search may be guided by criteria that are opaque to the programmer, resulting in test sequences that are long and confusing. This has a negative impact on test maintenance. Once tests have been created, the job is not done: programmers need to reason about the tests throughout the lifecycle, as the tested software units evolve. Maintenance includes diagnosing failing tests (whether due to a software fault or an invalid test) and preserving test oracles (ensuring that checked assertions are still relevant). Programmers also need to understand the tests created for code that they did not write themselves, in order to understand the intent of that code. If generated tests cannot be easily understood, then they will be extremely difficult to maintain. The overall objective of this thesis is to reaffirm the importance of unit test maintenance; and to offer novel techniques to improve the readability of automatically generated tests. The first contribution is an empirical survey of 225 developers from different parts of the world, who were asked to give their opinions about unit testing practices and problems. The survey responses confirm that unit testing is considered important; and that there is an appetite for higher-quality automated test generation, with a view to test maintenance. The second contribution is a domain-specific model of unit test readability, based on human judgements. The model is used to augment automated unit test generation to produce test suites with both high coverage and improved readability. In evaluations, 30 programmers preferred our improved tests and were able to answer maintenance questions 14level of accuracy. The third contribution is a novel algorithm for generating descriptive test names that summarise API- level coverage goals. Test optimisation ensures that each test is short, bears a clear relation to the covered code, and can be readily identified by programmers. In evaluations, 47 programmers agreed with the choice of synthesised names and that these were as descriptive as manually chosen names. Participants were also more accurate and faster at matching generated tests against the tested code, compared to matching with manually-chosen test names."
Interaktywne testowanie mutacyjne w procesie tworzenia oprogramowania w środowisku Visual Studio,['P Trzpil'],x (not English),
Introduction du test dans la modélisation par aspects,"['J Klein', 'B Baudry', 'O Barais', 'A Jackson']",x (not English),
Introduction to software testing,"['P Ammann', 'J Offutt']",x (Book),
Investigating the impact of development task on external quality in test-driven development: An industry experiment,"['A Tosun', 'O Dieste', 'S Vegas', 'D Pfahl']",,"Reviews on test-driven development (TDD) studies suggest that the conflicting results reported in the literature are due to unobserved factors, such as the tasks used in the experiments, and highlight that there are very few industry experiments conducted with professionals. The goal of this study is to investigate the impact of a new factor, the chosen task, and the development approach on external quality in an industrial experiment setting with 17 professionals. The participants are junior to senior developers in programming with Java, beginner to novice in unit testing, JUnit, and they have no prior experience in TDD. The experimental design is a 2 \times 2 cross-over, i.e., we use two tasks for each of the two approaches, namely TDD and incremental test-last development (ITLD). Our results reveal that both development approach and task are significant factors with regards to the external quality achieved by the participants. More specifically, the participants produce higher quality code during ITLD in which splitting user stories into subtasks, coding, and testing activities are followed, compared to TDD. The results also indicate that the participants produce higher quality code during the implementation of Bowling Score Keeper, compared to that of Mars Rover API, although they perceived both tasks as of similar complexity. An interaction between the development approach and task could not be observed in this experiment. We conclude that variables that have not been explored so often, such as the extent to which the task is specified in terms of smaller subtasks, and developers' unit testing experience might be critical factors in TDD experiments. The real-world appliance of TDD and its implications on external quality still remain to be challenging unless these uncontrolled and unconsidered factors are further investigated by researchers in both academic and industrial settings."
Java unit testing tool competition-sixth round,"['UR Molina', 'F Kifetew']",,"We report on the advances in this sixth edition of the JUnit tool competitions. This year the contest introduces new benchmarks to assess the performance of JUnit testing tools on different types of real-world software projects. Following on the statistical analyses from the past contest work, we have extended it with the combined tools performance aiming to beat the human made tests. Overall, the 6th competition evaluates four automated JUnit testing tools taking as baseline human written test cases for the selected benchmark projects. The paper details the modifications performed to the methodology and provides full results of the competition."
L3. 4: Etude de réduction de suites de tests,"['T Triki', 'L du-Bousquet', 'Y Ledru']",x (not English),
Mahtab: Phase-wise acceleration of regression testing for C,"['S Mondal', 'R Nasre']",,"Software regression testing consists of offline, online, and execution phases which are executed sequentially. The offline phase involves code instrumentation and test-coverage collection. Subsequently, the online phase performs program differencing, test-suite selection and prioritization. Finally, the selected test-cases are executed against the new version of software for its re-validation. Regression testing is a time-consuming process and is often on the critical path of the project. To improve the turn-around time of software development cycle, our goal is to reduce regression testing time across all phases using multi-core parallelization. This poses several challenges that stem from I/O, dependence on third-party libraries, and inherently sequential components in the overall testing process. We propose parallelization test-windows to effectively partition test-cases across threads. To measure the benefit of prioritization coupled with multi-threaded execution, we propose a new metric, EPSilon, for rewarding failure observation frequency in the timeline of test-execution. To measure the rate of code-change coverage due to regression test prioritization, we introduce ECC, a variant of the widely used APFD metric. We illustrate the effectiveness of our approach using the popular Software-artifact Infrastructure Repository (SIR) and five real-world projects from GitHub."
Mapeamento e aplicação de testes estatísticos em engenharia de software,['MNP Detoni'],x (not English),
Measuring the multiple-condition coverage with test suites for AspectJ programs,['A Zanderink'],,"We propose in this paper a way to measure the coverage of a Java test suite by considering the JMLspecification associed to the Java program under test. This approach is based on extracting a predicate-based graph from the JML method specifications. We then measure the coverage of this latter w.r.t. nodes of the graph that are visited by the test suite. In addition, we propose to check whether the test suitesatisfies classical condition coverage criteria. We also introduce a tool, to be used as precompiler for Java,that is in charge of measuring and reporting the coverage according to these criteria."
Mitigating the effects of flaky tests on mutation testing,"['A Shi', 'J Bell', 'D Marinov']",,"Mutation testing is widely used in research as a metric for evaluating the quality of test suites. Mutation testing runs the test suite on generated mutants (variants of the code under test), where a test suite kills a mutant if any of the tests fail when run on the mutant. Mutation testing implicitly assumes that tests exhibit deterministic behavior, in terms of their coverage and the outcome of a test (not) killing a certain mutant. Such an assumption does not hold in the presence of flaky tests, whose outcomes can non-deterministically differ even when run on the same code under test. Without reliable test outcomes, mutation testing can result in unreliable results, e.g., in our experiments, mutation scores vary by four percentage points on average between repeated executions, and 9% of mutant-test pairs have an unknown status. Many modern software projects suffer from flaky tests. We propose techniques that manage flakiness throughout the mutation testing process, largely based on strategically re-running tests. We implement our techniques by modifying the open-source mutation testing tool, PIT. Our evaluation on 30 projects shows that our techniques reduce the number of 'unknown' (flaky) mutants by 79.4%."
"Model-based testing of NASA's GMSEC, a reusable framework for ground system software","['V Gudmundsson', 'C Schulze', 'D Ganesan']",,"We present an empirical study in which model-based testing (MBT) was applied to the software bus of NASA’s Goddard Mission Service Evolution Center (GMSEC), a reusable software framework. The goal was to study the feasibility of using MBT on a real-world software system that was designed to be flexible. GMSEC has three levels of flexibility: 1) loose application coupling through a software bus based on the publish–subscribe architectural style, 2) language independence by providing APIs to the bus in several programming languages, 3) middleware independence by providing wrappers for several middlewares that are supported by the software bus. The novelty brought forward in this paper is that one model and one set of generated test cases were used as the basis to test the software bus for behavioral consistency across multiple programming languages and middleware wrappers. The comparison of costs and benefits from using finite state machines (FSM) vs. extended FSMs (EFSM) when used for MBT on a real-world system is also novel. The case study shows that it was feasible, even for a programmer who neither knew MBT nor the system under test, to successfully apply MBT to a flexible system such as GMSEC and that MBT could within reasonable effort detect non-trivial defects in a fielded system."
Model-based testing of flexible systems,['VÖ Guðmundsson'],,"We present an empirical study in which model-based testing (MBT) was applied to two different flexible systems. Namely, the software bus of NASA’s Goddard Mission Service Evolution Center (GMSEC), a reusable software framework used in several NASA missions, and the Android client of QuizUp, currently the largest mobile trivia game in the world. The main goal of the study was to examine whether MBT could be used, in an effective and efficient way, to test flexible systems using the same MBT approach. Our hypothesis was that although GMSEC and QuizUp are indeed different (i.e. QuizUp has a graphical user interface, GMSEC does not) they share certain similarities that would allow us to use the same MBT approach for testing both systems. In addition, we address the question of whether we could apply our MBT approach with reasonable effort. The effort would be viewed as reasonable if we would be able to successfully apply MBT within 6 months (i.e. the typical time limit for an internship) for each study. A comparison of the cost and benefit of using finite state machines (FSM) vs. extended FSMs (EFSM) as model representations in MBT is also provided. The study shows that we were able to use the same MBT approach to test two different flexible systems, thus, supporting our hypothesis. Non-trivial defects were detected, especially using EFSMs, on systems that were already well-tested. We found that maintaining a single behavioral model for each system was key in order to test these flexible systems in an efficient way. The study also demonstrates that it was feasible, even for a person without previous MBT background, to successfully apply MBT to these two flexible systems. Our comparison of costs and benefits showed that MBT started paying off as soon as we had finished our first iteration of MBT in the GMSEC study."
Model-based testing of measurement devices using a domain-specific modelling language,['C Burghard'],,"The practice of model-based testing finds increasing application in industry, due to its potential to cope with the ever rising complexity of technical systems. For this reason, the AVL List GmbH is introducing a model-based testing methodology for the application to its portfolio of automotive measurement devices. In a previous project by AVL, the Graz University of Technology and the Austrian Institute of Technology, a model-based mutation testing approach has been developed. While this approach has been successfully validated in terms of functionality, it was rejected by AVL’s test engineers as they deemed its UML-based modelling front-end too difficult to use in their specific industrial setting. In the thesis at hand, we examine the tool composition-, usability- and experience-related reasons which have lead to the rejection of this modelling approach. We present a textual domain-specific language which we specifically tailored to the sole purpose of modelling AVL’s measurement device state machines. To ensure the intended improvement in the user experience of the modelling formalism, we developed the language in close and frequent collaboration with the test engineers. The resulting domain-specific language, called MDML, turned out to be very easy to learn and to be able to efficiently encode measurement device state machine models. In conjunction with MDML, we further developed a dedicated modelling tool, based on the well-known Eclipse-IDE. As we did with the language, we tailored this modelling tool to our use case and we also enriched it with a number of features providing user guidance and direct connection to AVL-internal data sources. Most importantly, we integrated a test case generation toolchain which we built around the pre-existing MoMuT test case generator. This toolchain involves a model transformation from MDML into object-oriented action systems to serve as input for the generator. It further involves the concretion of MoMuT’s abstract test case into executable test code. Lastly, we show that the capabilities of our model-based testing methodology are at least on-par with those of the previous UML-based one by means of a case study involving the generation and execution of tests for one of AVL’s measurement devices."
MuAlloy: an automated mutation system for alloy,['K Wang'],,"Mutation is a powerful technique that researchers have studied for several decades in the context of imperative code. For example, mutation testing is commonly considered a 'gold standard' for test suite quality. Mutation in the context of declarative languages is a less studied problem. This thesis introduces a foundation for mutation-driven analyses for Alloy, a first-order, declarative language based on relations. Specifically, we introduce a family of mutation operators for Alloy models and define algorithms for applying the operators on different parts of the models. We embody these operators and algorithms in our prototype tool MuAlloy that provides a GUI-based front-end for customizing the application of mutation operators. To demonstrate the potential of our approach, we illustrate the use of MuAlloy in two application scenarios: (1) mutation testing for Alloy (in the spirit of traditional mutation testing for imperative languages); and (2) program repair for Alloy using mutation."
MuRanker: a mutant ranking tool,"['AS Namin', 'X Xue', 'O Rosas']",,"Mutation testing is a fault-based software testing technique in which a large number of mutants are generated in order to assess the adequacy of test cases devised. One of the daunting problems in this area consists in determining whether a mutant can be killed by a test case or it cannot be killed easily because the mutant is semantically equivalent to the original programme. A possible solution, as proposed in this paper, is to measure the complexity of each mutant and prioritize them according to how easy or hard they are to be exposed. As a result, using a proper metric based on the mutants' complexity, the tester may decide whether to focus on killing easy or hard mutants first. This paper introduces MuRanker, a mutation ranking tool that ranks mutants according to their predicted difficulty and complexity in being detected. The tool uses distance functions to decide the difficulty level of mutants. The computation of the distance function score is based on three representations, namely the control-flow-graph representation, the Jimple representation and the information captured through the code coverage data to differentiate the changes in the original and mutant programs. The tool generates a report that displays mutants in an ordered list based on their complexity. Using this tool, the tester can choose mutants and then devise appropriate test cases with the goal of killing them. The mutation ranking idea and the developed tool allow the software tester to save substantial time and effort on a task that, otherwise, would require the user to manually identify the difficult mutants. To our knowledge, MuRanker is the first mutation tool that proposes ranking mutants to facilitate mutation testing."
MuVM: Higher order mutation analysis virtual machine for C,"['S Tokumoto', 'H Yoshida', 'K Sakamoto']",,"Mutation analysis is a method for evaluating the effectiveness of a test suite by seeding faults artificially and measuring the fraction of seeded faults detected by the test suite. The major limitation of mutation analysis is its lengthy execution time because it involves generating, compiling and running large numbers of mutated programs, called mutants. Our tool MuVM achieves a significant runtime improvement by performing higher order mutation analysis using four techniques, meta mutation, mutation on virtual machine, higher order split-stream execution, and online adaptation technique. In order to obtain the same behavior as mutating the source code directly, meta mutation preserves the mutation location information which may potentially be lost during bit code compilation and optimization. Mutation on a virtual machine reduces the compilation and testing cost by compiling a program once and invoking a process once. Higher order split-stream execution also reduces the testing cost by executing common parts of the mutants together and splitting the execution at a seeded fault. Online adaptation technique reduces the number of generated mutants by omitting infeasible mutants. Our comparative experiments indicate that our tool is significantly superior to an existing tool, an existing technique (mutation schema generation), and no-split-stream execution in higher order mutation."
Mutasyon bazlı yazılım testlerinin iyileştirilmesi için bir yaklaşım,['MA Warsame'],x (not English),
Mutation based test generation using search based social group optimization approach,"['S Rani', 'B Suri']",,"Mutation based test generation is a popular and effective process for creating the test suite that is appraised for its caliber over a pool of artificial faults. These artificial faults can be infused by imposing mutagenic rules that further assist meta-heuristic techniques for searching the evolved test suite in search space. Meta-heuristic techniques switch between multiple solutions in search space and result in an optimized solution. This paper implements and presents a new test set generation algorithm, SGO-MT, by embracing a recently developed search based approach, Social Group Optimization algorithm (SGO) for exposing numerous artificial faults in the software. It works on the principle of human learning nature from society and a teacher in the group. The efficacy of the proposed approach is measured on thirteen Java programs widely used in academia. The results demonstrate the good performance for finding the simple and stubborn faults."
Mutation integration testing,"['M Grechanik', 'G Devanla']",,"In integration testing, integrated software modules or components are evaluated as a whole to determine if they behave correctly. Mutation testing is recognized as one of the strongest approaches for evaluating the effectiveness of test suites, and it is important to generate effective mutants efficiently for integration tests. However, it is difficult to generate integration mutants that create an error state in one component with certain assurances that this error state will affect computations in some other components. Unfortunately, little research exists that addresses this big and important problem to improve the quality of integration test suites. In this paper, we propose a theory and a solution for generating mutants that specifically target integration tests. We formulate a fault model for integration bugs that uses static dataflow analysis to obtain information about how integrated components interact in an application. Integration mutants are generated by applying mutation operators to instructions that lie in dataflow paths among integrated components. We implemented our approach and evaluated it on five open-source applications. In comparison to muJava, our approach reduces the number of generated mutants by up to approximately 19 times with a strong power to determine inadequacies in integration test suites."
Mutation reduction in software mutation testing using firefly optimization algorithm,"['N Shomali', 'B Arasteh']",,"Purpose: For delivering high-quality software applications, proper testing is required. A software test will function successfully if it can find more software faults. The traditional method of assessing the quality and effectiveness of a test suite is mutation testing. One of the main drawbacks of mutation testing is its computational cost. The research problem of this study is the high computational cost of the mutation test. Reducing the time and cost of the mutation test is the main goal of this study. Design/methodology/approach: With regard to the 80–20 rule, 80% of the faults are found in 20% of the fault-prone code of a program. The proposed method statically analyzes the source code of the program to identify the fault-prone locations of the program. Identifying the fault-prone (complex) paths of a program is an NP-hard problem. In the proposed method, a firefly optimization algorithm is used for identifying the most fault-prone paths of a program; then, the mutation operators are injected only on the identified fault-prone instructions. Findings: The source codes of five traditional benchmark programs were used for evaluating the effectiveness of the proposed method to reduce the mutant number. The proposed method was implemented in Matlab. The mutation injection operations were carried out by MuJava, and the output was investigated. The results confirm that the proposed method considerably reduces the number of mutants, and consequently, the cost of software mutation-test. Originality/value: The proposed method avoids the mutation of nonfault-prone (simple) codes of the program, and consequently, the number of mutants considerably is reduced. In a program with n branch instructions (if instruction), there are 2n execution paths (test paths) that the data and codes into each of these paths can be considered as a target of mutation. Identifying the error-prone (complex) paths of a program is an NP-hard problem. In the proposed method, a firefly optimization algorithm as a heuristic algorithm is used for identifying the most error-prone paths of a program; then, the mutation operators (faults) are injected only on the identified fault-prone instructions."
Mutation testing and test data generation approaches: A review,"['M Dave', 'R Agrawal']",,"Software advancement has increased the complexities many fold and to meet the quality standards, a lot of research is being done in designing new testing methodologies and tools. Mutation testing is a proven effective technique but the high cost attached with it averts it from establishing it as an industrial tool. The review is an extension of the previous work where a review was done on search based test data generation and mutation testing. The objective is to study the remaining techniques/approaches and summaries the discussion of both the reviews. The application of mutation testing with various techniques at various phases of software development along with various languages/tools show that it is a versatile, adaptable and efficient, which is motivating the researchers to explore the new areas."
Mutation testing techniques: A comparative study,"['S Hamimoune', 'B Falah']",,"Testing is a very crucial phase in any software development, in which various testing techniques are used with the intent of finding software defects. Different approaches have been suggested to effectively accomplish an application testing, and testers shall choose the most adequate one in terms of cost and efficiency. Mutation has been ranked as one the most effective testing techniques in assessing the quality of input values and test cases. However, it has been neglected by many testers because of the costly techniques it encompasses. This paper conducts a comparative study of four different mutation testing techniques (class-level operators, method-level operators, all operators, and random sampling). The purpose of this research paper is to conduct the most effective and reliable mutation testing technique. To do this, an empirical study on five different java applications is presented and focused on investigating each mutation technique. Based on the results of this experimental comparison, the all operators sampling technique is the most optimized and effective mutation testing method."
Mutation testing with hyperproperties,"['A Fellner', 'MT Befrouei', 'G Weissenbacher']",,"We present a new method for model-based mutation-driven test case generation. Mutants are generated by making small syntactical modifications to the model or source code of the system under test. A test case kills a mutant if the behavior of the mutant deviates from the original system when running the test. In this work, we use hyperproperties—which allow to express relations between multiple executions—to formalize different notions of killing for both deterministic as well as non-deterministic models. The resulting hyperproperties are universal in the sense that they apply to arbitrary reactive models and mutants. Moreover, an off-the-shelf model checking tool for hyperproperties can be used to generate test cases. Furthermore, we propose solutions to overcome the limitations of current model checking tools via a model transformation and a bounded SMT encoding. We evaluate our approach on a number of models expressed in two different modeling languages by generating tests using a state-of-the-art mutation testing tool."
On-line tracing of XACML-based policy coverage criteria,"['F Lonetti', 'E Marchetti']",,"Currently, eXtensible Access Control Markup Language (XACML) has becoming the standard for implementing access control policies and consequently more attention is dedicated to testing the correctness of XACML policies. In particular, coverage measures can be adopted for assessing test strategy effectiveness in exercising the policy elements. This study introduces a set of XACML coverage criteria and describes the access control infrastructure, based on a monitor engine, enabling the coverage criterion selection and the on-line tracing of the testing activity. Examples of infrastructure usage and of assessment of different test strategies are provided."
Optimizing mutation testing by discovering dynamic mutant subsumption relations,"['MA Guimarães', 'L Fernandes', 'M Ribeiro']",,"One recent promising direction on reducing costs of mutation analysis is to identify redundant mutations, i.e., mutations that are subsumed by some other mutations. Previous works found out redundant mutants manually through the truth table. Although the idea is promising, it can only be applied for logical and relational operators. In this paper, we propose an approach to discover redundancy in mutations through dynamic subsumption relations among mutants. We focus on subsumption relations among mutations of an expression or statement, named here as “mutation target:” By focusing on targets and relying on automatic test generation tools, we define subsumption relations for dozens of mutation targets in which the MUJAVA tool can apply mutations. We then implemented these relations in a tool, named MUJAVA-M, that generates a reduced set of mutants for each target, avoiding redundant mutants. We evaluated MUJAVA and MUJAVA-M using classes of five open-source projects. As results, we analyze 2,341 occurrences of 32 mutation targets in 168 classes. MUJAVA-M generates less mutants (on average 64.43% less) with 100% of effectiveness in 20 out of 32 targets and more than 95% in 29 out of 32 mutation targets. MUJAVA- M also reduced the time to execute the test suites against the mutants in 52.53% on average, considering the full mutation analysis process."
Partitioning patches into test-equivalence classes for scaling program repair,"['S Mechtaev', 'X Gao', 'SH Tan']",,"Automated program repair is a problem of finding a transformation (called a patch) of a given incorrect program that eliminates the observable failures. It has important applications such as providing debugging aids, automatically grading assignments and patching security vulnerabilities. A common challenge faced by all existing repair techniques is scalability to large patch spaces, since there are many candidate patches that these techniques explicitly or implicitly consider. The correctness criterion for program repair is often given as a suite of tests, since a formal specification of the intended program behavior may not be available. Current repair techniques do not scale due to the large number of test executions performed by the underlying search algorithms. We address this problem by introducing a methodology of patch generation based on a test-equivalence relation (if two programs are 'test-equivalent' for a given test, they produce indistinguishable results on this test). We propose two test-equivalence relations based on runtime values and dependencies respectively and present an algorithm that performs on-the-fly partitioning of patches into test-equivalence classes. Our experiments on real-world programs reveal that the proposed methodology drastically reduces the number of test executions and therefore provides an order of magnitude efficiency improvement over existing repair techniques, without sacrificing patch quality."
PraPR: Practical program repair via bytecode mutation,"['A Ghanbari', 'L Zhang']",,"Automated program repair (APR) is one of the recent advances in automated software engineering aiming for reducing the burden of debugging by suggesting high-quality patches that either directly fix the bugs, or help the programmers in the course of manual debugging. We believe scalability, applicability, and accurate patch validation are the main design objectives for a practical APR technique. In this paper, we present PraPR, our implementation of a practical APR technique that operates at the level of JVM bytecode. We discuss design decisions made in the development of PraPR, and argue that the technique is a viable baseline toward attaining aforementioned objectives. Our experimental results show that: (1) PraPR can fix more bugs than state-of-the-art APR techniques and can be over 10X faster, (2) state-of-the-art APR techniques suffer from dataset overfitting, while the simplistic template-based PraPR performs more consistently on different datasets, and (3) PraPR can fix bugs for other JVM languages, such as Kotlin. PraPR is publicly available at https://github.com/prapr/prapr."
Practical mutation testing for smart contracts,"['JJ Honig', 'MH Everts', 'M Huisman']",," Solidity smart contracts operate in a hostile environment, which introduces the need for the adequate application of testing techniques to ensure mitigation of the risk of a security incident. Mutation testing is one such technique. It allows for the evaluation of the efficiency of a test suite in detecting faults in a program, allowing developers to both assess and improve the quality of their test suites. In this paper, we propose a mutation testing framework and implement a prototype implementation called Vertigo that targets Solidity contracts for the Ethereum blockchain. We also show that mutation testing can be used to assess the test suites of real-world projects."
Reduzindo o custo do teste de mutação com base no conceito de arcos primitivos,['PH Kuroishi'],x (not English),
"Revisiting test smells in automatically generated tests: limitations, pitfalls, and opportunities","['A Panichella', 'S Panichella', 'G Fraser']",,"Test smells attempt to capture design issues in test code that reduce their maintainability. Previous work found such smells to be highly common in automatically generated test-cases, but based this result on specific static detection rules; although these are based on the original definition of 'test smells', a recent empirical study showed that developers perceive these as overly strict and non-representative of the maintainability and quality of test suites. This leads us to investigate how effective such test smell detection tools are on automatically generated test suites. In this paper, we build a dataset of 2,340 test cases automatically generated by EVOSUITE for 100 Java classes. We performed a multi-stage, cross-validated manual analysis to identify six types of test smells and label their instances. We benchmark the performance of two test smell detection tools: one widely used in prior work, and one recently introduced with the express goal to match developer perceptions of test smells. Our results show that these test smell detection strategies poorly characterized the issues in automatically generated test suites; the older tool's detection strategies, especially, misclassified over 70% of test smells, both missing real instances (false negatives) and marking many smell-free tests as smelly (false positives). We identify common patterns in these tests that can be used to improve the tools, refine and update the definition of certain test smells, and highlight as of yet uncharacterized issues. Our findings suggest the need for (i) more appropriate metrics to match development practice; and (ii) more accurate detection strategies, to be evaluated primarily in industrial contexts."
SPt: uma nova abordagem para revisão automática de artefatos de software e geração de planos de teste,"['AC MOTA', 'FA BARROS']",x (not English),
Scaling testing of refactoring engines.,['MMCL Sabino'],,"Refactoring engines may have overly weak conditions, overly strong conditions, and transformation issues related to the refactoring definitions. We find that 86% of the test suites of Eclipse and JRRT are concerned to those kinds of bugs. However, the engines still have them. Researchers have proposed a number of techniques for testing refactoring engines. Nevertheless, they may have limitations related to the program generator, time consumption, kinds of bugs, automation, and debugging. We propose and implement a technique to scale testing of refactoring engines. We improve expressiveness of a program generator and use a technique to skip some test inputs to improve performance. Moreover, we propose new oracles to detect behavioral changes using change impact analysis, overly strong conditions using mutation testing, and transformation issues. We evaluate our technique in 28 refactoring implementations of Java (Eclipse and JRRT) and C (Eclipse) and find 119 bugs. The technique reduces the time in 96% using skips while missing only 6% of the bugs. Using the new oracle to identify overly strong conditions, it detects more bugs and facilitates the debugging activity different from previous works. Finally, we evaluate refactoring implementations of Eclipse and JRRT using the input programs of their refactoring test suites and find a number of bugs not detected by the developers."
Self determination: A comprehensive strategy for making automated tests more effective and efficient,"['K Baral', 'J Offutt', 'F Mulla']",,"A significant change in software development over the last decade has been the growth of test automation. Most software organizations automate as many tests as possible, which not only saves time and money, but also increases reproducibility and reduces errors during testing. However, as software evolves over time, so must the test suites. For each software change, each test falls into one of four categories: (1) it needs to rerun as is, (2) it does not need to rerun, (3) it needs to change and rerun, (4) it should be deleted. This test management is currently done by hand, leading to shortcuts such as always running all tests (wasteful and expensive), deleting valuable tests that should be fixed, and not deleting unneeded tests. Over time, the test suite becomes larger and more expensive to run while also becoming steadily less effective. This project introduces a novel solution to this problem by giving individual tests the ability to self- manage through self-awareness and self-determination. Each test will encode its purpose (its test requirement), can discover what changed in the software, and then decide whether to run, not run, be changed, or self-delete. We are developing techniques and algorithms to compare syntactically two versions of the same program (previous and new) to identify differences. Tests can then check to see whether their purpose is affected by the change, and decide what to do. We have developed preliminary test framework infrastructure to be used with tests that satisfy edge coverage, based on the control flow graph. We have carried out empirical studies on open-source software to evaluate the accuracy of tests' decisions and the cost of execution. Results are encouraging, indicating strong accuracy and reasonable cost."
Service testing for the internet of things,['ES Reetz'],x (Book),
Smartunit: Empirical evaluations for automated unit testing of embedded software in industry,"['C Zhang', 'Y Yan', 'H Zhou', 'Y Yao', 'K Wu']",,"In this paper, we aim at the automated unit coverage-based testing for embedded software. To achieve the goal, by analyzing the industrial requirements and our previous work on automated unit testing tool CAUT, we rebuild a new tool, SmartUnit, to solve the engineering requirements that take place in our partner companies. SmartUnit is a dynamic symbolic execution implementation, which supports statement, branch, boundary value and MC/DC coverage. SmartUnit has been used to test more than one million lines of code in real projects. For confidentiality motives, we select three in-house real projects for the empirical evaluations. We also carry out our evaluations on two open source database projects, SQLite and PostgreSQL, to test the scalability of our tool since the scale of the embedded software project is mostly not large, 5K-50K lines of code on average. From our experimental results, in general, more than 90% of functions in commercial embedded software achieve 100% statement, branch, MC/DC coverage, more than 80% of functions in SQLite achieve 100% MC/DC coverage, and more than 60% of functions in PostgreSQL achieve 100% MC/DC coverage. Moreover, SmartUnit is able to find the runtime exceptions at the unit testing level. We also have reported exceptions like array index out of bounds and divided-by-zero in SQLite. Furthermore, we analyze the reasons of low coverage in automated unit testing in our setting and give a survey on the situation of manual unit testing with respect to automated unit testing in industry. SmartUnit is a dynamic symbolic execution implementation, which supports statement, branch, boundary value and MC/DC coverage. SmartUnit has been used to test more than one million lines of code in real projects. For confidentiality motives, we select three in-house real projects for the empirical evaluations. We also carry out our evaluations on two open source database projects, SQLite and PostgreSQL, to test the scalability of our tool since the scale of the embedded software project is mostly not large, 5K-50K lines of code on average. From our experimental results, in general, more than 90% of functions in commercial embedded software achieve 100% statement, branch, MC/DC coverage, more than 80% of functions in SQLite achieve 100% MC/DC coverage, and more than 60% of functions in PostgreSQL achieve 100% MC/DC coverage. Moreover, SmartUnit is able to find the runtime exceptions at the unit testing level. We also have reported exceptions like array index out of bounds and divided-by-zero in SQLite. Furthermore, we analyze the reasons of low coverage in automated unit testing in our setting and give a survey on the situation of manual unit testing with respect to automated unit testing in industry."
Smells in software test code: A survey of knowledge in industry and academia,"['V Garousi', 'B Küçük']",,"As a type of anti-pattern, test smells are defined as poorly designed tests and their presence may negatively affect the quality of test suites and production code. Test smells are the subject of active discussions among practitioners and researchers, and various guidelines to handle smells are constantly offered for smell prevention, smell detection, and smell correction. Since there is a vast grey literature as well as a large body of research studies in this domain, it is not practical for practitioners and researchers to locate and synthesize such a large literature. Motivated by the above need and to find out what we, as the community, know about smells in test code, we conducted a ‘multivocal’ literature mapping (classification) on both the scientific literature and also practitioners’ grey literature. By surveying all the sources on test smells in both industry (120 sources) and academia (46 sources), 166 sources in total, our review presents the largest catalogue of test smells, along with the summary of guidelines/techniques and the tools to deal with those smells. This article aims to benefit the readers (both practitioners and researchers) by serving as an “index” to the vast body of knowledge in this important area, and by helping them develop high-quality test scripts, and minimize occurrences of test smells and their negative consequences in large test automation projects."
Special features of testing tools applicable for use in trading systems production,"['AA Averina', 'IL Itkin', 'NA Antonov']",,"The paper examines basic requirements for tools developed for verification of correct work of electronic trading systems by applying High Volume Automated Testing (HiVAT) methods and analyzes the applicability of such tools during production operation of trading systems."
Speeding-up mutation testing via data compression and state infection,"['Q Zhu', 'A Panichella', 'A Zaidman']",,"Mutation testing is widely considered as a high-end test criterion due to the vast number of mutants it generates. Although many efforts have been made to reduce the computational cost of mutation testing, its scalability issue remains in practice. In this paper, we introduce a novel method to speed up mutation testing based on state infection information. In addition to filtering out uninfected test executions, we further select a subset of mutants and a subset of test cases to run leveraging data-compression techniques. In particular, we adopt Formal Concept Analysis (FCA) to group similar mutants together and then select test cases to cover these mutants. To evaluate our method, we conducted an experimental study on six open source Java projects. We used EvoSuite to automatically generate test cases and to collect mutation data. The initial results show that our method can reduce the execution time by 83.93% with only 0.257% loss in precision."
Subnets generation of program nets and its application to software testing,"['B Wu', 'X Bao', 'N Zhang', 'H Morita', 'M Nakata']",,"Software testing is an important problem to design a large software system and it is difficult to be solved due to its computational complexity. We try to use program nets to approach this problem. As the first step towards solving software testing problem, this paper provides a technique to generate subnets of a program net and applies this technique to software testing. Firstly, definitions and properties of program nets are introduced based on our previous works, and the explanation of software testing problem is given. Secondly, polynomial algorithms are proposed to generate subnets that can cover all the given program net. Finally, a case study is presented to show how to find subnets covering a given program net by using the proposed algorithms, as well as to show the input test data of the program net for software testing."
Supporting test suite evolution through test case adaptation,"['M Mirzaaghaei', 'F Pastore']",,"Software systems evolve during development and maintenance, and many test cases designed for the early versions of the system become obsolete during the software lifecycle. Repairing test cases that do not compile due to changes in the code under test and generating new test cases to test the changed code is an expensive and time consuming activity that could benefit from automated approaches. In this paper we propose an approach for automatically repairing and generating test cases during software evolution. Differently from existing approaches to test case generation, our approach uses information available in existing test cases, defines a set of heuristics to repair test cases invalidated by changes in the software, and generate new test cases for evolved software. The results obtained with a prototype implementation of the technique show that the approach can effectively maintain evolving test suites, and perform well compared to competing approaches."
Systematic literature review on search based mutation testing,"['J Nishtha', 'S Bharti', 'R Shweta']",,"Search based techniques have been widely applied in the domain of software testing. This Systematic Literature Review aims to present the research carried out in the field of search based approaches applied particularly to mutation testing. During the course of literature review, renowned databases were searched for the relevant publications in the field to include relevant studies up to the year 2014. Few studies for the year 2015-16, gathered by performing snowball search, have also been included. For reviewing the literature in the field, 43 studies were evaluated, out of which 18 studies were thoroughly studied and analysed. The result of this SLR shows that search based techniques were applied to mutation testing primarily for two purposes, either for mutant optimisation or for test case optimisation. The future directions of this SLR suggests the application of search based techniques for other issues related to mutation testing, like, solution to equivalents mutants, generation of non-trivial mutants, multi-objective test data generation and non-functional testing."
Test coverage in python programs,"['H Zhai', 'C Casalnuovo']",,"We study code coverage in several popular Python projects: flask, matplotlib, pandas, scikit-learn, and scrapy. Coverage data on these projects is gathered and hosted on the Codecov website, from where this data can be mined. Using this data, and a syntactic parse of the code, we examine the effect of control flow structure, statement type (e.g., if, for) and code age on test coverage. We find that coverage depends on control flow structure, with more deeply nested statements being significantly less likely to be covered. This is a clear effect, which holds up in every project, even when controlling for the age of the line (as determined by git blame). We find that the age of a line per se has a small (but statistically significant) positive effect on coverage. Finally, we find that the kind of statement (try, if, except, raise, etc) has varying effects on coverage, with exception-handling statements being covered much less often. These results suggest that developers in Python projects have difficulty writing test sets that cover deeply-nested and error-handling statements, and might need assistance covering such code."
Test effort and test coverage: correlation analysis in a safety critical operating system,"['D Di Leo', 'R Natella', 'R Pietrantuono', 'B Ovilio']",x (not English),
Test suite optimization using chaotic firefly algorithm in software testing,"['A Pandey', 'S Banerjee']",,"Software testing is time consuming and a costly activity. Effective generation of test cases is necessary in order to perform rigorous testing. There exist various techniques for effective test case generation. These techniques are based on various test adequacy criteria such as statement coverage, branch coverage etc. Automatic generation of test data has been the primary focus of software testing research in recent past. In this paper a novel approach based on chaotic behavior of firefly algorithm is proposed for test suite optimization. Test suite optimization problem is modeled in the framework of firefly algorithm. An Algorithm for test optimization based on firefly algorithm is also proposed. Experiments are performed on some benchmark Program and simulation results are compared for ABC algorithm, ACO algorithm, GA with Chaotic firefly algorithm. Major research findings are that chaotic firefly algorithm outperforms other bio inspired algorithm such as artificial bee colony, Ant colony optimization and Genetic Algorithm in terms of Branch coverage in software testing."
Test-case prioritization for configuration testing,"['R Cheng', 'L Zhang', 'D Marinov', 'T Xu']",,"Configuration changes are among the dominant causes of failures of large-scale software system deployment. Given the velocity of configuration changes, typically at the scale of hundreds to thousands of times daily in modern cloud systems, checking these configuration changes is critical to prevent failures due to misconfigurations. Recent work has proposed configuration testing, Ctest, a technique that tests configuration changes together with the code that uses the changed configurations. Ctest can automatically generate a large number of ctests that can effectively detect misconfigurations, including those that are hard to detect by traditional techniques. However, running ctests can take a long time to detect misconfigurations. Inspired by traditional test-case prioritization (TCP) that aims to reorder test executions to speed up detection of regression code faults, we propose to apply TCP to reorder ctests to speed up detection of misconfigurations. We extensively evaluate a total of 84 traditional and novel ctest-specific TCP techniques. The experimental results on five widely used cloud projects demonstrate that TCP can substantially speed up misconfiguration detection. Our study provides guidelines for applying TCP to configuration testing in practice."
The effectiveness of test-driven development approach on software projects: A multi-case study,"['V Bakhtiary', 'TJ Gandomani', 'A Salajegheh']",,"Over recent years, software teams and companies have made attempts to achieve higher productivity and efficiency and get more success in the competitive market by employing proper software methods and practices. Test-driven development (TDD) is one of these practices. The literature review shows that this practice can lead to the improvement of the software development process. Existing empirical studies on TDD report different conclusions about its effects on quality and productivity. The present study tried to briefly report the results from a comparative multiple-case study of two software development projects where the effect of TDD within an industrial environment. Method: We conducted an experiment in an industrial case with 18 professionals. We measured TDD effectiveness in terms of team productivity and code quality. We also measured mood metric and cyclomatic complexity to compare our results with the literature. We have found that the test cases written for a TDD task have higher defect detection ability than test cases written for an incremental NON-TDD development task. Additionally, discovering bugs and fixing them became easier. The results obtained showed the TDD developers develop software code with a higher quality rate, and it results in increasing team productivity than NON_TDD developers."
The use of automatic test data generation for genetic improvement in a live system,"['SO Haraldsson', 'JR Woodward']",,"In this paper we present a bespoke live system in commercial use that has been implemented with self-improving properties. During business hours it provides overview and control for many specialists to simultaneously schedule and observe the rehabilitation process for multiple clients. However in the evening, after the last user logs out, it starts a self-analysis based on the day's recorded interactions and the self-improving process. It uses Search Based Software Testing (SBST) techniques to generate test data for Genetic Improvement (GI) to fix any bugs if exceptions have been recorded. The system has already been under testing for 4 months and demonstrates the effectiveness of simple test data generation and the power of GI for improving live code."
To be optimal or not in test-case prioritization,"['D Hao', 'L Zhang', 'L Zang', 'Y Wang']",,"Software testing aims to assure the quality of software under test. To improve the efficiency of software testing, especially regression testing, test-case prioritization is proposed to schedule the execution order of test cases in software testing. Among various test-case prioritization techniques, the simple additional coverage-based technique, which is a greedy strategy, achieves surprisingly competitive empirical results. To investigate how much difference there is between the order produced by the additional technique and the optimal order in terms of coverage, we conduct a study on various empirical properties of optimal coverage-based test-case prioritization. To enable us to achieve the optimal order in acceptable time for our object programs, we formulate optimal coverage-based test-case prioritization as an integer linear programming (ILP) problem. Then we conduct an empirical study for comparing the optimal technique with the simple additional coverage-based technique. From this empirical study, the optimal technique can only slightly outperform the additional coverage-based technique with no statistically significant difference in terms of coverage, and the latter significantly outperforms the former in terms of either fault detection or execution time. As the optimal technique schedules the execution order of test cases based on their structural coverage rather than detected faults, we further implement the ideal optimal test-case prioritization technique, which schedules the execution order of test cases based on their detected faults. Taking this ideal technique as the upper bound of test-case prioritization, we conduct another empirical study for comparing the optimal technique and the simple additional technique with this ideal technique. From this empirical study, both the optimal technique and the additional technique significantly outperform the ideal technique in terms of coverage, but the latter significantly outperforms the former two techniques in terms of fault detection. Our findings indicate that researchers may need take cautions in pursuing the optimal techniques in test-case prioritization with intermediate goals."
To detect abnormal program behaviours via mutation deduction,"['J Zhang', 'D Hao', 'L Zhang']",,"This paper presents Mutation Deduction, a methodology framework that explores the behaviours of a program under test through exploring the behaviours of its mutants. Mutation Deduction makes use of the relationship between the syntactic changes and semantic changes of a program under test: a new type of metamorphic relation. A metamorphic? relation is supposed to hold as long as the program is correct. Once a metamorphic relation is violated, one could deem that abnormal behaviours exist. The framework is supposed to apply to both single-version and multi-version scenarios. It enlarges the behaviour space that the current test inputs could explore, which could help observe more abnormal behaviours and better ensure software quality."
Topsy-Turvy: a smarter and faster parallelization of mutation analysis,"['R Gopinath', 'C Jensen', 'A Groce']",,"Mutation analysis is an effective, if computationally expensive, technique that allows practitioners to accurately evaluate the quality of their test suites. To reduce the time and cost of mutation analysis, researchers have looked at parallelizing mutation runs --- running multiple mutated versions of the program in parallel, and running through the tests in sequence on each mutated program until a bug is found. While an improvement over sequential execution of mutants and tests, this technique carries a significant overhead cost due to its redundant execution of unchanged code paths. In this paper we propose a novel technique (and its implementation) which parallelizes the test runs rather than the mutants, forking mutants from a single program execution at the point of invocation, which reduces redundancy. We show that our technique can lead to significant efficiency improvements and cost reductions."
Traceability mining between unit test and source code based on textual analysis applied to software systems,"['AH Arshia', 'AH Rasekh', 'MR Moosavi']",,"Correctness of the designed system is one of the most important issues in the software development process. Therefore, various tests have been defined and designed to help software teams develop software with little or no problem. Finding a proper link between test class and the class under the test is an important but difficult task. Finding this relation helps the developers to conduct regression tests more efficiently. In this paper, we seek to propose a model for recovering traceable links between test classes and the classes under the test. The proposed method encompasses three parts: (1) method for extracting keywords and the measure of similarity of a specific part of code, (2) backward chain method based on a rule-based system, (3) using hybrid model to find traceable links between test classes and the code under test. This study uses three open-source and one industrial source projects to conduct experiments. The results are satisfactory compared to previous studies."
Transitioning from manual to automated software regression testing: Experience from the banking domain,"['A Akin', 'S Sentürk', 'V Garousi']",,"Regression testing is needed when a software or the environment hosting that software changes. Motivated by a real-world industrial need in the context of a large financial (banking) corporation in Turkey, the authors and their colleagues developed and introduced an automated regression testing infrastructure for automated testing of one of the main mobile applications of the company. Before this project, regression testing was conducted manually which incurred a lot of costs and was by nature subjective. We report in this paper our experience in 'transitioning' from manual to automated regression testing, and in developing and introducing a set of large automated test suites (more than 16 KLOC in total), using best practices in state-of-the art and -practice, and to report its observed benefits by conducting cost-benefit analysis. The project was conducted based on the principles of case-study and 'action research' in which the real industrial needs drove the research. Among the best practices that we used are the followings: (1) modularity in test code, (2) creating test-specific libraries, and (3) separating test data from test logic. By serving as a success story and experience report in development and introduction of automated test suites in an industrial setting, this paper adds to the body of evidence in this area and it aims at sharing both technical (e.g., using automated test patterns) and process aspects (e.g., test process improvement) from our project with other practitioners and researchers."
Um arcabouço para a geração automatizada de testes funcionais a partir de cenários BDD,"['NN Marques', 'RA Fernandes']",x (not English),
Uma contribuição para o teste baseado em defeitos de software orientado a aspectos,['FC Ferrari'],x (not English),
Uma investigação sobre o uso de critérios de teste no desenvolvimento baseado em testes para o ensino de programação,['BHP Camara'],x (not English),
Unifying regression testing with mutation testing,['L Zhang'],,"Software testing is the most commonly used methodology for validating quality of software systems. Conceptually, testing is simple, but in practice, given the huge (practically infinite) space of inputs to test against, it requires solving a number of challenging problems, including evaluating and reusing tests efficiently and effectively as software evolves. While software testing research has seen much progress in recent years, many crucial bugs still evade state-of-the-art approaches and cause significant monetary losses and sometimes are responsible for loss of life. My thesis is that a unified, bi-dimensional, change-driven methodology can form the basis of novel techniques and tools that can make testing significantly more effective and efficient, and allow us to find more bugs at a reduced cost. We propose a novel unification of the following two dimensions of change: (1) real manual changes made by programmers, e.g., as commonly used to support more effective and efficient regression testing techniques; and (2) mechanically introduced changes to code or specifications, e.g., as originally conceived in mutation testing for evaluating quality of test suites. We believe such unification can lay the foundation of a scalable and highly effective methodology for testing and maintaining real software systems. The primary contribution of my thesis is two-fold. One, it introduces new techniques to address central problems in both regression testing (e.g., test prioritization) and mutation testing (e.g., selective mutation testing). Two, it introduces a new methodology that uses the foundations of regression testing to speed up mutation testing, and also uses the foundations of mutation testing to help with the fault localization problem raised in regression testing. The central ideas are embodied in a suite of prototype tools. Rigorous experimental evaluation is used to validate the efficacy of the proposed techniques using a variety of real-world Java programs."
Unit and regression tests of scientific software: A study on SWMM,"['Z Peng', 'X Lin', 'M Simon', 'N Niu']",,"Testing helps assure software quality by executing a program and uncovering bugs. Scientific software developers often find it challenging to carry out systematic and automated testing due to reasons like inherent model uncertainties and complex floating-point computations. Extending the recent work on analyzing the unit tests written by the developers of the Storm Water Management Model (SWMM) [32], we report in this paper the investigation of both unit and regression tests of SWMM. The results show that the 2953 unit tests of SWMM have a 39.7% statement-level code coverage and a 82.4% user manual coverage. Meanwhile, an examination of 58 regression tests of SWMM shows a 44.9% statement-level code coverage and a near 100% user manual coverage. We also observe a “getter-setter-getter” testing pattern from the SWMM unit tests, and suggest a diversified way of executing regression tests."
Using Aspect-Oriented Programming for mutation testing of third-party components,['MP Usaola'],x (not found),
Using evolutionary computation to improve mutation testing,"['P Delgado-Pérez', 'I Medina-Bulo']",,"The work on mutation testing has attracted a lot of attention during the last decades. Mutation testing is a powerful mechanism to improve the quality of test suites based on the injection of syntactic changes into the code of the original program. Several studies have focused on reducing the high computational cost of applying this technique and increasing its efficiency. Only some of them have tried to do it through the application of genetic algorithms. Genetic algorithms can guide through the generation of a reduced subset of mutants without significant loss of information. In this paper, we analyse recent advances in mutation testing that contribute to reduce the cost associated to this technique and propose to apply them for addressing current drawbacks in Evolutionary Mutation Testing (EMT), a genetic algorithm based technique with promising experimental results so far."
Using probabilistic model checking to evaluate GUI testing techniques,"['C Bertolini', 'A Mota']",,"Different testing techniques are being proposed in software testing to improve systems quality and increase development productivity. However, it is difficult to determine from a given set of testing techniques, which is the most effective testing technique for a certain domain, particularly if they are random-based. We are proposing a strategy and a framework that can evaluate such testing techniques. Our framework is defined compositionally and parametric ally. This allows us to characterize different aspects of systems in an incremental way as well as test specific hypothesis about the system under test. In this paper we focus on GUI-based systems. That is, the specific internal behavior of the system is unknown but it can be approximated by probabilistic behaviors. And the empirical evaluation is based on the probabilistic model checker PRISM."
Using program mutation for the empirical assessment of fault detection techniques: a comparison of concurrency testing and model checking,['JS Bradbury'],x (Book),
Using source transformation to test and model check implicit-invocation systems,"['H Zhang', 'JS Bradbury', 'JR Cordy', 'J Dingel']",,"In this paper we present a source transformation-based framework to support uniform testing and model checking of implicit-invocation software systems. The framework includes a new domain-specific programming language, the Implicit-Invocation Language (IIL), explicitly designed for directly expressing implicit-invocation software systems, and a set of formal rule-based source transformation tools that allow automatic generation of both executable and formal verification artifacts. We provide details of these transformation tools, evaluate the framework in practice, and discuss the benefits of formal automatic transformation in this context. Our approach is designed not only to advance the state-of-the-art in validating implicit-invocation systems, but also to further explore the use of automated source transformation as a uniform vehicle to assist in the implementation, validation and verification of programming languages and software systems in general."
What factors make SQL test cases understandable for testers? a human study of automated test data generation techniques,"['A Alsharif', 'GM Kapfhammer']",,"Since relational databases are a key component of software systems ranging from small mobile to large enterprise applications, there are well-studied methods that automatically generate test cases for database-related functionality. Yet, there has been no research to analyze how well testers - who must often serve as an 'oracle' - both understand tests involving SQL and decide if they reveal flaws. This paper reports on a human study of test comprehension in the context of automatically generated tests that assess the correct specification of the integrity constraints in a relational database schema. In this domain, a tool generates INSERT statements with data values designed to either satisfy (i.e., be accepted into the database) or violate the schema (i.e., be rejected from the database). The study reveals two key findings. First, the choice of data values in INSERTs influences human understandability: the use of default values for elements not involved in the test (but necessary for adhering to SQL's syntax rules) aided participants, allowing them to easily identify and understand the important test values. Yet, negative numbers and 'garbage' strings hindered this process. The second finding is more far reaching: humans found the outcome of test cases very difficult to predict when NULL was used in conjunction with foreign keys and CHECK constraints. This suggests that, while including NULLs can surface the confusing semantics of database schemas, their use makes tests less understandable for humans."
When tests collide: Evaluating and coping with the impact of test dependence,"['W Lam', 'S Zhang', 'MD Ernst']",,"In a test suite, all the test cases should be independent: no test should affect any other test’s result, and running the tests in any order should produce the same test results. The assumption of test independence is important so that tests behave consistently as designed. In addition, many downstream testing techniques, including test prioritization, test selection, and test parallelization, assume test independence. However, this critical assumption often does not hold in practice. This paper empirically investigates the impact of test dependence on three downstream testing techniques (test prioritization, selection, and parallelization) and proposes a general approach to cope with such impact. It presents two sets of results. First, we describe an empirical study to assess the impact of test dependence on 4 test prioritization, 6 test selection, and 2 test parallelization algorithms. Test dependence negatively affects the results of all these downstream testing algorithms. For example, an automatically-generated test suite for the XML-Security program contains 665 tests, and 111 of those tests yield a different test result (success vs. fail) if the suite is parallelized to run on 16 CPUs. Second, we present an approach that enhances each test prioritization, selection, and parallelization algorithm to respect test dependence, so that each test in a suite yields the same result before and after applying the downstream testing technique. In an experimental evaluation, the enhanced testing algorithms worked as intended: the test results were consistent even in the presence of test dependence, and they did not substantially compromise the effectiveness of the original testing algorithms."
Which generated test failures are fault revealing? prioritizing failures based on inferred precondition violations using PAF,"['M Kim', 'SC Cheung', 'S Kim']",,"Automated unit testing tools, such as Randoop, have been developed to produce failing tests as means of finding faults. However, these tools often produce false alarms, so are not widely used in practice. The main reason for a false alarm is that the generated failing test violates an implicit precondition of the method under test, such as a field should not be null at the entry of the method. This condition is not explicitly programmed or documented but implicitly assumed by developers. To address this limitation, we propose a technique called PAF to cluster generated test failures due to the same cause and reorder them based on their likelihood of violating an implicit precondition of the method under test. From various test executions, PAF observes their dataflows to the variables whose values are used when the program fails. Based on the dataflow similarity and where these values are originated, PAF clusters failures and determines their likelihood of being fault revealing. We integrated PAF into Randoop. Our empirical results on open-source projects show that PAF effectively clusters fault revealing tests arising from the same fault and successfully prioritizes the fault-revealing ones."
Wodel-Test: a model-based framework for language-independent mutation testing,"['P Gómez-Abajo', 'E Guerra', 'J de Lara']",,"Mutation testing (MT) targets the assessment of test cases by measuring their efficiency to detect faults. This technique involves modifying the program under test to emulate programming faults, and assessing whether the existing test cases detect such mutations. MT has been extensively studied since the 70’s, and many tools have been proposed for widely used languages like C, Java, Fortran, Ada and SQL; and for notations like Petri-nets. However, building MT tools is costly and error-prone, which may prevent their development for new programming and domain-specific (modelling) languages. In this paper, we propose a framework called Wodel-Test to reduce the effort to create MT tools. For this purpose, it follows a model-driven approach by which MT tools are synthesized from a high-level description. This description makes use of the domain-specific language Wodel to define and execute model mutations. Wodel is language-independent, as it allows the creation of mutation operators for any language defined by a meta-model. Starting from the definition of the mutation operators, Wodel-Test generates a MT environment which parses the program under test into a model, applies the mutation operators, and evaluates the test-suite against the generated mutants, offering a rich collection of MT metrics. We report on an evaluation of the approach based on the creation of MT tools for Java and the Atlas transformation language."
XACMET: XACML testing & modeling,"['S Daoudagh', 'F Lonetti', 'E Marchetti']",,"In the context of access control systems, testing activity is among the most adopted means to assure that sensible information or resources are correctly accessed. In XACML-based access control systems, incoming access requests are transmitted to the policy decision point (PDP) that grants or denies the access based on the defined XACML policies. The criticality of a PDP component requires an intensive testing activity consisting in probing such a component with a set of requests and checking whether its responses grant or deny the requested access as specified in the policy. Existing approaches for improving manual derivation of test requests such as combinatorial ones do not consider policy function semantics and do not provide a verdict oracle. In this paper, we introduce XACMET, a novel approach for systematic generation of XACML requests as well as automated model-based oracle derivation. The main features of XACMET are as follows: (i) it defines a typed graph, called the XAC-Graph, that models the XACML policy evaluation; (ii) it derives a set of test requests via full-path coverage of this graph; (iii) it derives automatically the expected verdict of a specific request execution by executing the corresponding path in such graph; (iv) it allows us to measure coverage assessment of a given test suite. Our validation of the XACMET prototype implementation confirms the effectiveness of the proposed approach."
iDFlakies: A framework for detecting and partially classifying flaky tests,"['W Lam', 'R Oei', 'A Shi', 'D Marinov']",,"Regression testing is increasingly important with the wide use of continuous integration. A desirable requirement for regression testing is that a test failure reliably indicates a problem in the code under test and not a false alarm from the test code or the testing infrastructure. However, some test failures are unreliable, stemming from flaky tests that can nondeterministically pass or fail for the same code under test. There are many types of flaky tests, with order-dependent tests being a prominent type. To help advance research on flaky tests, we present (1) a framework, iDFlakies, to detect and partially classify flaky tests; (2) a dataset of flaky tests in open-source projects; and (3) a study with our dataset. iDFlakies automates experimentation with our tool for Maven-based Java projects. Using iDFlakies, we build a dataset of 422 flaky tests, with 50.5% order-dependent and 49.5% not. Our study of these flaky tests finds the prevalence of two types of flaky tests, probability of a test-suite run to have at least one failure due to flaky tests, and how different test reorderings affect the number of detected flaky tests. We envision that our work can spur research to alleviate the problem of flaky tests."
isense2. 0: Improving completion-aware crowdtesting management with duplicate tagger and sanity checker,"['J Wang', 'Y Yang', 'T Menzies', 'Q Wang']",,"Software engineers get questions of “how much testing is enough” on a regular basis. Existing approaches in software testing management employ experience-, risk-, or value-based analysis to prioritize and manage testing processes. However, very few is applicable to the emerging crowdtesting paradigm to cope with extremely limited information and control over unknown, online crowdworkers. In practice, deciding when to close a crowdtesting task is largely done by experience-based guesswork and frequently results in ineffective crowdtesting. More specifically, it is found that an average of 32% testing cost was wasteful spending in current crowdtesting practice. This article intends to address this challenge by introducing automated decision support for monitoring and determining appropriate time to close crowdtesting tasks. To that end, it first investigates the necessity and feasibility of close prediction of crowdtesting tasks based on an industrial dataset. Next, it proposes a close prediction approach named iSENSE2.0, which applies incremental sampling technique to process crowdtesting reports arriving in chronological order and organizes them into fixed-sized groups as dynamic inputs. Then, a duplicate tagger analyzes the duplicate status of received crowd reports, and a CRC-based (Capture-ReCapture) close estimator generates the close decision based on the dynamic bug arrival status. In addition, a coverage-based sanity checker is designed to reinforce the stability and performance of close prediction. Finally, the evaluation of iSENSE2.0 is conducted on 56,920 reports of 306 crowdtesting tasks from one of the largest crowdtesting platforms. The results show that a median of 100% bugs can be detected with 30% saved cost. The performance of iSENSE2.0 does not demonstrate significant difference with the state-of-the-art approach iSENSE, while the later one relies on the duplicate tag, which is generally considered as time-consuming and tedious to obtain."
