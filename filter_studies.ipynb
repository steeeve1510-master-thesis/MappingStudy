{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./all_studies.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIER = 'Identifier'\n",
    "TITLE = 'Title'\n",
    "AUTHOR = 'Author'\n",
    "YEAR = 'Year'\n",
    "ABSTRACT = 'Abstract'\n",
    "DOI = 'DOI'\n",
    "\n",
    "KEYWORD_MATCH = 'Keyword Match'\n",
    "KEYWORD_MATCH_AUTO = 'Keyword Auto Match'\n",
    "KEYWORD_MATCH_MANUAL = 'Keyword Manual Match'\n",
    "\n",
    "ABSTRACT_MATCH = 'Abstract Match'\n",
    "ABSTRACT_MATCH_AUTO = 'Abstract Auto Match'\n",
    "ABSTRACT_MATCH_MANUAL = 'Abstract Manual Match'\n",
    "\n",
    "USE = 'Use'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce and Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = df.loc[:, ['Identifier', 'Title', 'Author', 'Year', 'Custom1', 'DOI']]\n",
    "ps.columns = [IDENTIFIER, TITLE, AUTHOR, YEAR, ABSTRACT, DOI]\n",
    "ps = ps.sort_values(by=[YEAR], ascending=False)\n",
    "ps[USE] = True\n",
    "ps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = len(ps.index)\n",
    "\n",
    "ps.drop_duplicates(TITLE, inplace=True)\n",
    "\n",
    "rows_after = len(ps.index)\n",
    "removed = rows_before - rows_after\n",
    "\n",
    "print(f'Removed {str(removed)} duplicates ({rows_after}/{rows_before})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "from scidownl.scihub import *\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "size = len(ps.index)\n",
    "\n",
    "for index, row in ps.iterrows():\n",
    "    doi = row[DOI]\n",
    "    out = 'papers/' + row[IDENTIFIER]\n",
    "    print(f'Download {index} of {size}')\n",
    "    if path.exists(out) and len(os.listdir(out)) > 0:\n",
    "        print('skipping')\n",
    "        continue\n",
    "    try:\n",
    "        sci = SciHub(doi, out).download(choose_scihub_url_index=(2 + index%4))\n",
    "    except Exception as e:\n",
    "        print(e, file=sys.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter all Studies where the Full-Text is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "rows_before = len(ps.index)\n",
    "\n",
    "nft = ps[ps.apply(lambda x: len(os.listdir('papers/' + x[IDENTIFIER])) == 0, axis=1)]\n",
    "nft.to_csv('no_full-text.csv', index = False, header=True)\n",
    "#print(nft)\n",
    "\n",
    "ps = ps[ps.apply(lambda x: len(os.listdir('papers/' + x[IDENTIFIER])) > 0, axis=1)]\n",
    "\n",
    "rows_after = len(ps.index)\n",
    "removed = rows_before - rows_after\n",
    "\n",
    "print(f'Removed {str(removed)} papers, because the full-text was not available ({rows_after}/{rows_before})')\n",
    "assert removed == 1, removed\n",
    "\n",
    "## Manual search for removed papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Title for Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps[KEYWORD_MATCH_AUTO] = ps[ps[USE] == True][TITLE].str.match(pat='.*(test|mutant|mutation|coverage).*', case=False)\n",
    "ps[KEYWORD_MATCH_MANUAL] = ps[IDENTIFIER].str.match(pat='(Golagha2017|Li2014|Zhang2013a|Gopinath2012)')\n",
    "# Manual inspection of marked papers (x -> removed, / -> will be kept)\n",
    "# x - Degott2019\n",
    "# x - Vancsics2019\n",
    "# x - Soto2019\n",
    "# x - Vancsics2019a\n",
    "# x - Wang2019\n",
    "# x - Laemmel2018\n",
    "# / - Golagha2017\n",
    "# x - Clapp2015\n",
    "# x - Smith2015\n",
    "# / - Li2014\n",
    "# / - Zhang2013a\n",
    "# x - Shahriar2012\n",
    "# / - Gopinath2012\n",
    "# x - Polikarpova2009\n",
    "## TODO Why are those papers removed?\n",
    "ps[KEYWORD_MATCH] = ps[KEYWORD_MATCH_AUTO] | ps[KEYWORD_MATCH_MANUAL]\n",
    "\n",
    "rows_before = len(ps[ps[USE] == True])\n",
    "rows_auto = len(ps[ps[KEYWORD_MATCH_AUTO] == True])\n",
    "rows_manual = len(ps[ps[KEYWORD_MATCH_MANUAL] == True])\n",
    "rows_after = len(ps[ps[KEYWORD_MATCH] == True])\n",
    "removed = rows_before - rows_auto\n",
    "assert rows_before == 116, rows_before\n",
    "assert rows_auto == 102, rows_auto\n",
    "assert rows_manual == 4, rows_manual\n",
    "assert rows_after == 106, rows_after\n",
    "assert removed == 14, removed\n",
    "\n",
    "print(f'Marked {str(removed)} studies, because their title didn\\'t match any keyword ({rows_auto}/{rows_before})')\n",
    "#print(ps[ps[KEYWORD_MATCH_AUTO] == False][IDENTIFIER].tolist())\n",
    "print(f'{rows_manual} of those {str(removed)} studies met the requirements through manual analysis ({rows_after}/{rows_before})')\n",
    "\n",
    "ps[USE] = ps[USE] & ps[KEYWORD_MATCH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Abstact for Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps[ABSTRACT_MATCH_AUTO] = ps[ps[USE] == True][ABSTRACT].str.match(pat='.*(test suite).*', case=False)\n",
    "ps[ABSTRACT_MATCH_MANUAL] = ps[IDENTIFIER].str.match(pat='(Magalhaes2020|GomezAbajo2020|Wang2020|Wong2020|Bertolino2019|Chen2019|EscobarVelasquez2019|Gergely2019|Minhas2018|Gergely2018|Groce2018|Yi2018|Bowes2017|Felbinger2017|Fellner2017|Golagha2017|Kazmi2017|Magalhaes2017|Giannakopoulou2014|Mirzaaghaei2014|Jehan2013|Schuler2013|Zhang2013a|Selim2012|Gopinath2012|Dobolyi2010|Halfond2009|Fraser2007|Xie2006|Bradbury2005a)')\n",
    "# Manual inspection of the marked studies (x -> removed, / -> will be kept)\n",
    "# / - Magalhaes2020\n",
    "# / - GomezAbajo2020\n",
    "# x - Krotkov2020\n",
    "# / - Wang2020\n",
    "# / - Wong2020\n",
    "# x - Ghanbari2019\n",
    "# / - Bertolino2019\n",
    "# / - Chen2019\n",
    "# / - EscobarVelasquez2019\n",
    "# / - Gergely2019\n",
    "# / - Minhas2018\n",
    "# / - Gergely2018\n",
    "# / - Groce2018\n",
    "# / - Yi2018\n",
    "# / - Bowes2017\n",
    "# / - Felbinger2017\n",
    "# / - Fellner2017\n",
    "# / - Golagha2017\n",
    "# / - Kazmi2017\n",
    "# / - Magalhaes2017\n",
    "# / - Giannakopoulou2014\n",
    "# / - Mirzaaghaei2014\n",
    "# / - Jehan2013\n",
    "# / - Schuler2013\n",
    "# / - Zhang2013a\n",
    "# / - Selim2012\n",
    "# / - Gopinath2012\n",
    "# x - Schuler2011 (duplicate)\n",
    "# / - Dobolyi2010\n",
    "# / - Halfond2009\n",
    "# / - Fraser2007\n",
    "# / - Xie2006\n",
    "# / - Bradbury2005a\n",
    "## TODO Why are those papers removed?\n",
    "ps[ABSTRACT_MATCH] = ps[ABSTRACT_MATCH_AUTO] | ps[ABSTRACT_MATCH_MANUAL]\n",
    "\n",
    "rows_before = len(ps[ps[USE] == True])\n",
    "rows_auto = len(ps[ps[ABSTRACT_MATCH_AUTO] == True])\n",
    "rows_manual = len(ps[ps[ABSTRACT_MATCH_MANUAL] == True])\n",
    "rows_after = len(ps[ps[ABSTRACT_MATCH] == True])\n",
    "removed = rows_before - rows_auto\n",
    "assert rows_before == 106, rows_before\n",
    "assert rows_auto == 73, rows_auto\n",
    "assert rows_manual == 30, rows_manual\n",
    "assert rows_after == 103, rows_after\n",
    "assert removed == 33, removed\n",
    "\n",
    "print(f'Marked {str(removed)} studies, because their abstract didn\\'t match any keyword ({rows_auto}/{rows_before})')\n",
    "# print(ps[ps[ABSTRACT_MATCH_AUTO] == False][IDENTIFIER].tolist())\n",
    "print(f'{rows_manual} of those {str(removed)} studies met the requirements through manual analysis ({rows_after}/{rows_before})')\n",
    "\n",
    "ps[USE] = ps[USE] & ps[ABSTRACT_MATCH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ps[ps[USE] == True]\n",
    "#ps = ps.loc[:, [IDENTIFIER, TITLE, AUTHOR, YEAR, ABSTRACT, DOI]]\n",
    "ps = ps.loc[:, [IDENTIFIER, TITLE, AUTHOR, YEAR, ABSTRACT, DOI]]\n",
    "\n",
    "rows_used = len(ps)\n",
    "assert rows_used == 103, rows_used\n",
    "print(f'{rows_used} papers remain in the study')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Auto Filtered Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_auto = ps.loc[:, [IDENTIFIER, TITLE, ABSTRACT]]\n",
    "ps_auto.to_csv('filtered_studies_auto.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Manual Filtered Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_manual = pd.read_csv('filtered_studies_manual.csv')\n",
    "\n",
    "undef = ps_manual[USE].isnull().sum()\n",
    "assert undef == 0, undef\n",
    "\n",
    "print(ps_manual.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Compability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = set(ps_auto[IDENTIFIER].tolist()) - set(ps_manual[IDENTIFIER].tolist())\n",
    "difference2 = set(ps_manual[IDENTIFIER].tolist()) - set(ps_auto[IDENTIFIER].tolist())\n",
    "difference |= difference2\n",
    "\n",
    "assert len(difference) == 0, difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = len(ps_auto.index)\n",
    "rows_after = len(ps_manual[ps_manual[USE] == True])\n",
    "\n",
    "assert rows_after == 73, rows_after\n",
    "\n",
    "print(f'After manual filtering, {rows_after} studies remain ({rows_after}/{rows_before})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Manual Filtered Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_final = ps_manual[ps_manual[USE] == True]\n",
    "\n",
    "ps_final = ps_final.loc[:, [IDENTIFIER, TITLE]]\n",
    "ps_final = pd.merge(ps_final, ps, how=\"inner\", on=[IDENTIFIER, TITLE])\n",
    "ps_final = ps_final.loc[:, [IDENTIFIER, TITLE, DOI]]\n",
    "ps_final.to_csv('filtered_studies_final.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
